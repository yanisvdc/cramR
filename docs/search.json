[{"path":"https://yanisvdc.github.io/cramR/articles/cram_bandit.html","id":"what-is-cram_bandit","dir":"Articles","previous_headings":"","what":"What is cram_bandit()?","title":"Cram Bandit","text":"cram_bandit() function implements Cram methodology -policy statistical evaluation contextual bandit algorithms. Unlike traditional -policy approaches, Cram uses adaptively collected data learning evaluation, delivering efficient, consistent, asymptotically normal policy value estimates.","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_bandit.html","id":"introduction-bandits-policies-and-cram","dir":"Articles","previous_headings":"","what":"Introduction: Bandits, Policies, and Cram","title":"Cram Bandit","text":"many machine learning settings, decisions must made sequentially uncertainty ‚Äî instance, recommending content, personalizing treatments, allocating resources. problems often modeled contextual bandits, agent: Observes context (features situation) Chooses action (e.g., recommend article) Observes reward (e.g., targeted user clicks article ) policy function maps context probability distribution actions, goal maximizing expected cumulative reward time. Learning optimal policy evaluating performance using data difficult due adaptive nature data collection. challenge becomes evident comparing supervised learning: supervised learning, outcome label yy observed every input xx, allowing direct minimization prediction error. contrast, bandit setting, outcome (reward) observed single action chosen agent. agent must therefore select action order reveal reward associated , making data collection learning inherently intertwined. Cram method addresses general statistical framework evaluating final learned policy multi-armed contextual bandit algorithm, using dataset generated bandit algorithm. Notably, Cram able leverage setting return estimate well learned policy perform deployed entire population (policy value), along confidence interval desired significance level.","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_bandit.html","id":"understanding-the-inputs","dir":"Articles","previous_headings":"","what":"Understanding the inputs","title":"Cram Bandit","text":"Many contextual bandit algorithms update policies every rounds instead every step ‚Äî known batched setting. example, batch size B=5B = 5, algorithm collects 5 new samples updating policy. results sequence policies œÄÃÇ1,œÄÃÇ2,...,œÄÃÇT\\hat{\\pi}_1, \\hat{\\pi}_2, ..., \\hat{\\pi}_T, TT number batches. total, observe T√óBT \\times B data points, consisting : context action selected policy active time reward Cram supports batched setting bandit algorithms allow flexible use. Note one can still set B=1B = 1 performing policy updates observation. Thus, Cram bandit takes inputs: pi: array shape (T √ó B, T, K) (T √ó B, T), : TT number learning steps (policy updates) BB batch size KK number arms T√óBT \\times B total number contexts natural 3D version, pi[j, t, ] gives probability policy œÄÃÇt\\hat{\\pi}_t assigns arm context XjX_j Users may still use 2D version internally, actually need probabilities assigned chosen arm AjA_j context XjX_j historical data - probabilities arms aa context XjX_j, allows us remove last dimension (‚Äúarm dimension‚Äù) 3D array. words, compact form omits full distribution arms assumes providing realized action probabilities. üõ†Ô∏è need compute probability array trained policy historical data, cramR package provides helper utilities cramR::: namespace (see ‚ÄúBandit Helpers‚Äù vignette). Note exact method may depend bandit logs models structured. arm: vector length T√óBT \\times B indicating arm selected context. reward: vector observed rewards length T√óBT \\times B. batch: (optional) Integer batch size BB. Default 1. alpha: Significance level confidence intervals. Cram bandit returns: Estimated policy value Estimated standard error Confidence interval level alpha","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_bandit.html","id":"example-use-cram_bandit-on-simulated-data-with-batch-size-of-1","dir":"Articles","previous_headings":"","what":"Example: Use cram_bandit() on simulated data with batch size of 1","title":"Cram Bandit","text":"","code":"# Set random seed for reproducibility set.seed(42)  # Define parameters T <- 100  # Number of timesteps K <- 4    # Number of arms  # Simulate a 3D array `pi` of shape (T, T, K) # - First dimension: Individuals (context Xj) # - Second dimension: Time steps (pi_t) # - Third dimension: Arms (depth) pi <- array(runif(T * T * K, 0.1, 1), dim = c(T, T, K))  # Normalize probabilities so that each row sums to 1 across arms for (t in 1:T) {   for (j in 1:T) {     pi[j, t, ] <- pi[j, t, ] / sum(pi[j, t, ])     } }  # Simulate arm selections (randomly choosing an arm) arm <- sample(1:K, T, replace = TRUE)  # Simulate rewards (assume normally distributed rewards) reward <- rnorm(T, mean = 1, sd = 0.5) result <- cram_bandit(pi, arm, reward, batch=1, alpha=0.05) result$raw_results #>                        Metric   Value #> 1       Policy Value Estimate 0.67621 #> 2 Policy Value Standard Error 0.04394 #> 3       Policy Value CI Lower 0.59008 #> 4       Policy Value CI Upper 0.76234 result$interactive_table"},{"path":"https://yanisvdc.github.io/cramR/articles/cram_bandit.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Cram Bandit","text":"Jia, Z., Imai, K., & Li, M. L. (2024). Cram Method Efficient Simultaneous Learning Evaluation. arXiv preprint arXiv:2403.07031. Zhan et al.¬†(2021). -policy evaluation via adaptive weighting data contextual bandits. KDD.","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_bandit_helpers.html","id":"what-is-this-article-about","dir":"Articles","previous_headings":"","what":"üåü What is this article about?","title":"Cram Bandit Helpers","text":"order use cram_bandit(), users must supply matrix action selection probabilities œÄt(Xj,Aj)\\pi_t(X_j, A_j) combination policy update tt context jj historical dataset. environments log probabilities directly, many contextual bandit libraries (contextual) store policy parameters (e.g., regression coefficients) without explicit probability tracking. article explains Cram Bandit Helpers reconstruct œÄt(Xj,Aj)\\pi_t(X_j, A_j) parameters common policies: theoretical formulas practical code snippets provided.","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_bandit_helpers.html","id":"policy-parameters-explained","dir":"Articles","previous_headings":"","what":"üõ†Ô∏èPolicy parameters explained","title":"Cram Bandit Helpers","text":"using linear bandit algorithms like Epsilon-Greedy, LinUCB, Thompson Sampling, arm kk maintains summary statistics (parameters) estimate expected reward: AkA_k Gram matrix:Ak=XkTXk A_k = X_k^T X_k  XkX_k matrix feature vectors (contexts) rounds arm kk selected. ‚ûî Interpretation: AkA_k captures amount information (correlation structure) features arm kk. plays role ‚Äúfeature covariance matrix.‚Äù bkb_k response vector:bk=XkTyk b_k = X_k^T y_k  yky_k observed rewards arm kk. ‚ûî Interpretation: bkb_k captures relationship observed rewards contexts arm kk. sufficient statistics allow policy compute Least Squares estimate reward model: Œ∏k=Ak‚àí1bk \\theta_k = A_k^{-1} b_k : Œ∏k\\theta_k estimated coefficient vector predicts expected reward arm kk function context. Thus: AkA_k tells us confident Œ∏k\\theta_k (smaller eigenvalues AkA_k imply uncertainty). bkb_k provides observed signal (reward-weighted context features) fit Œ∏k\\theta_k. policy selects action based Œ∏k\\theta_k arm kk observe reward associated choice, used update parameters AkA_k bkb_k policy.","code":""},{"path":[]},{"path":"https://yanisvdc.github.io/cramR/articles/cram_bandit_helpers.html","id":"theoretical-computation","dir":"Articles","previous_headings":"‚ú® Epsilon-Greedy Policy","what":"ü§ñ Theoretical computation","title":"Cram Bandit Helpers","text":"Epsilon-Greedy, exploration rate Œµ\\varepsilon, probability selecting one best arms : P(|Xt)=(1‚àíŒµ)√ó1#best arms+Œµ√ó1K P(A_t | X_t) = (1 - \\varepsilon) \\times \\frac{1}{\\# \\text{best arms}} + \\varepsilon \\times \\frac{1}{K} probability selecting arm among best arms : P(|Xt)=Œµ√ó1K P(A_t | X_t) = \\varepsilon \\times \\frac{1}{K} : Best arms maximal estimated rewards. KK total number available arms. define least squares estimate : Œ∏k=Ak‚àí1bk(Least Squares estimate) \\theta_k = A_k^{-1} b_k \\quad \\text{(Least Squares estimate)} : AkA_k Gram matrix XkTXkX_k^T X_k bkb_k vector XkTYkX_k^T Y_k Best arms identified via estimated expected reward: Expected reward=XtTŒ∏k \\text{Expected reward} = X_t^T \\theta_k","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_bandit_helpers.html","id":"code-helper","dir":"Articles","previous_headings":"‚ú® Epsilon-Greedy Policy","what":"üìä Code helper","title":"Cram Bandit Helpers","text":"cramR, implemented : function: Computes Œ∏k\\theta_k arm Calculates expected rewards XtTŒ∏kX_t^T \\theta_k Identifies best arms Applies formula","code":"get_proba_c_eps_greedy(eps, A_list, b_list, contexts, chosen_arms)"},{"path":[]},{"path":"https://yanisvdc.github.io/cramR/articles/cram_bandit_helpers.html","id":"theoretical-computation-1","dir":"Articles","previous_headings":"üî¢ LinUCB Disjoint Policy with Œµ\\varepsilon-Greedy","what":"ü§ñ Theoretical computation","title":"Cram Bandit Helpers","text":"LinUCB selects arms based Upper Confidence Bounds (UCBs): UCBk(Xt)=Œºk(Xt)+Œ±œÉk(Xt) \\text{UCB}_k(X_t) = \\mu_k(X_t) + \\alpha \\sigma_k(X_t) : Œºk(Xt)=XtTŒ∏k\\mu_k(X_t) = X_t^T \\theta_k œÉk(Xt)=XtTAk‚àí1Xt\\sigma_k(X_t) = \\sqrt{X_t^T A_k^{-1} X_t} measures uncertainty Œ±\\alpha controls exploration strength action probabilities follow structure Epsilon-Greedy UCB scores instead plain expected rewards .e.¬†probability select one best arms : P(|Xt)=(1‚àíŒµ)√ó1#best arms+Œµ√ó1K P(A_t | X_t) = (1 - \\varepsilon) \\times \\frac{1}{\\# \\text{best arms}} + \\varepsilon \\times \\frac{1}{K} probability select arm among best arms : P(|Xt)=Œµ√ó1K P(A_t | X_t) = \\varepsilon \\times \\frac{1}{K} ‚Äúbest arms‚Äù highest UCB scores.","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_bandit_helpers.html","id":"code-helper-1","dir":"Articles","previous_headings":"üî¢ LinUCB Disjoint Policy with Œµ\\varepsilon-Greedy","what":"üìä Code helper","title":"Cram Bandit Helpers","text":"cramR, implemented : function: Computes Œ∏k\\theta_k Computes Œºk(Xt)\\mu_k(X_t) œÉk(Xt)\\sigma_k(X_t) Identifies arms maximizing UCBk(Xt)\\text{UCB}_k(X_t) Applies Epsilon-Greedy selection formula","code":"get_proba_ucb_disjoint(alpha, eps, A_list, b_list, contexts, chosen_arms)"},{"path":[]},{"path":"https://yanisvdc.github.io/cramR/articles/cram_bandit_helpers.html","id":"theoretical-computation-2","dir":"Articles","previous_headings":"ü§ì Thompson Sampling (LinTS)","what":"ü§ñ Theoretical computation","title":"Cram Bandit Helpers","text":"Thompson Sampling, actions sampled according posterior draws action associated maximum value chosen. probability arm AtA_t optimal : P(|Xt)=‚Ñô(Œ∏AtTXt>Œ∏kTXt‚àÄk‚â†) P(A_t | X_t) = \\mathbb{P}\\left( \\theta_{A_t}^T X_t > \\theta_{k}^T X_t \\quad \\forall k \\neq A_t \\right) Œ∏k‚àºùí©(Ak‚àí1bk,œÉ2Ak‚àí1)\\theta_k \\sim \\mathcal{N}(A_k^{-1} b_k, \\sigma^2 A_k^{-1}). requires computing multivariate probability, approximate via adaptive numerical integration.","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_bandit_helpers.html","id":"code-helper-2","dir":"Articles","previous_headings":"ü§ì Thompson Sampling (LinTS)","what":"üìä Code helper","title":"Cram Bandit Helpers","text":"cramR, implemented : function: Computes posterior means variances Integrates space chosen arm AtA_t highest sampled reward Returns clipped probabilities numerical stability","code":"get_proba_thompson(sigma, A_list, b_list, contexts, chosen_arms)"},{"path":"https://yanisvdc.github.io/cramR/articles/cram_bandit_helpers.html","id":"practical-workflow","dir":"Articles","previous_headings":"","what":"üë®‚Äçüíª Practical Workflow","title":"Cram Bandit Helpers","text":"using bandit policy practice: Record action choices, contexts, policy parameters (e.g., AA, bb) Calculate action selection probabilities. policy within ones presented , please feel free rely helper functions build œÄ\\pi. Feed pi, arm, reward cram_bandit() evaluation policy.","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_bandit_helpers.html","id":"estimand-calculation-in-cram_bandit_sim","dir":"Articles","previous_headings":"","what":"üß™ Estimand Calculation in cram_bandit_sim()","title":"Cram Bandit Helpers","text":"following concerns simulation framework implemented benchmarking purposes. policies reconstructed, compute true expected value ‚Äî referred estimand ‚Äî applying learned policy independent contexts evaluating known reward function used simulation. done via: Accurately computing estimand critical properly assessing bias confidence interval coverage Cram estimate simulations.","code":"compute_estimand(data_group, list_betas, policy, policy_name, batch_size, bandit)"},{"path":"https://yanisvdc.github.io/cramR/articles/cram_bandit_helpers.html","id":"useful-links","dir":"Articles","previous_headings":"","what":"üìÇ Useful Links","title":"Cram Bandit Helpers","text":"contextual package: original framework cram_bandit(): Cram evaluation contextual bandits cram_bandit_sim(): Full simulation engine automatic pi estimation","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_bandit_helpers.html","id":"acknowledgments","dir":"Articles","previous_headings":"","what":"üåü Acknowledgments","title":"Cram Bandit Helpers","text":"helper functions designed faithfully reconstruct action probabilities policies implemented contextual, enabling reproducible Cram-based evaluation.","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_bandit_simulation.html","id":"what-is-cram_bandit_sim","dir":"Articles","previous_headings":"","what":"What is cram_bandit_sim()?","title":"Cram Bandit Simulation","text":"cram_bandit_sim() function runs -policy simulation contextual bandit algorithms using Cram method. evaluates statistical properties policy value estimates : Empirical Bias Policy Value Average relative error Policy Value RMSE using relative errors Policy Value Empirical Coverage Confidence Intervals useful benchmarking bandit policies controlled, simulated environments.","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_bandit_simulation.html","id":"inputs","dir":"Articles","previous_headings":"","what":"üìã Inputs","title":"Cram Bandit Simulation","text":"need provide: bandit: contextual bandit environment object generates contexts (feature vectors) rewards arm. Example: ContextualLinearBandit, object following contextual package interface. policy: policy object takes context selects arm (action) timestep. Example: BatchContextualLinTSPolicy, compatible contextual package policy. horizon: integer specifying number timesteps (rounds) per simulation. simulation run exactly horizon steps. simulations: integer specifying number independent Monte Carlo simulations perform. simulation independently reset environment policy. Optional Parameters: alpha: numeric value 0 1 specifying significance level confidence intervals calculating empirical coverage. Default: 0.05 (95% confidence intervals). seed: optional integer set random seed reproducibility. NULL, seed set. do_parallel: logical value indicating whether parallelize simulations across available CPU cores. Default: FALSE (parallelization disabled). recommend keeping do_parallel = FALSE unless necessary, parallel execution can make harder underlying contextual package reliably track simulation history. particular, parallel runs may cause missing incomplete entries recorded history, discarded analysis.","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_bandit_simulation.html","id":"example-cram-bandit-simulation","dir":"Articles","previous_headings":"","what":"Example: Cram Bandit Simulation","title":"Cram Bandit Simulation","text":"","code":"# Number of time steps horizon       <- 500L  # Number of simulations  simulations   <- 100L  # Number of arms k = 4  # Number of context features d= 3  # Reward beta parameters of linear model (the outcome generation models, one for each arm, are linear with arm-specific parameters betas) list_betas <- cramR:::get_betas(simulations, d, k)  # Define the contextual linear bandit, where sigma is the scale of the noise in the outcome linear model bandit        <- cramR:::ContextualLinearBandit$new(k = k, d = d, list_betas = list_betas, sigma = 0.3)  # Define the policy object (choose between Contextual Epsilon Greedy, UCB Disjoint and Thompson Sampling) policy <- cramR:::BatchContextualEpsilonGreedyPolicy$new(epsilon=0.1, batch_size=5) # policy <- cramR:::BatchLinUCBDisjointPolicyEpsilon$new(alpha=1.0, epsilon=0.1, batch_size=1) # policy <- cramR:::BatchContextualLinTSPolicy$new(v = 0.1, batch_size=1)   sim <- cram_bandit_sim(horizon, simulations,                             bandit, policy,                             alpha=0.05, do_parallel = FALSE) #> Simulation horizon: 500 #> Number of simulations: 101 #> Number of batches: 1 #> Starting main loop. #> Finished main loop. #> Completed simulation in 0:00:05.218 #> Computing statistics."},{"path":"https://yanisvdc.github.io/cramR/articles/cram_bandit_simulation.html","id":"what-does-it-return","dir":"Articles","previous_headings":"","what":"What Does It Return?","title":"Cram Bandit Simulation","text":"output contains: data.table one row per simulation, including: estimate: estimated policy value variance_est: estimated variance estimand: true policy value (computed held-context data) prediction_error: estimate - estimand est_rel_error: relative error estimate variance_prediction_error: relative error variance ci_lower, ci_upper: bounds confidence interval std_error: standard error Result tables (raw interactive), reporting: Empirical Bias Policy Value Average relative error Policy Value RMSE using relative errors Policy Value Empirical Coverage Confidence Intervals","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_bandit_simulation.html","id":"example-output-preview","dir":"Articles","previous_headings":"","what":"Example Output Preview","title":"Cram Bandit Simulation","text":"","code":"head(sim$estimates) #>      sim  estimate variance_est  estimand prediction_error est_rel_error #>    <int>     <num>        <num>     <num>            <num>         <num> #> 1:     1 0.5017577  0.008990666 0.5445425      -0.04278478   -0.07857014 #> 2:     2 0.6189290  0.000770998 0.5981170       0.02081205    0.03479596 #> 3:     3 0.3455183  0.057464183 0.5528602      -0.20734195   -0.37503504 #> 4:     4 0.5837325  0.001025324 0.5998785      -0.01614596   -0.02691539 #> 5:     5 0.3333935  0.018343895 0.5228533      -0.18945980   -0.36235750 #> 6:     6 0.5137367  0.001389443 0.4651693       0.04856737    0.10440794 #>    variance_prediction_error  std_error    ci_lower  ci_upper #>                        <num>      <num>       <num>     <num> #> 1:                -0.8807182 0.09481912  0.31591566 0.6875998 #> 2:                -0.9897709 0.02776685  0.56450699 0.6733510 #> 3:                -0.2376059 0.23971688 -0.12431818 0.8153547 #> 4:                -0.9863967 0.03202069  0.52097315 0.6464919 #> 5:                -0.7566262 0.13543963  0.06793667 0.5988503 #> 6:                -0.9815659 0.03727523  0.44067855 0.5867948 sim$interactive_table"},{"path":"https://yanisvdc.github.io/cramR/articles/cram_bandit_simulation.html","id":"notes","dir":"Articles","previous_headings":"","what":"Notes","title":"Cram Bandit Simulation","text":"list_betas updated internally track true parameters per simulation first simulation discarded design (due writing issues contextual) even do_parallel = FALSE.","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_bandit_simulation.html","id":"recommended-use-cases","dir":"Articles","previous_headings":"","what":"Recommended Use Cases","title":"Cram Bandit Simulation","text":"Validate bandit policies repeated experiments Compare bias variance different policy types Analyze empirical coverage confidence intervals Stress-test policies different batch sizes, sigma levels, dimensions","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_bandit_simulation.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Cram Bandit Simulation","text":"simulation builds : Contextual bandits (contextual package) -policy Cram estimation","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_learning.html","id":"what-is-cram_learning","dir":"Articles","previous_headings":"","what":"üîç What is cram_learning()?","title":"Using cram_learning() for Sequential or Parallel Policy Training","text":"cram_learning() function runs core learning routine CRAM framework. learns batch-wise policies using cumulative data splits supports: Different model types (causal_forest, s_learner, m_learner) Different learners (ridge, fnn) Flexible batching (sequential parallel) Support custom models (custom_fit, custom_predict) function typically called internally wrappers like cram_policy(), cram_simulation(), cram_ml() ‚Äî can also used standalone advanced use.","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_learning.html","id":"when-to-use-it","dir":"Articles","previous_headings":"","what":"üß† When to use it?","title":"Using cram_learning() for Sequential or Parallel Policy Training","text":"Use cram_learning() directly want: - control model training batch handling - debug visualize policy learning phase - inject custom models outside built-ones","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_learning.html","id":"example-running-cram_learning-with-causal-forest","dir":"Articles","previous_headings":"","what":"üìò Example: Running cram_learning() with Causal Forest","title":"Using cram_learning() for Sequential or Parallel Policy Training","text":"","code":"# Simulated data X <- matrix(rnorm(100 * 5), nrow = 100, ncol = 5) D <- sample(c(0, 1), 100, replace = TRUE) Y <- rnorm(100) # Parameters batch <- 20 model_type <- 'causal_forest'      # causal_forest, s_learner, or m_learner learner_type <- NULL               # NULL for causal_forest baseline_policy <- as.list(rep(0, nrow(X)))  # or random: as.list(sample(c(0, 1), nrow(X), TRUE)) parallelize_batch <- FALSE         # Set to TRUE for parallelized learning model_params <- NULL               # e.g., list(num.trees = 100) for causal_forest # Run cram_learning learning_result <- cram_learning(   X = X,   D = D,   Y = Y,   batch = batch,   model_type = model_type,   learner_type = learner_type,   baseline_policy = baseline_policy,   parallelize_batch = parallelize_batch,   model_params = model_params )"},{"path":"https://yanisvdc.github.io/cramR/articles/cram_learning.html","id":"output","dir":"Articles","previous_headings":"","what":"üì¶ Output","title":"Using cram_learning() for Sequential or Parallel Policy Training","text":"Returns list :","code":"str(learning_result) #> List of 3 #>  $ final_policy_model:List of 28 #>   ..$ _ci_group_size          : num 2 #>   ..$ _num_variables          : num 5 #>   ..$ _num_trees              : num 100 #>   ..$ _root_nodes             :List of 100 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. .. [list output truncated] #>   ..$ _child_nodes            :List of 100 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num 0 #>   .. .. ..$ : num 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num 0 #>   .. .. ..$ : num 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num 0 #>   .. .. ..$ : num 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num 0 #>   .. .. ..$ : num 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num 0 #>   .. .. ..$ : num 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num 0 #>   .. .. ..$ : num 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num 0 #>   .. .. ..$ : num 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num 0 #>   .. .. ..$ : num 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num 0 #>   .. .. ..$ : num 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num 0 #>   .. .. ..$ : num 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num 0 #>   .. .. ..$ : num 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num 0 #>   .. .. ..$ : num 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num 0 #>   .. .. ..$ : num 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num 0 #>   .. .. ..$ : num 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num 0 #>   .. .. ..$ : num 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num 0 #>   .. .. ..$ : num 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. ..$ :List of 2 #>   .. .. ..$ : num [1:3] 1 0 0 #>   .. .. ..$ : num [1:3] 2 0 0 #>   .. .. [list output truncated] #>   ..$ _leaf_samples           :List of 100 #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:12] 91 33 98 72 13 81 29 9 36 75 ... #>   .. .. ..$ : num [1:13] 66 25 67 1 43 92 38 8 70 11 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:9] 7 91 72 43 64 16 38 56 42 #>   .. .. ..$ : num [1:16] 36 68 54 67 31 90 57 25 27 71 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:16] 3 17 11 56 63 29 43 38 77 55 ... #>   .. .. ..$ : num [1:9] 8 92 13 94 93 47 83 4 5 #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:17] 43 2 76 39 24 86 56 8 83 1 ... #>   .. .. ..$ : num [1:8] 35 94 0 22 21 85 3 52 #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:12] 65 16 46 72 54 42 80 94 88 28 ... #>   .. .. ..$ : num [1:13] 45 85 67 38 3 74 95 73 4 30 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:6] 76 88 74 15 29 30 #>   .. .. ..$ : num [1:19] 21 26 41 85 27 77 17 0 87 73 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:6] 41 75 62 80 40 82 #>   .. .. ..$ : num [1:19] 46 23 53 4 38 63 89 95 39 47 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:20] 53 89 24 7 66 54 92 10 40 15 ... #>   .. .. ..$ : num [1:5] 68 80 41 83 51 #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:13] 41 45 53 64 16 82 72 32 96 17 ... #>   .. .. ..$ : num [1:12] 8 83 66 50 31 77 94 76 62 1 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:12] 64 66 94 57 14 39 84 23 78 67 ... #>   .. .. ..$ : num [1:13] 72 59 49 10 17 69 31 9 83 96 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:13] 24 95 43 82 20 72 53 80 48 92 ... #>   .. .. ..$ : num [1:12] 90 3 52 4 16 31 34 12 11 97 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:8] 52 82 35 33 97 84 12 23 #>   .. .. ..$ : num [1:17] 96 17 31 40 90 0 8 18 61 89 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:14] 73 38 58 49 9 88 63 25 30 6 ... #>   .. .. ..$ : num [1:11] 12 3 68 94 98 85 57 44 21 51 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:17] 6 74 39 15 44 25 66 32 38 24 ... #>   .. .. ..$ : num [1:8] 98 36 55 51 69 68 85 42 #>   .. ..$ :List of 1 #>   .. .. ..$ : num [1:25] 30 43 74 24 99 58 31 52 36 73 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:16] 32 91 62 42 77 76 40 67 94 64 ... #>   .. .. ..$ : num [1:9] 79 53 87 7 46 13 99 56 74 #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:10] 76 88 15 57 44 54 74 64 70 46 #>   .. .. ..$ : num [1:15] 96 83 26 72 73 47 87 45 69 1 ... #>   .. ..$ :List of 1 #>   .. .. ..$ : num [1:25] 71 27 13 64 72 79 47 69 42 44 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:14] 33 80 69 40 27 78 22 13 94 36 ... #>   .. .. ..$ : num [1:11] 6 4 32 14 58 48 52 19 49 92 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:14] 45 83 92 78 86 27 64 5 22 77 ... #>   .. .. ..$ : num [1:11] 21 62 48 38 74 37 63 60 4 80 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:13] 59 45 67 29 6 69 57 55 94 91 ... #>   .. .. ..$ : num [1:12] 13 30 3 89 1 84 38 33 43 75 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:11] 33 67 74 57 35 84 79 3 94 70 ... #>   .. .. ..$ : num [1:14] 91 53 32 60 26 54 5 61 83 11 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:9] 19 15 12 4 6 97 55 48 20 #>   .. .. ..$ : num [1:16] 49 96 92 34 62 8 32 60 26 69 ... #>   .. ..$ :List of 1 #>   .. .. ..$ : num [1:25] 62 96 52 15 53 27 77 98 59 13 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:12] 15 73 76 36 39 94 16 63 93 66 ... #>   .. .. ..$ : num [1:13] 69 65 75 38 28 13 83 21 47 45 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:16] 76 11 71 97 81 37 82 28 16 83 ... #>   .. .. ..$ : num [1:9] 89 10 44 38 63 47 34 52 66 #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:9] 20 26 56 69 32 60 76 75 13 #>   .. .. ..$ : num [1:16] 45 38 68 25 19 2 67 96 95 47 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:15] 9 0 61 81 49 86 67 23 5 88 ... #>   .. .. ..$ : num [1:10] 74 87 38 30 3 19 60 13 58 63 #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:4] 34 81 44 57 #>   .. .. ..$ : num [1:21] 40 23 46 95 48 22 16 1 25 11 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:6] 55 98 60 91 81 57 #>   .. .. ..$ : num [1:19] 64 39 25 77 22 11 74 37 10 38 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:16] 39 44 63 11 70 79 50 8 92 58 ... #>   .. .. ..$ : num [1:9] 36 51 0 3 5 26 16 41 57 #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:11] 8 92 80 28 32 76 70 50 73 30 ... #>   .. .. ..$ : num [1:14] 51 10 78 23 68 16 64 44 31 66 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:10] 31 72 0 88 41 83 34 94 39 24 #>   .. .. ..$ : num [1:15] 37 7 12 56 53 69 89 71 99 28 ... #>   .. ..$ :List of 1 #>   .. .. ..$ : num [1:25] 71 69 76 24 11 36 50 43 98 94 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:8] 36 81 14 39 91 88 86 29 #>   .. .. ..$ : num [1:17] 7 78 84 85 54 75 40 99 97 28 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:16] 32 81 20 36 51 77 14 39 22 41 ... #>   .. .. ..$ : num [1:9] 99 79 52 28 65 12 10 48 90 #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:16] 93 74 70 71 20 85 72 91 82 14 ... #>   .. .. ..$ : num [1:9] 38 65 81 90 61 9 49 8 86 #>   .. ..$ :List of 1 #>   .. .. ..$ : num [1:25] 66 91 43 42 20 85 90 35 70 11 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:13] 95 92 44 70 14 82 91 81 42 2 ... #>   .. .. ..$ : num [1:12] 25 35 74 52 43 84 21 20 71 89 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:18] 22 95 61 92 18 35 24 67 69 42 ... #>   .. .. ..$ : num [1:7] 84 56 68 16 63 99 48 #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:16] 7 41 13 22 72 82 60 35 55 64 ... #>   .. .. ..$ : num [1:9] 48 95 67 43 61 1 38 63 21 #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:11] 41 82 88 26 28 55 60 14 17 7 ... #>   .. .. ..$ : num [1:14] 35 13 51 77 22 36 93 71 57 92 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:8] 55 78 26 86 11 88 93 5 #>   .. .. ..$ : num [1:17] 4 32 63 87 49 97 70 85 18 14 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:21] 60 73 12 44 13 35 88 55 40 53 ... #>   .. .. ..$ : num [1:4] 26 0 81 28 #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:13] 2 85 48 93 23 6 19 88 74 91 ... #>   .. .. ..$ : num [1:12] 25 26 0 61 41 96 21 45 62 75 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:13] 78 93 58 57 48 14 91 16 6 15 ... #>   .. .. ..$ : num [1:12] 43 96 41 0 73 77 75 65 72 99 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:16] 59 5 21 6 49 8 15 54 88 0 ... #>   .. .. ..$ : num [1:9] 50 68 25 1 89 79 11 52 48 #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:17] 70 4 59 93 54 23 11 95 79 48 ... #>   .. .. ..$ : num [1:8] 68 90 0 13 96 21 56 45 #>   .. ..$ :List of 1 #>   .. .. ..$ : num [1:25] 8 11 87 94 0 57 68 47 40 78 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:11] 4 95 78 70 23 82 57 16 67 15 ... #>   .. .. ..$ : num [1:14] 34 37 77 45 62 0 11 27 47 43 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:17] 40 80 15 6 65 46 69 72 76 78 ... #>   .. .. ..$ : num [1:8] 53 13 43 4 37 48 89 75 #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:13] 17 76 83 69 55 34 22 82 62 95 ... #>   .. .. ..$ : num [1:12] 25 89 28 13 11 10 48 56 84 37 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:10] 48 4 52 23 39 97 36 84 76 54 #>   .. .. ..$ : num [1:15] 90 71 32 62 86 85 27 89 81 11 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:14] 73 47 25 32 92 83 15 19 56 37 ... #>   .. .. ..$ : num [1:11] 61 22 7 85 98 23 27 42 52 78 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:14] 91 24 31 57 56 82 36 20 42 27 ... #>   .. .. ..$ : num [1:11] 87 53 51 84 61 95 99 10 77 11 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:8] 95 84 48 3 66 12 79 20 #>   .. .. ..$ : num [1:17] 90 75 56 71 73 80 10 43 41 8 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:14] 58 32 64 20 6 95 48 85 23 40 ... #>   .. .. ..$ : num [1:11] 37 26 81 71 96 49 0 73 1 87 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:9] 95 85 14 91 16 15 76 36 57 #>   .. .. ..$ : num [1:16] 71 87 89 49 81 26 99 25 96 83 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:21] 15 1 2 67 88 13 97 53 71 3 ... #>   .. .. ..$ : num [1:4] 38 10 8 65 #>   .. ..$ :List of 1 #>   .. .. ..$ : num [1:25] 81 37 1 22 68 12 44 63 89 14 ... #>   .. ..$ :List of 1 #>   .. .. ..$ : num [1:25] 45 76 54 72 32 90 42 49 12 63 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:19] 23 64 36 12 6 32 58 19 34 54 ... #>   .. .. ..$ : num [1:6] 18 75 22 98 86 90 #>   .. ..$ :List of 1 #>   .. .. ..$ : num [1:25] 2 76 4 15 66 38 42 17 8 75 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 9 72 80 20 93 71 76 #>   .. .. ..$ : num [1:18] 54 11 3 66 69 84 26 44 0 96 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:8] 86 17 55 93 60 26 29 76 #>   .. .. ..$ : num [1:17] 53 48 50 52 14 38 18 21 64 5 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:11] 46 64 29 58 52 33 93 66 3 6 ... #>   .. .. ..$ : num [1:14] 99 37 27 25 86 49 90 0 71 60 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:11] 40 14 31 77 88 45 59 39 92 49 ... #>   .. .. ..$ : num [1:14] 84 30 75 50 4 52 37 56 80 19 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:14] 72 64 6 19 14 42 17 53 3 60 ... #>   .. .. ..$ : num [1:11] 54 50 11 84 13 79 77 92 1 67 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:16] 58 6 32 36 19 42 66 74 76 5 ... #>   .. .. ..$ : num [1:9] 45 69 37 83 28 22 11 99 77 #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:11] 40 17 30 25 65 88 78 43 28 19 ... #>   .. .. ..$ : num [1:14] 1 67 95 11 13 81 58 36 37 79 ... #>   .. ..$ :List of 1 #>   .. .. ..$ : num [1:25] 83 5 78 84 61 42 35 28 44 7 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:14] 43 96 10 49 66 44 19 82 89 40 ... #>   .. .. ..$ : num [1:11] 0 5 69 52 21 51 98 55 27 42 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:8] 12 75 79 69 24 55 29 41 #>   .. .. ..$ : num [1:17] 90 44 52 65 39 49 0 37 2 70 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:17] 34 12 88 71 54 32 70 42 29 79 ... #>   .. .. ..$ : num [1:8] 68 0 90 87 83 69 65 80 #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:11] 91 20 29 14 76 64 34 44 16 39 ... #>   .. .. ..$ : num [1:14] 45 89 13 99 72 75 8 47 83 51 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:12] 20 30 45 60 26 17 55 34 16 64 ... #>   .. .. ..$ : num [1:13] 69 89 36 57 76 27 85 0 98 24 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:13] 9 61 88 5 93 45 42 81 39 73 ... #>   .. .. ..$ : num [1:12] 98 48 65 12 55 53 68 28 13 80 ... #>   .. ..$ :List of 1 #>   .. .. ..$ : num [1:25] 26 30 81 61 79 90 68 55 83 64 ... #>   .. ..$ :List of 1 #>   .. .. ..$ : num [1:25] 11 94 62 43 39 56 85 28 53 64 ... #>   .. ..$ :List of 1 #>   .. .. ..$ : num [1:25] 62 87 85 30 32 53 96 88 70 33 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:17] 48 95 49 81 19 88 53 32 87 65 ... #>   .. .. ..$ : num [1:8] 75 3 69 11 42 22 12 31 #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:10] 48 14 19 83 81 71 63 49 89 53 #>   .. .. ..$ : num [1:15] 74 87 77 42 96 75 3 26 11 12 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:11] 24 15 44 16 6 42 2 19 58 5 ... #>   .. .. ..$ : num [1:14] 10 87 90 81 83 45 62 47 17 43 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:12] 42 3 19 66 6 67 24 5 54 14 ... #>   .. .. ..$ : num [1:13] 26 83 69 21 96 99 89 87 65 72 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:8] 26 56 78 21 45 86 17 2 #>   .. .. ..$ : num [1:17] 76 36 37 41 57 47 50 0 90 23 ... #>   .. ..$ :List of 1 #>   .. .. ..$ : num [1:25] 90 27 15 66 31 8 50 80 5 83 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:11] 35 33 14 92 39 50 70 58 74 15 ... #>   .. .. ..$ : num [1:14] 49 98 51 18 53 10 86 38 8 77 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:17] 40 1 54 74 4 60 91 33 94 15 ... #>   .. .. ..$ : num [1:8] 98 0 51 18 86 77 13 81 #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:19] 57 92 42 95 88 24 58 36 40 14 ... #>   .. .. ..$ : num [1:6] 49 56 81 83 31 28 #>   .. ..$ :List of 1 #>   .. .. ..$ : num [1:25] 91 56 1 36 35 70 19 74 75 34 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:11] 53 93 82 49 15 30 65 63 72 95 ... #>   .. .. ..$ : num [1:14] 85 3 41 94 8 46 99 24 43 98 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:9] 27 47 0 91 82 18 8 64 9 #>   .. .. ..$ : num [1:16] 3 53 65 85 19 37 38 15 46 33 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:14] 13 45 79 72 48 34 39 95 71 47 ... #>   .. .. ..$ : num [1:11] 31 46 26 64 66 27 59 61 51 97 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:20] 51 57 55 27 71 39 29 69 45 92 ... #>   .. .. ..$ : num [1:5] 66 1 48 4 50 #>   .. ..$ :List of 1 #>   .. .. ..$ : num [1:25] 50 71 6 13 44 35 97 9 42 79 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:14] 64 12 58 24 97 42 63 35 76 33 ... #>   .. .. ..$ : num [1:11] 26 38 60 28 51 13 8 27 9 18 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:14] 20 94 35 57 30 79 46 78 70 48 ... #>   .. .. ..$ : num [1:11] 1 18 49 26 81 47 8 41 28 51 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 41 15 78 8 49 94 2 #>   .. .. ..$ : num [1:18] 60 52 25 3 84 99 48 23 43 65 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:15] 82 57 19 91 40 72 64 5 3 58 ... #>   .. .. ..$ : num [1:10] 56 83 87 99 75 96 65 69 77 38 #>   .. .. [list output truncated] #>   ..$ _split_vars             :List of 100 #>   .. ..$ : num [1:3] 2 0 0 #>   .. ..$ : num [1:3] 4 0 0 #>   .. ..$ : num [1:3] 4 0 0 #>   .. ..$ : num [1:3] 3 0 0 #>   .. ..$ : num [1:3] 2 0 0 #>   .. ..$ : num [1:3] 0 0 0 #>   .. ..$ : num [1:3] 2 0 0 #>   .. ..$ : num [1:3] 0 0 0 #>   .. ..$ : num [1:3] 4 0 0 #>   .. ..$ : num [1:3] 0 0 0 #>   .. ..$ : num [1:3] 3 0 0 #>   .. ..$ : num [1:3] 0 0 0 #>   .. ..$ : num [1:3] 3 0 0 #>   .. ..$ : num [1:3] 3 0 0 #>   .. ..$ : num 0 #>   .. ..$ : num [1:3] 1 0 0 #>   .. ..$ : num [1:3] 0 0 0 #>   .. ..$ : num 0 #>   .. ..$ : num [1:3] 2 0 0 #>   .. ..$ : num [1:3] 1 0 0 #>   .. ..$ : num [1:3] 1 0 0 #>   .. ..$ : num [1:3] 0 0 0 #>   .. ..$ : num [1:3] 0 0 0 #>   .. ..$ : num 0 #>   .. ..$ : num [1:3] 0 0 0 #>   .. ..$ : num [1:3] 2 0 0 #>   .. ..$ : num [1:3] 2 0 0 #>   .. ..$ : num [1:3] 1 0 0 #>   .. ..$ : num [1:3] 1 0 0 #>   .. ..$ : num [1:3] 2 0 0 #>   .. ..$ : num [1:3] 3 0 0 #>   .. ..$ : num [1:3] 3 0 0 #>   .. ..$ : num [1:3] 1 0 0 #>   .. ..$ : num 0 #>   .. ..$ : num [1:3] 1 0 0 #>   .. ..$ : num [1:3] 1 0 0 #>   .. ..$ : num [1:3] 0 0 0 #>   .. ..$ : num 0 #>   .. ..$ : num [1:3] 1 0 0 #>   .. ..$ : num [1:3] 1 0 0 #>   .. ..$ : num [1:3] 2 0 0 #>   .. ..$ : num [1:3] 4 0 0 #>   .. ..$ : num [1:3] 2 0 0 #>   .. ..$ : num [1:3] 0 0 0 #>   .. ..$ : num [1:3] 0 0 0 #>   .. ..$ : num [1:3] 0 0 0 #>   .. ..$ : num [1:3] 1 0 0 #>   .. ..$ : num [1:3] 0 0 0 #>   .. ..$ : num 0 #>   .. ..$ : num [1:3] 0 0 0 #>   .. ..$ : num [1:3] 1 0 0 #>   .. ..$ : num [1:3] 1 0 0 #>   .. ..$ : num [1:3] 0 0 0 #>   .. ..$ : num [1:3] 3 0 0 #>   .. ..$ : num [1:3] 2 0 0 #>   .. ..$ : num [1:3] 0 0 0 #>   .. ..$ : num [1:3] 0 0 0 #>   .. ..$ : num [1:3] 0 0 0 #>   .. ..$ : num [1:3] 0 0 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num [1:3] 0 0 0 #>   .. ..$ : num 0 #>   .. ..$ : num [1:3] 3 0 0 #>   .. ..$ : num [1:3] 2 0 0 #>   .. ..$ : num [1:3] 0 0 0 #>   .. ..$ : num [1:3] 1 0 0 #>   .. ..$ : num [1:3] 4 0 0 #>   .. ..$ : num [1:3] 0 0 0 #>   .. ..$ : num [1:3] 4 0 0 #>   .. ..$ : num 0 #>   .. ..$ : num [1:3] 3 0 0 #>   .. ..$ : num [1:3] 2 0 0 #>   .. ..$ : num [1:3] 0 0 0 #>   .. ..$ : num [1:3] 0 0 0 #>   .. ..$ : num [1:3] 4 0 0 #>   .. ..$ : num [1:3] 1 0 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num 0 #>   .. ..$ : num [1:3] 3 0 0 #>   .. ..$ : num [1:3] 3 0 0 #>   .. ..$ : num [1:3] 0 0 0 #>   .. ..$ : num [1:3] 0 0 0 #>   .. ..$ : num [1:3] 4 0 0 #>   .. ..$ : num 0 #>   .. ..$ : num [1:3] 0 0 0 #>   .. ..$ : num [1:3] 0 0 0 #>   .. ..$ : num [1:3] 0 0 0 #>   .. ..$ : num 0 #>   .. ..$ : num [1:3] 3 0 0 #>   .. ..$ : num [1:3] 1 0 0 #>   .. ..$ : num [1:3] 3 0 0 #>   .. ..$ : num [1:3] 1 0 0 #>   .. ..$ : num 0 #>   .. ..$ : num [1:3] 0 0 0 #>   .. ..$ : num [1:3] 0 0 0 #>   .. ..$ : num [1:3] 1 0 0 #>   .. ..$ : num [1:3] 0 0 0 #>   .. .. [list output truncated] #>   ..$ _split_values           :List of 100 #>   .. ..$ : num [1:3] -0.118 -1 -1 #>   .. ..$ : num [1:3] -0.479 -1 -1 #>   .. ..$ : num [1:3] 0.0645 -1 -1 #>   .. ..$ : num [1:3] 0.337 -1 -1 #>   .. ..$ : num [1:3] 0.0609 -1 -1 #>   .. ..$ : num [1:3] -0.247 -1 -1 #>   .. ..$ : num [1:3] -0.752 -1 -1 #>   .. ..$ : num [1:3] 0.556 -1 -1 #>   .. ..$ : num [1:3] -0.368 -1 -1 #>   .. ..$ : num [1:3] 0.112 -1 -1 #>   .. ..$ : num [1:3] 0.072 -1 -1 #>   .. ..$ : num [1:3] -0.156 -1 -1 #>   .. ..$ : num [1:3] 0.337 -1 -1 #>   .. ..$ : num [1:3] 0.559 -1 -1 #>   .. ..$ : num -1 #>   .. ..$ : num [1:3] 0.427 -1 -1 #>   .. ..$ : num [1:3] 0.0192 -1 -1 #>   .. ..$ : num -1 #>   .. ..$ : num [1:3] -0.0709 -1 -1 #>   .. ..$ : num [1:3] 0.108 -1 -1 #>   .. ..$ : num [1:3] 0.518 -1 -1 #>   .. ..$ : num [1:3] -0.244 -1 -1 #>   .. ..$ : num [1:3] -0.00557 -1 -1 #>   .. ..$ : num -1 #>   .. ..$ : num [1:3] 0.363 -1 -1 #>   .. ..$ : num [1:3] 0.0655 -1 -1 #>   .. ..$ : num [1:3] 0.00789 -1 -1 #>   .. ..$ : num [1:3] 0.449 -1 -1 #>   .. ..$ : num [1:3] -0.474 -1 -1 #>   .. ..$ : num [1:3] -0.308 -1 -1 #>   .. ..$ : num [1:3] 0.393 -1 -1 #>   .. ..$ : num [1:3] 0.0208 -1 -1 #>   .. ..$ : num [1:3] -0.103 -1 -1 #>   .. ..$ : num -1 #>   .. ..$ : num [1:3] -0.356 -1 -1 #>   .. ..$ : num [1:3] 0.427 -1 -1 #>   .. ..$ : num [1:3] 0.363 -1 -1 #>   .. ..$ : num -1 #>   .. ..$ : num [1:3] 0.133 -1 -1 #>   .. ..$ : num [1:3] 0.259 -1 -1 #>   .. ..$ : num [1:3] 0.112 -1 -1 #>   .. ..$ : num [1:3] -0.368 -1 -1 #>   .. ..$ : num [1:3] -0.0103 -1 -1 #>   .. ..$ : num [1:3] 0.524 -1 -1 #>   .. ..$ : num [1:3] 0.244 -1 -1 #>   .. ..$ : num [1:3] 0.07 -1 -1 #>   .. ..$ : num [1:3] 0.427 -1 -1 #>   .. ..$ : num [1:3] 0.434 -1 -1 #>   .. ..$ : num -1 #>   .. ..$ : num [1:3] 0.07 -1 -1 #>   .. ..$ : num [1:3] 0.604 -1 -1 #>   .. ..$ : num [1:3] 0.429 -1 -1 #>   .. ..$ : num [1:3] -0.016 -1 -1 #>   .. ..$ : num [1:3] 0.199 -1 -1 #>   .. ..$ : num [1:3] -0.0779 -1 -1 #>   .. ..$ : num [1:3] -0.0526 -1 -1 #>   .. ..$ : num [1:3] 0.118 -1 -1 #>   .. ..$ : num [1:3] 0.0465 -1 -1 #>   .. ..$ : num [1:3] 0.468 -1 -1 #>   .. ..$ : num -1 #>   .. ..$ : num -1 #>   .. ..$ : num [1:3] 0.176 -1 -1 #>   .. ..$ : num -1 #>   .. ..$ : num [1:3] -0.344 -1 -1 #>   .. ..$ : num [1:3] -0.341 -1 -1 #>   .. ..$ : num [1:3] -0.00557 -1 -1 #>   .. ..$ : num [1:3] 0.192 -1 -1 #>   .. ..$ : num [1:3] -0.264 -1 -1 #>   .. ..$ : num [1:3] 0.176 -1 -1 #>   .. ..$ : num [1:3] -0.262 -1 -1 #>   .. ..$ : num -1 #>   .. ..$ : num [1:3] 0.408 -1 -1 #>   .. ..$ : num [1:3] -0.341 -1 -1 #>   .. ..$ : num [1:3] 0.424 -1 -1 #>   .. ..$ : num [1:3] 0.255 -1 -1 #>   .. ..$ : num [1:3] -0.323 -1 -1 #>   .. ..$ : num [1:3] 0.122 -1 -1 #>   .. ..$ : num -1 #>   .. ..$ : num -1 #>   .. ..$ : num -1 #>   .. ..$ : num [1:3] 0.337 -1 -1 #>   .. ..$ : num [1:3] -0.105 -1 -1 #>   .. ..$ : num [1:3] 0.0465 -1 -1 #>   .. ..$ : num [1:3] 0.176 -1 -1 #>   .. ..$ : num [1:3] -0.489 -1 -1 #>   .. ..$ : num -1 #>   .. ..$ : num [1:3] 0.172 -1 -1 #>   .. ..$ : num [1:3] 0.244 -1 -1 #>   .. ..$ : num [1:3] 0.244 -1 -1 #>   .. ..$ : num -1 #>   .. ..$ : num [1:3] -0.105 -1 -1 #>   .. ..$ : num [1:3] -0.163 -1 -1 #>   .. ..$ : num [1:3] 0.344 -1 -1 #>   .. ..$ : num [1:3] 0.376 -1 -1 #>   .. ..$ : num -1 #>   .. ..$ : num [1:3] 0.07 -1 -1 #>   .. ..$ : num [1:3] 0.176 -1 -1 #>   .. ..$ : num [1:3] 0.0673 -1 -1 #>   .. ..$ : num [1:3] 0.424 -1 -1 #>   .. .. [list output truncated] #>   ..$ _drawn_samples          :List of 100 #>   .. ..$ : num [1:50] 38 35 31 12 81 33 43 6 9 72 ... #>   .. ..$ : num [1:50] 98 44 11 56 16 43 33 38 81 93 ... #>   .. ..$ : num [1:50] 40 29 92 94 63 13 37 76 93 47 ... #>   .. ..$ : num [1:50] 17 1 47 21 52 56 8 51 18 24 ... #>   .. ..$ : num [1:50] 21 52 56 67 55 4 60 44 66 6 ... #>   .. ..$ : num [1:50] 77 79 80 47 21 6 85 87 22 88 ... #>   .. ..$ : num [1:50] 92 96 20 84 45 54 79 15 89 42 ... #>   .. ..$ : num [1:50] 98 42 39 45 40 3 21 4 13 82 ... #>   .. ..$ : num [1:50] 29 96 59 94 61 56 75 17 38 41 ... #>   .. ..$ : num [1:50] 26 49 50 33 71 75 48 76 67 66 ... #>   .. ..$ : num [1:50] 52 0 18 42 3 23 21 75 96 43 ... #>   .. ..$ : num [1:50] 80 23 0 18 61 98 33 35 24 11 ... #>   .. ..$ : num [1:50] 21 63 24 38 70 67 61 74 75 58 ... #>   .. ..$ : num [1:50] 9 85 39 74 88 24 99 51 38 58 ... #>   .. ..$ : num [1:50] 64 12 94 87 59 1 68 0 52 74 ... #>   .. ..$ : num [1:50] 56 1 43 24 94 69 31 96 0 32 ... #>   .. ..$ : num [1:50] 57 27 56 82 41 77 45 21 91 72 ... #>   .. ..$ : num [1:50] 73 78 45 8 33 82 88 13 65 66 ... #>   .. ..$ : num [1:50] 14 66 45 7 80 64 40 21 6 8 ... #>   .. ..$ : num [1:50] 22 52 49 77 35 38 83 92 27 66 ... #>   .. ..$ : num [1:50] 53 87 45 1 21 32 30 56 50 16 ... #>   .. ..$ : num [1:50] 37 74 53 88 58 35 9 55 56 43 ... #>   .. ..$ : num [1:50] 45 61 13 11 80 95 36 4 19 56 ... #>   .. ..$ : num [1:50] 27 49 5 20 62 97 51 45 34 80 ... #>   .. ..$ : num [1:50] 66 13 61 57 45 41 15 51 83 73 ... #>   .. ..$ : num [1:50] 36 39 28 34 8 51 78 45 81 13 ... #>   .. ..$ : num [1:50] 38 5 86 6 13 47 95 25 88 59 ... #>   .. ..$ : num [1:50] 58 60 29 23 75 9 54 63 3 11 ... #>   .. ..$ : num [1:50] 95 57 52 19 1 55 87 37 34 80 ... #>   .. ..$ : num [1:50] 77 10 51 4 84 16 40 39 86 19 ... #>   .. ..$ : num [1:50] 23 36 11 54 58 70 39 3 49 41 ... #>   .. ..$ : num [1:50] 68 55 39 59 78 23 80 65 31 11 ... #>   .. ..$ : num [1:50] 43 15 85 12 59 11 52 81 55 0 ... #>   .. ..$ : num [1:50] 99 34 56 94 43 7 2 37 6 70 ... #>   .. ..$ : num [1:50] 48 32 54 14 96 31 52 51 20 39 ... #>   .. ..$ : num [1:50] 32 86 2 81 12 64 48 90 93 29 ... #>   .. ..$ : num [1:50] 48 90 17 38 70 14 91 71 8 58 ... #>   .. ..$ : num [1:50] 32 86 91 11 65 13 40 20 49 21 ... #>   .. ..$ : num [1:50] 52 54 95 29 21 61 80 66 42 67 ... #>   .. ..$ : num [1:50] 91 25 89 9 61 99 54 14 80 42 ... #>   .. ..$ : num [1:50] 13 93 52 41 19 89 15 83 17 61 ... #>   .. ..$ : num [1:50] 36 61 15 1 64 95 7 9 46 16 ... #>   .. ..$ : num [1:50] 18 65 23 53 28 40 99 87 68 44 ... #>   .. ..$ : num [1:50] 97 81 32 86 56 35 44 60 5 26 ... #>   .. ..$ : num [1:50] 59 89 61 47 45 14 51 2 3 70 ... #>   .. ..$ : num [1:50] 91 73 89 68 2 70 79 48 76 26 ... #>   .. ..$ : num [1:50] 88 10 23 8 21 77 6 70 13 2 ... #>   .. ..$ : num [1:50] 12 11 77 63 95 1 4 13 62 93 ... #>   .. ..$ : num [1:50] 87 11 68 69 90 24 3 93 8 78 ... #>   .. ..$ : num [1:50] 69 16 77 62 93 47 40 4 87 24 ... #>   .. ..$ : num [1:50] 4 13 43 7 15 65 18 22 62 99 ... #>   .. ..$ : num [1:50] 62 29 97 90 50 17 92 76 45 47 ... #>   .. ..$ : num [1:50] 62 66 35 78 94 4 18 96 27 90 ... #>   .. ..$ : num [1:50] 35 73 79 3 92 76 89 11 66 29 ... #>   .. ..$ : num [1:50] 80 81 36 21 48 8 51 54 16 75 ... #>   .. ..$ : num [1:50] 99 77 73 3 40 64 95 9 0 74 ... #>   .. ..$ : num [1:50] 6 75 41 20 72 17 95 65 85 73 ... #>   .. ..$ : num [1:50] 95 6 16 81 29 48 69 87 30 75 ... #>   .. ..$ : num [1:50] 71 8 90 15 93 95 2 34 76 24 ... #>   .. ..$ : num [1:50] 31 81 90 68 95 70 29 65 2 77 ... #>   .. ..$ : num [1:50] 65 15 93 54 53 61 77 25 6 36 ... #>   .. ..$ : num [1:50] 41 74 60 65 35 46 77 73 25 36 ... #>   .. ..$ : num [1:50] 38 20 19 0 14 2 59 75 26 70 ... #>   .. ..$ : num [1:50] 66 23 57 2 72 17 8 50 21 77 ... #>   .. ..$ : num [1:50] 53 26 17 86 48 73 52 93 18 89 ... #>   .. ..$ : num [1:50] 37 96 53 91 11 87 46 0 90 33 ... #>   .. ..$ : num [1:50] 17 9 75 39 56 52 99 59 71 66 ... #>   .. ..$ : num [1:50] 52 79 75 12 88 17 50 66 59 45 ... #>   .. ..$ : num [1:50] 37 30 44 42 45 1 76 87 77 78 ... #>   .. ..$ : num [1:50] 11 30 63 58 24 37 69 22 19 52 ... #>   .. ..$ : num [1:50] 46 72 40 51 27 83 21 56 17 19 ... #>   .. ..$ : num [1:50] 46 40 43 5 7 37 49 12 27 81 ... #>   .. ..$ : num [1:50] 9 83 35 78 75 24 31 33 79 71 ... #>   .. ..$ : num [1:50] 3 44 32 39 42 69 29 55 78 57 ... #>   .. ..$ : num [1:50] 4 18 64 51 56 98 20 75 31 47 ... #>   .. ..$ : num [1:50] 55 99 64 29 58 14 72 45 89 27 ... #>   .. ..$ : num [1:50] 54 25 26 76 52 36 65 89 47 46 ... #>   .. ..$ : num [1:50] 5 91 76 93 74 61 36 71 54 13 ... #>   .. ..$ : num [1:50] 17 95 15 66 38 12 44 99 9 85 ... #>   .. ..$ : num [1:50] 95 79 90 12 28 69 56 54 93 3 ... #>   .. ..$ : num [1:50] 14 48 87 31 75 54 28 15 33 7 ... #>   .. ..$ : num [1:50] 89 15 88 44 48 96 77 7 28 9 ... #>   .. ..$ : num [1:50] 52 16 22 47 20 3 92 98 57 28 ... #>   .. ..$ : num [1:50] 0 54 44 89 74 10 39 65 24 84 ... #>   .. ..$ : num [1:50] 21 49 42 31 60 54 95 29 46 30 ... #>   .. ..$ : num [1:50] 49 5 56 37 21 54 42 26 14 76 ... #>   .. ..$ : num [1:50] 8 51 61 39 32 15 98 40 97 49 ... #>   .. ..$ : num [1:50] 18 21 14 13 59 33 77 49 79 98 ... #>   .. ..$ : num [1:50] 99 87 59 96 77 49 74 31 66 70 ... #>   .. ..$ : num [1:50] 5 57 6 59 24 56 92 15 19 9 ... #>   .. ..$ : num [1:50] 21 82 40 18 9 98 46 63 0 83 ... #>   .. ..$ : num [1:50] 3 93 15 7 94 88 9 22 19 49 ... #>   .. ..$ : num [1:50] 92 50 79 69 46 68 58 39 59 32 ... #>   .. ..$ : num [1:50] 43 90 47 20 34 32 11 26 9 71 ... #>   .. ..$ : num [1:50] 12 50 35 34 93 53 67 8 95 33 ... #>   .. ..$ : num [1:50] 36 99 96 28 8 67 62 18 16 27 ... #>   .. ..$ : num [1:50] 20 47 63 41 17 48 57 34 18 2 ... #>   .. ..$ : num [1:50] 34 15 49 65 38 22 82 51 78 99 ... #>   .. ..$ : num [1:50] 39 86 75 87 62 23 13 96 8 30 ... #>   .. .. [list output truncated] #>   ..$ _send_missing_left      :List of 100 #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi TRUE #>   .. ..$ : logi TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi TRUE #>   .. ..$ : logi TRUE #>   .. ..$ : logi TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. ..$ : logi [1:3] TRUE TRUE TRUE #>   .. .. [list output truncated] #>   ..$ _pv_values              :List of 100 #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.1434 -0.2106 -0.2106 -0.0856 0.2587 ... #>   .. .. ..$ : num [1:7] 0.1616 0.0373 0.0373 0.2264 0.2705 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.6 -0.175 -0.175 0.226 0.298 ... #>   .. .. ..$ : num [1:7] 0.0253 -0.1244 -0.1244 0.0712 0.2635 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.4359 -0.0281 -0.0281 -0.0255 0.2743 ... #>   .. .. ..$ : num [1:7] -0.4072 0.0124 0.0124 -0.0373 0.2478 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.093 0.086 0.086 0.0512 0.2665 ... #>   .. .. ..$ : num [1:7] -0.131 0.369 0.369 -0.359 0.287 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.283 0.154 0.154 0.187 0.281 ... #>   .. .. ..$ : num [1:7] 0.1205 0.0123 0.0123 -0.1004 0.2563 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] -0.137 0.137 0.137 -0.234 0.208 ... #>   .. .. ..$ : num [1:7] 0.0188 0.0851 0.0851 0.0074 0.2602 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.5369 -0.146 -0.146 -0.0117 0.2712 ... #>   .. .. ..$ : num [1:7] -0.157 -0.147 -0.147 0.112 0.25 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.2483 -0.1215 -0.1215 -0.0178 0.2653 ... #>   .. .. ..$ : num [1:7] -0.163 0.132 0.132 0.044 0.281 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.0735 -0.0312 -0.0312 -0.1274 0.2736 ... #>   .. .. ..$ : num [1:7] -0.0507 0.0802 0.0802 0.0785 0.2524 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.1 0.143 0.143 -0.13 0.261 ... #>   .. .. ..$ : num [1:7] -0.227 -0.0169 -0.0169 0.1358 0.2472 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.00532 -0.18847 -0.18847 -0.01481 0.23083 ... #>   .. .. ..$ : num [1:7] -0.4153 -0.2061 -0.2061 -0.0864 0.2705 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] -0.5007 -0.1714 -0.1714 0.0625 0.259 ... #>   .. .. ..$ : num [1:7] -0.088 -0.1313 -0.1313 -0.0434 0.248 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.0566 0.155 0.155 0.0704 0.236 ... #>   .. .. ..$ : num [1:7] -0.3628 0.0456 0.0456 -0.0648 0.3231 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.0635 0.132 0.132 0.0597 0.2513 ... #>   .. .. ..$ : num [1:7] 0.312 0.164 0.164 0.274 0.297 ... #>   .. ..$ :List of 1 #>   .. .. ..$ : num [1:7] 0.0987 -0.052 -0.052 0.1134 0.261 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.5017 0.0587 0.0587 0.0437 0.2645 ... #>   .. .. ..$ : num [1:7] 0.27 0.141 0.141 0.174 0.226 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.3428 0.0475 0.0475 -0.2269 0.2681 ... #>   .. .. ..$ : num [1:7] -0.386624 -0.038608 -0.038608 0.000421 0.271994 ... #>   .. ..$ :List of 1 #>   .. .. ..$ : num [1:7] 0.33512 -0.07353 -0.07353 -0.00189 0.26369 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.362 -0.213 -0.213 -0.192 0.262 ... #>   .. .. ..$ : num [1:7] 0.0422 0.2217 0.2217 -0.0312 0.2391 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.256 0.0651 0.0651 0.0559 0.2701 ... #>   .. .. ..$ : num [1:7] 0.1232 0.0491 0.0491 -0.0965 0.2532 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] -0.0122 0.0532 0.0532 -0.1579 0.2809 ... #>   .. .. ..$ : num [1:7] -0.071 -0.257 -0.257 0.148 0.28 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.285 0.013 0.013 -0.36 0.261 ... #>   .. .. ..$ : num [1:7] 0.18211 0.00624 0.00624 -0.09823 0.25469 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] -0.1411 -0.0856 -0.0856 0.2372 0.2556 ... #>   .. .. ..$ : num [1:7] -0.11206 0.13994 0.13994 0.00914 0.2775 ... #>   .. ..$ :List of 1 #>   .. .. ..$ : num [1:7] -0.18888 0.13044 0.13044 0.00613 0.24482 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.07789 -0.12131 -0.12131 -0.00407 0.27233 ... #>   .. .. ..$ : num [1:7] -0.5053 -0.0324 -0.0324 0.0621 0.2785 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] -0.0164 -0.0126 -0.0126 -0.0951 0.241 ... #>   .. .. ..$ : num [1:7] -0.3475 -0.0799 -0.0799 0.1586 0.2471 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] -0.00292 -0.1469 -0.1469 0.1695 0.23999 ... #>   .. .. ..$ : num [1:7] 0.069782 -0.000126 -0.000126 0.043476 0.247289 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.13051 0.08542 0.08542 -0.00868 0.24723 ... #>   .. .. ..$ : num [1:7] 0.1217 -0.2042 -0.2042 0.0107 0.2377 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.2682 -0.0303 -0.0303 -0.0124 0.2998 ... #>   .. .. ..$ : num [1:7] -0.0847 -0.1186 -0.1186 0.0755 0.2418 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.35 0.177 0.177 0.135 0.287 ... #>   .. .. ..$ : num [1:7] -0.1774 -0.0477 -0.0477 -0.0665 0.2469 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] -0.2086 -0.0352 -0.0352 -0.099 0.2604 ... #>   .. .. ..$ : num [1:7] 0.1494 -0.1744 -0.1744 -0.0491 0.2932 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] -0.0937 0.1195 0.1195 -0.0953 0.2453 ... #>   .. .. ..$ : num [1:7] -0.2555 -0.0744 -0.0744 0.0236 0.2843 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] -0.1891 0.0861 0.0861 -0.1655 0.2727 ... #>   .. .. ..$ : num [1:7] -0.1163 -0.0871 -0.0871 0.2171 0.264 ... #>   .. ..$ :List of 1 #>   .. .. ..$ : num [1:7] -0.297 0.1708 0.1708 -0.0269 0.2354 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.319 -0.0463 -0.0463 -0.2839 0.2803 ... #>   .. .. ..$ : num [1:7] -0.3788 -0.0457 -0.0457 -0.0509 0.2643 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.0811 0.0789 0.0789 0.0211 0.2738 ... #>   .. .. ..$ : num [1:7] -0.9136 -0.0681 -0.0681 0.2144 0.2568 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.07215 -0.00358 -0.00358 -0.06436 0.27236 ... #>   .. .. ..$ : num [1:7] 0.38 0.173 0.173 0.323 0.275 ... #>   .. ..$ :List of 1 #>   .. .. ..$ : num [1:7] 0.1496 -0.0498 -0.0498 0.1231 0.2756 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.3115 0.0369 0.0369 0.0424 0.2886 ... #>   .. .. ..$ : num [1:7] -0.6055 0.0834 0.0834 -0.1047 0.2191 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.320212 0.040369 0.040369 0.000657 0.264658 ... #>   .. .. ..$ : num [1:7] -0.0359 -0.0429 -0.0429 0.1945 0.2513 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.2933 -0.0579 -0.0579 -0.0142 0.2544 ... #>   .. .. ..$ : num [1:7] -0.0794 -0.1119 -0.1119 0.0164 0.2599 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.2977 -0.0183 -0.0183 -0.1142 0.26 ... #>   .. .. ..$ : num [1:7] -0.11953 -0.09832 -0.09832 0.00601 0.2564 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] -0.181 0.124 0.124 -0.016 0.256 ... #>   .. .. ..$ : num [1:7] -0.1017 0.2074 0.2074 0.0553 0.2534 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] -0.2453 -0.0477 -0.0477 0.088 0.2628 ... #>   .. .. ..$ : num [1:7] -0.1571 0.2505 0.2505 -0.0195 0.2327 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] -0.162 0.0194 0.0194 -0.2 0.2557 ... #>   .. .. ..$ : num [1:7] -0.127 0.0355 0.0355 0.1246 0.2692 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.0557 -0.0681 -0.0681 -0.2782 0.2812 ... #>   .. .. ..$ : num [1:7] -0.579 0.105 0.105 0.082 0.253 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] -0.0236 0.0534 0.0534 -0.0865 0.2659 ... #>   .. .. ..$ : num [1:7] -0.541 0.167 0.167 -0.184 0.232 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] -0.05813 -0.00118 -0.00118 -0.31238 0.25002 ... #>   .. .. ..$ : num [1:7] -0.259 0.1575 0.1575 0.0419 0.2883 ... #>   .. ..$ :List of 1 #>   .. .. ..$ : num [1:7] -0.0723 0.1622 0.1622 -0.1906 0.2577 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] -0.147 -0.147 -0.147 -0.206 0.244 ... #>   .. .. ..$ : num [1:7] -0.0584 0.0075 0.0075 -0.0885 0.2528 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] -0.21198 0.00653 0.00653 0.04426 0.24045 ... #>   .. .. ..$ : num [1:7] -0.2251 -0.2601 -0.2601 0.0559 0.2331 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.684014 0.000903 0.000903 -0.135834 0.261857 ... #>   .. .. ..$ : num [1:7] -0.3293 -0.0824 -0.0824 0.1466 0.2537 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] -0.047 -0.155 -0.155 -0.198 0.27 ... #>   .. .. ..$ : num [1:7] -0.00826 0.24196 0.24196 0.10557 0.26012 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] -0.0023 0.0543 0.0543 -0.0516 0.2451 ... #>   .. .. ..$ : num [1:7] -0.0877 0.0492 0.0492 0.0299 0.2692 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.4313 -0.1403 -0.1403 -0.0738 0.2713 ... #>   .. .. ..$ : num [1:7] -0.3991 -0.0413 -0.0413 0.1585 0.2259 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.2092 -0.1641 -0.1641 -0.0101 0.2645 ... #>   .. .. ..$ : num [1:7] -0.101 -0.07 -0.07 0.142 0.274 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.2424 -0.0774 -0.0774 -0.247 0.2512 ... #>   .. .. ..$ : num [1:7] 0.1411 0.2438 0.2438 0.0474 0.2794 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] -0.061 0.0438 0.0438 -0.123 0.2773 ... #>   .. .. ..$ : num [1:7] 0.2601 -0.0357 -0.0357 0.1061 0.2293 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] -0.0174 -0.2038 -0.2038 -0.1081 0.2913 ... #>   .. .. ..$ : num [1:7] -0.3657 -0.0115 -0.0115 0.6287 0.3105 ... #>   .. ..$ :List of 1 #>   .. .. ..$ : num [1:7] -0.151 -0.0247 -0.0247 0.0997 0.2755 ... #>   .. ..$ :List of 1 #>   .. .. ..$ : num [1:7] 0.039 -0.0311 -0.0311 0.2737 0.2709 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.3079 -0.2607 -0.2607 0.0915 0.2807 ... #>   .. .. ..$ : num [1:7] -0.281 0.193 0.193 0.103 0.273 ... #>   .. ..$ :List of 1 #>   .. .. ..$ : num [1:7] -0.0407 0.0955 0.0955 -0.0265 0.2506 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] -0.0891 -0.24 -0.24 0.1725 0.2584 ... #>   .. .. ..$ : num [1:7] -0.0293 0.0214 0.0214 -0.205 0.2618 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.5816 -0.1006 -0.1006 0.0784 0.2591 ... #>   .. .. ..$ : num [1:7] 0.00782 0.22312 0.22312 -0.10291 0.26679 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.5206 -0.2007 -0.2007 -0.0741 0.2757 ... #>   .. .. ..$ : num [1:7] 0.1234 -0.0596 -0.0596 0.1997 0.2517 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.2418 -0.0606 -0.0606 -0.1878 0.268 ... #>   .. .. ..$ : num [1:7] -0.1779 -0.0247 -0.0247 -0.2202 0.2433 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.481 -0.1452 -0.1452 0.0851 0.2667 ... #>   .. .. ..$ : num [1:7] -0.35 0.11 0.11 -0.162 0.241 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.295 0.118 0.118 0.157 0.25 ... #>   .. .. ..$ : num [1:7] -0.2211 -0.045 -0.045 -0.0855 0.2421 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] -0.1829 -0.0979 -0.0979 -0.1224 0.2157 ... #>   .. .. ..$ : num [1:7] 0.0791 -0.1033 -0.1033 -0.0849 0.255 ... #>   .. ..$ :List of 1 #>   .. .. ..$ : num [1:7] 0.19424 0.13646 0.13646 0.00721 0.24229 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.0913 -0.1505 -0.1505 0.2721 0.2664 ... #>   .. .. ..$ : num [1:7] -0.12944 0.17027 0.17027 0.00202 0.2774 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] -0.14 0.00348 0.00348 0.24093 0.29438 ... #>   .. .. ..$ : num [1:7] 0.2361 0.0165 0.0165 -0.1712 0.2849 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.153 -0.186 -0.186 -0.198 0.291 ... #>   .. .. ..$ : num [1:7] 0.0948 0.1405 0.1405 -0.0393 0.2441 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.428 -0.348 -0.348 -0.248 0.287 ... #>   .. .. ..$ : num [1:7] -0.627 -0.221 -0.221 0.131 0.254 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.276 -0.3847 -0.3847 0.0224 0.2445 ... #>   .. .. ..$ : num [1:7] 0.0934 0.1072 0.1072 -0.0625 0.2662 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.2431 -0.058 -0.058 -0.0527 0.2623 ... #>   .. .. ..$ : num [1:7] -0.0646 0.0923 0.0923 0.1512 0.2782 ... #>   .. ..$ :List of 1 #>   .. .. ..$ : num [1:7] 0.1905 0.0987 0.0987 0.0433 0.2455 ... #>   .. ..$ :List of 1 #>   .. .. ..$ : num [1:7] 0.4114 0.0431 0.0431 -0.1235 0.2758 ... #>   .. ..$ :List of 1 #>   .. .. ..$ : num [1:7] 0.171 0.0472 0.0472 0.0164 0.2587 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.237 0.143 0.143 -0.018 0.257 ... #>   .. .. ..$ : num [1:7] 0.174 -0.14 -0.14 0.249 0.294 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.0508 0.0221 0.0221 0.1389 0.2508 ... #>   .. .. ..$ : num [1:7] 0.0127 0.0227 0.0227 0.0598 0.2685 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] -0.0945 0.029 0.029 -0.0364 0.2586 ... #>   .. .. ..$ : num [1:7] -0.179 0.0673 0.0673 0.2349 0.231 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.5913 -0.0178 -0.0178 -0.0182 0.2644 ... #>   .. .. ..$ : num [1:7] -0.36618 0.132671 0.132671 -0.000512 0.255963 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] -0.177 0.17 0.17 -0.133 0.265 ... #>   .. .. ..$ : num [1:7] -0.0474 -0.104 -0.104 0.013 0.2617 ... #>   .. ..$ :List of 1 #>   .. .. ..$ : num [1:7] -0.0844 -0.1482 -0.1482 -0.1062 0.2587 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.17712 -0.00182 -0.00182 -0.36857 0.24232 ... #>   .. .. ..$ : num [1:7] -0.2335 0.0897 0.0897 0.1864 0.2765 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.0761 0.0472 0.0472 -0.2607 0.252 ... #>   .. .. ..$ : num [1:7] -0.3197 0.1377 0.1377 0.0382 0.2496 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.0514 0.0258 0.0258 -0.1524 0.254 ... #>   .. .. ..$ : num [1:7] 0.442 0.358 0.358 0.154 0.263 ... #>   .. ..$ :List of 1 #>   .. .. ..$ : num [1:7] -0.098 -0.1401 -0.1401 -0.0548 0.2536 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] -0.0509 -0.0355 -0.0355 0.173 0.2508 ... #>   .. .. ..$ : num [1:7] 0.00194 0.13453 0.13453 0.02499 0.27838 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.0342 -0.0847 -0.0847 -0.2556 0.2816 ... #>   .. .. ..$ : num [1:7] 0.28422 0.00692 0.00692 -0.05958 0.25885 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] -0.138 -0.2345 -0.2345 0.0462 0.2486 ... #>   .. .. ..$ : num [1:7] 0.1353 -0.2393 -0.2393 -0.0199 0.2392 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] -0.0258 -0.1609 -0.1609 -0.026 0.2696 ... #>   .. .. ..$ : num [1:7] -0.0309 0.265 0.265 -0.1258 0.2168 ... #>   .. ..$ :List of 1 #>   .. .. ..$ : num [1:7] 0.02149 0.00541 0.00541 0.03591 0.26366 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.112 -0.184 -0.184 0.157 0.283 ... #>   .. .. ..$ : num [1:7] -0.2495 -0.0508 -0.0508 0.1312 0.2648 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.02079 -0.00497 -0.00497 -0.1303 0.24454 ... #>   .. .. ..$ : num [1:7] -0.227 0.162 0.162 0.196 0.281 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] -0.1716 0.367 0.367 0.0641 0.2971 ... #>   .. .. ..$ : num [1:7] -0.1606 -0.0407 -0.0407 0.1448 0.2398 ... #>   .. ..$ :List of 3 #>   .. .. ..$ : num(0)  #>   .. .. ..$ : num [1:7] 0.612 -0.237 -0.237 -0.199 0.295 ... #>   .. .. ..$ : num [1:7] 0.0457 0.1203 0.1203 0.205 0.2378 ... #>   .. .. [list output truncated] #>   ..$ _pv_num_types           : num 7 #>   ..$ predictions             : num [1:100, 1] 0.1017 0.0629 -0.0916 -0.1134 0.0676 ... #>   ..$ variance.estimates      : num[0 , 0 ]  #>   ..$ debiased.error          : num [1:100, 1] 0.0521 0.0654 0.6136 3.7177 1.6982 ... #>   ..$ excess.error            : num [1:100, 1] 0.00211 0.00225 0.00213 0.00569 0.00172 ... #>   ..$ seed                    : num 9.8e+08 #>   ..$ num.threads             : num 0 #>   ..$ ci.group.size           : num 2 #>   ..$ X.orig                  : num [1:100, 1:5] 0.9354 0.2134 -0.0381 -0.9358 -0.1557 ... #>   ..$ Y.orig                  : num [1:100] -0.527 0.234 -0.771 1.807 -1.437 ... #>   ..$ W.orig                  : num [1:100] 1 1 1 0 1 0 1 0 0 1 ... #>   ..$ Y.hat                   : num [1:100] -0.3849 -0.0265 -0.0267 -0.1986 -0.2333 ... #>   ..$ W.hat                   : num [1:100] 0.509 0.435 0.478 0.639 0.621 ... #>   ..$ clusters                : num(0)  #>   ..$ equalize.cluster.weights: logi FALSE #>   ..$ tunable.params          :List of 7 #>   .. ..$ sample.fraction     : num 0.5 #>   .. ..$ mtry                : num 5 #>   .. ..$ min.node.size       : num 5 #>   .. ..$ honesty.fraction    : num 0.5 #>   .. ..$ honesty.prune.leaves: logi TRUE #>   .. ..$ alpha               : num 0.05 #>   .. ..$ imbalance.penalty   : num 0 #>   ..$ has.missing.values      : logi FALSE #>   ..- attr(*, \"class\")= chr [1:2] \"causal_forest\" \"grf\" #>  $ policies          : num [1:100, 1:21] 0 0 0 0 0 0 0 0 0 0 ... #>  $ batch_indices     :List of 20 #>   ..$ 1 : int [1:5] 31 60 94 27 88 #>   ..$ 2 : int [1:5] 4 71 80 83 12 #>   ..$ 3 : int [1:5] 15 22 62 45 18 #>   ..$ 4 : int [1:5] 57 64 25 2 43 #>   ..$ 5 : int [1:5] 97 13 69 17 87 #>   ..$ 6 : int [1:5] 99 40 92 75 14 #>   ..$ 7 : int [1:5] 44 58 47 90 35 #>   ..$ 8 : int [1:5] 30 7 91 95 78 #>   ..$ 9 : int [1:5] 41 93 54 86 29 #>   ..$ 10: int [1:5] 6 36 61 100 67 #>   ..$ 11: int [1:5] 70 63 50 74 52 #>   ..$ 12: int [1:5] 9 73 66 39 33 #>   ..$ 13: int [1:5] 32 77 19 10 3 #>   ..$ 14: int [1:5] 48 85 42 46 96 #>   ..$ 15: int [1:5] 38 68 72 79 16 #>   ..$ 16: int [1:5] 56 11 81 28 59 #>   ..$ 17: int [1:5] 51 34 37 82 20 #>   ..$ 18: int [1:5] 55 5 84 65 89 #>   ..$ 19: int [1:5] 98 53 49 1 8 #>   ..$ 20: int [1:5] 26 24 23 21 76"},{"path":"https://yanisvdc.github.io/cramR/articles/cram_learning.html","id":"advanced-configuration","dir":"Articles","previous_headings":"","what":"üõ†Ô∏è Advanced Configuration","title":"Using cram_learning() for Sequential or Parallel Policy Training","text":"can plug custom training/prediction functions: can also provide advanced model_params like: neural networks:","code":"custom_fit <- function(X, Y, D) { ... } custom_predict <- function(model, X, D) { ... } list(num.trees = 200)  # for grf::causal_forest fnn_params <- list(   input_layer = list(units = 64, activation = 'relu', input_shape = c(ncol(X))),   layers = list(list(units = 32, activation = 'relu')),   output_layer = list(units = 1, activation = 'linear'),   compile_args = list(optimizer = 'adam', loss = 'mse'),   fit_params = list(epochs = 5, batch_size = 32, verbose = 0) )"},{"path":"https://yanisvdc.github.io/cramR/articles/cram_learning.html","id":"parallelization","dir":"Articles","previous_headings":"","what":"‚ö° Parallelization","title":"Using cram_learning() for Sequential or Parallel Policy Training","text":"Set parallelize_batch = TRUE enable foreach-based parallel training (e.g.¬†across 4 cores):","code":"learning_result <- cram_learning(   X, D, Y, batch,   model_type = \"s_learner\",   learner_type = \"ridge\",   parallelize_batch = TRUE,   n_cores = 4 )"},{"path":"https://yanisvdc.github.io/cramR/articles/cram_ml.html","id":"cram-ml","dir":"Articles","previous_headings":"","what":"Cram ML","title":"Cram ML","text":"article ‚ÄúIntroduction & Cram Policy Part 1‚Äù, introduced Cram method, enables simultaneous learning evaluation binary policy. section, extend framework machine learning tasks cram_ml() function.","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_ml.html","id":"output-of-cram-ml","dir":"Articles","previous_headings":"Cram ML","what":"Output of Cram ML","title":"Cram ML","text":"Cram ML outputs Expected Loss Estimate, refers following statistical quantity:R(œÄÃÇ)=ùîºXÃÉ‚àºD[L(XÃÉ,œÄÃÇ)], R(\\hat{\\pi}) = \\mathbb{E}_{\\tilde{X} \\sim D} \\left[ L(\\tilde{X}, \\hat{\\pi}) \\right],  Expected Loss Estimate represents average loss incurred model, trained given data sample, deployed across entire population. Cram framework, corresponds estimating learned model generalizes unseen data‚Äî.e., performs new observations XÃÉ\\tilde{X} drawn true data-generating distribution DD, independently training data. expected loss serves population-level performance metric (analogous policy value policy learning), Cram provides consistent, low-bias estimate quantity combining models trained sequential batches evaluating held-observations.","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_ml.html","id":"built-in-model","dir":"Articles","previous_headings":"Cram ML","what":"Built-in Model","title":"Cram ML","text":"illustrate use cram_ml(), begin generating synthetic dataset regression task. data consists three independent covariates continuous outcome. section illustrates use cram_ml() built-modeling options available cramR package. function integrates caret framework, allowing users specify learning algorithm, loss function, batching strategy evaluate model performance. Beyond caret, cram_ml() also supports fully custom model training, prediction, loss functions, making suitable virtually machine learning task ‚Äî including regression classification. cram_ml() function offers extensive flexibility loss_name caret_params arguments.","code":"set.seed(42) X_data <- data.frame(x1 = rnorm(100), x2 = rnorm(100), x3 = rnorm(100)) Y_data <- rnorm(100) data_df <- data.frame(X_data, Y = Y_data)"},{"path":"https://yanisvdc.github.io/cramR/articles/cram_ml.html","id":"loss_name-argument","dir":"Articles","previous_headings":"Cram ML > Built-in Model","what":"loss_name argument","title":"Cram ML","text":"loss_name argument specifies performance metric used evaluate model batch. Note Cram needs calculate individual losses (.e.¬†map data point prediction loss value) internally averaged across batches observations form Expected Loss Estimate. Depending task, losses interpreted follows: denote xix_i data point œÄÃÇk\\hat{\\pi}_k model trained first k batches data illustrate individual losses computed using built-loss names package.","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_ml.html","id":"regression-losses","dir":"Articles","previous_headings":"Cram ML > Built-in Model > loss_name argument","what":"Regression Losses","title":"Cram ML","text":"Squared Error (\"se\"):L(xi,œÄÃÇk)=(yÃÇ‚àíyi)2 L(x_i, \\hat{\\pi}_k) = (\\hat{y}_i - y_i)^2  Measures squared difference predicted actual outcomes. Absolute Error (\"ae\"):L(xi,œÄÃÇk)=|yÃÇ‚àíyi| L(x_i, \\hat{\\pi}_k) = |\\hat{y}_i - y_i|  Captures magnitude prediction error, regardless direction.","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_ml.html","id":"classification-losses","dir":"Articles","previous_headings":"Cram ML > Built-in Model > loss_name argument","what":"Classification Losses","title":"Cram ML","text":"Accuracy (\"accuracy\"):L(xi,œÄÃÇk)=1{yÃÇ=yi} L(x_i, \\hat{\\pi}_k) = 1\\{\\hat{y}_i = y_i\\}  performance metric loss - Cram allows define performance metric want estimate accuracy built-example. metric 1 correct predictions, 0 incorrect ones. Logarithmic Loss (\"logloss\"): \"logloss\" loss function measures well predicted class probabilities align true class labels. applies binary multiclass classification tasks. given observation ii, let: yi‚àà{c1,c2,‚Ä¶,cK}y_i \\\\{c_1, c_2, \\dots, c_K\\} true class label, pÃÇk(,c)\\hat{p}_k(, c) predicted probability assigned class cc model. individual log loss computed : L(xi,œÄÃÇk)=‚àílog(pÃÇk(,yi)) L(x_i, \\hat{\\pi}_k) = -\\log\\left( \\hat{p}_k(, y_i) \\right)  , take negative log probability assigned true class.","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_ml.html","id":"custom-loss-functions","dir":"Articles","previous_headings":"Cram ML > Built-in Model > loss_name argument","what":"Custom Loss Functions","title":"Cram ML","text":"Users can also define custom loss function providing custom_loss(predictions, data) function returns vector individual losses. allows evaluation complex models domain-specific metrics (details Custom Model part )","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_ml.html","id":"caret_params-argument","dir":"Articles","previous_headings":"Cram ML > Built-in Model","what":"caret_params argument","title":"Cram ML","text":"caret_params list defines model trained using caret package. can include argument supported caret::train(), allowing full control model specification tuning. Common components include: method: machine learning algorithm (e.g., \"lm\" linear regression, \"rf\" random forest, \"xgbTree\" XGBoost, \"svmLinear\" support vector machines) trControl: resampling strategy (e.g., trainControl(method = \"cv\", number = 5) 5-fold cross-validation, \"none\" training without resampling) tuneGrid: grid hyperparameters tuning (e.g., expand.grid(mtry = c(2, 3, 4))) metric: model selection metric used tuning (e.g., \"RMSE\" \"Accuracy\") preProcess: optional preprocessing steps (e.g., centering, scaling) importance: logical flag compute variable importance (useful tree-based models) Refer full documentation caret model training tuning complete list supported arguments options.","code":"caret_params_lm <- list(   method = \"lm\",   trControl = trainControl(method = \"none\") )  result <- cram_ml(   data = data_df,   formula = Y ~ .,   batch = 5,   loss_name = \"se\",   caret_params = caret_params_lm ) print(result) #> $raw_results #>                         Metric    Value #> 1       Expected Loss Estimate  0.86429 #> 2 Expected Loss Standard Error  0.73665 #> 3       Expected Loss CI Lower -0.57952 #> 4       Expected Loss CI Upper  2.30809 #>  #> $interactive_table #>  #> $final_ml_model #> Linear Regression  #>  #> 100 samples #>   3 predictor #>  #> No pre-processing #> Resampling: None"},{"path":"https://yanisvdc.github.io/cramR/articles/cram_ml.html","id":"case-of-categorical-target-variable","dir":"Articles","previous_headings":"Cram ML > Built-in Model","what":"Case of categorical target variable","title":"Cram ML","text":"cram_ml() function can also used classification tasks, whether predicting hard labels class probabilities. controlled via classify argument loss_name. , demonstrate two typical use cases. Also note data inputs needs numeric types, hence Y categorical, contain numeric values representing class observation. need use type factor cram_ml().","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_ml.html","id":"case-1-predicting-class-labels","dir":"Articles","previous_headings":"Cram ML > Built-in Model > Case of categorical target variable","what":"Case 1: Predicting Class Labels","title":"Cram ML","text":"case, model outputs hard predictions (labels, e.g.¬†0, 1, 2 etc.), metric used classification accuracy‚Äîproportion correctly predicted labels. Use loss_name = \"accuracy\" Set classProbs = FALSE trainControl Set classify = TRUE cram_ml()","code":"set.seed(42)  # Generate binary classification dataset X_data <- data.frame(x1 = rnorm(100), x2 = rnorm(100), x3 = rnorm(100)) Y_data <- rbinom(nrow(X_data), 1, 0.5) data_df <- data.frame(X_data, Y = Y_data)  # Define caret parameters: predict labels (default behavior) caret_params_rf <- list(   method = \"rf\",   trControl = trainControl(method = \"none\") )  # Run CRAM ML with accuracy as loss result <- cram_ml(   data = data_df,   formula = Y ~ .,   batch = 5,   loss_name = \"accuracy\",   caret_params = caret_params_rf,   classify = TRUE )  print(result) #> $raw_results #>                         Metric    Value #> 1       Expected Loss Estimate  0.48750 #> 2 Expected Loss Standard Error  0.43071 #> 3       Expected Loss CI Lower -0.35668 #> 4       Expected Loss CI Upper  1.33168 #>  #> $interactive_table #>  #> $final_ml_model #> Random Forest  #>  #> 100 samples #>   3 predictor #>   2 classes: 'class0', 'class1'  #>  #> No pre-processing #> Resampling: None"},{"path":"https://yanisvdc.github.io/cramR/articles/cram_ml.html","id":"case-2-predicting-class-probabilities","dir":"Articles","previous_headings":"Cram ML > Built-in Model > Case of categorical target variable","what":"Case 2: Predicting Class Probabilities","title":"Cram ML","text":"setup, model outputs class probabilities, loss evaluated using logarithmic loss (logloss)‚Äîstandard metric probabilistic classification. Use loss_name = \"logloss\" Set classProbs = TRUE trainControl Set classify = TRUE cram_ml() Together, arguments allow users apply cram_ml() using wide variety built-machine learning models losses. users need go beyond built-choices, also provide next section friendly workflow specify custom models losses cram_ml().","code":"set.seed(42)  # Generate binary classification dataset X_data <- data.frame(x1 = rnorm(100), x2 = rnorm(100), x3 = rnorm(100)) Y_data <- rbinom(nrow(X_data), 1, 0.5) data_df <- data.frame(X_data, Y = Y_data)  # Define caret parameters for probability output caret_params_rf_probs <- list(   method = \"rf\",   trControl = trainControl(method = \"none\", classProbs = TRUE) )  # Run CRAM ML with logloss as the evaluation loss result <- cram_ml(   data = data_df,   formula = Y ~ .,   batch = 5,   loss_name = \"logloss\",   caret_params = caret_params_rf_probs,   classify = TRUE )  print(result) #> $raw_results #>                         Metric    Value #> 1       Expected Loss Estimate  0.93225 #> 2 Expected Loss Standard Error  0.48118 #> 3       Expected Loss CI Lower -0.01085 #> 4       Expected Loss CI Upper  1.87534 #>  #> $interactive_table #>  #> $final_ml_model #> Random Forest  #>  #> 100 samples #>   3 predictor #>   2 classes: 'class0', 'class1'  #>  #> No pre-processing #> Resampling: None"},{"path":"https://yanisvdc.github.io/cramR/articles/cram_ml.html","id":"custom-model","dir":"Articles","previous_headings":"Cram ML","what":"Custom Model","title":"Cram ML","text":"addition using built-learners via caret, cram_ml() also supports fully custom model workflows. can specify : Model fitting function (custom_fit) Prediction function (custom_predict) Loss function (custom_loss) offers maximum flexibility, allowing CRAM evaluate learning model performance criterion, including regression, classification, even unsupervised losses clustering distance.","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_ml.html","id":"custom_fitdata----","dir":"Articles","previous_headings":"Cram ML > Custom Model","what":"1. custom_fit(data, ...)","title":"Cram ML","text":"function takes data frame returns fitted model. may define additional arguments hyperparameters training settings. data: data frame includes predictors outcome variable Y. Example: basic linear model fit three predictors:","code":"custom_fit <- function(data) {   lm(Y ~ x1 + x2 + x3, data = data) }"},{"path":"https://yanisvdc.github.io/cramR/articles/cram_ml.html","id":"custom_predictmodel-data","dir":"Articles","previous_headings":"Cram ML > Custom Model","what":"2. custom_predict(model, data)","title":"Cram ML","text":"function generates predictions fitted model new data. returns numeric vector predicted outcomes. model: fitted model returned custom_fit() data: data frame new observations (typically including original predictors) Example: Extract predictors apply standard predict() call:","code":"custom_predict <- function(model, data) {   predictors_only <- data[, setdiff(names(data), \"Y\"), drop = FALSE]   predict(model, newdata = predictors_only) }"},{"path":"https://yanisvdc.github.io/cramR/articles/cram_ml.html","id":"custom_losspredictions-data","dir":"Articles","previous_headings":"Cram ML > Custom Model","what":"3. custom_loss(predictions, data)","title":"Cram ML","text":"function defines loss metric used evaluate model predictions. return numeric vector individual losses, one per observation. internally aggregated cram_ml() compute overall performance. predictions: numeric vector predicted values model data: data frame containing true outcome values (Y) Example: Define custom loss function using Squared Error (SE)","code":"custom_loss <- function(predictions, data) {   actuals <- data$Y   se_loss <- (predictions - actuals)^2   return(se_loss) }"},{"path":"https://yanisvdc.github.io/cramR/articles/cram_ml.html","id":"use-cram_ml-with-custom-functions","dir":"Articles","previous_headings":"Cram ML > Custom Model","what":"4. Use cram_ml() with Custom Functions","title":"Cram ML","text":"defined custom training, prediction, loss functions, can pass directly cram_ml() shown , note caret_params loss_name used built-functionalities now NULL:","code":"set.seed(42) X_data <- data.frame(x1 = rnorm(100), x2 = rnorm(100), x3 = rnorm(100)) Y_data <- rnorm(100) data_df <- data.frame(X_data, Y = Y_data)  result <- cram_ml(   data = data_df,   formula = Y ~ .,   batch = 5,   custom_fit = custom_fit,   custom_predict = custom_predict,   custom_loss = custom_loss ) print(result) #> $raw_results #>                         Metric    Value #> 1       Expected Loss Estimate  0.86429 #> 2 Expected Loss Standard Error  0.73665 #> 3       Expected Loss CI Lower -0.57952 #> 4       Expected Loss CI Upper  2.30809 #>  #> $interactive_table #>  #> $final_ml_model #>  #> Call: #> lm(formula = Y ~ x1 + x2 + x3, data = data) #>  #> Coefficients: #> (Intercept)           x1           x2           x3   #>    0.031503     0.057754     0.008829    -0.031611"},{"path":"https://yanisvdc.github.io/cramR/articles/cram_ml_learning.html","id":"what-is-ml_learning","dir":"Articles","previous_headings":"","what":"üîç What is ml_learning()?","title":"Using ml_learning() for Batch-wise Machine Learning","text":"ml_learning() function implements batch-wise machine learning supervised unsupervised tasks. supports: caret::train() compatible model (regression, classification, clustering, etc.) Custom model training + prediction via custom_fit, custom_predict Custom built-loss functions (e.g., MSE, logloss, accuracy) Optional parallel processing (parallelize_batch = TRUE) ‚Äôs flexible utility powers cram_ml() general-purpose ML workflows, also useful customizing training pipelines.","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_ml_learning.html","id":"when-to-use-ml_learning","dir":"Articles","previous_headings":"","what":"üß† When to use ml_learning()?","title":"Using ml_learning() for Batch-wise Machine Learning","text":"want evaluate model‚Äôs performance multiple growing batches data want track loss evolution time need parallelized learning, e.g., neural nets larger datasets ‚Äôre experimenting custom ML pipelines, loss functions, unsupervised tasks","code":""},{"path":[]},{"path":"https://yanisvdc.github.io/cramR/articles/cram_ml_learning.html","id":"example-linear-regression-with-mse","dir":"Articles","previous_headings":"","what":"üìò Example: Linear Regression with MSE","title":"Using ml_learning() for Batch-wise Machine Learning","text":"","code":"# Simulate regression data set.seed(42) X_data <- data.frame(x1 = rnorm(100), x2 = rnorm(100), x3 = rnorm(100)) Y_data <- rnorm(100) data_df <- data.frame(X_data, Y = Y_data) # Define model settings caret_params_lm <- list(   method = \"lm\",   trControl = trainControl(method = \"none\")  # No cross-validation )  # Define batch count nb_batch <- 5 # Run ML learning result_lm <- ml_learning(   data = data_df,   formula = Y ~ .,   batch = nb_batch,   loss_name = \"se\",   caret_params = caret_params_lm )"},{"path":"https://yanisvdc.github.io/cramR/articles/cram_ml_learning.html","id":"output-structure","dir":"Articles","previous_headings":"","what":"üì¶ Output Structure","title":"Using ml_learning() for Batch-wise Machine Learning","text":"returned object list :","code":"str(result_lm) #> List of 3 #>  $ final_ml_model:List of 24 #>   ..$ method      : chr \"lm\" #>   ..$ modelInfo   :List of 13 #>   .. ..$ label     : chr \"Linear Regression\" #>   .. ..$ library   : NULL #>   .. ..$ loop      : NULL #>   .. ..$ type      : chr \"Regression\" #>   .. ..$ parameters:'data.frame':    1 obs. of  3 variables: #>   .. .. ..$ parameter: chr \"intercept\" #>   .. .. ..$ class    : chr \"logical\" #>   .. .. ..$ label    : chr \"intercept\" #>   .. ..$ grid      :function (x, y, len = NULL, search = \"grid\")   #>   .. ..$ fit       :function (x, y, wts, param, lev, last, classProbs, ...)   #>   .. ..$ predict   :function (modelFit, newdata, submodels = NULL)   #>   .. ..$ prob      : NULL #>   .. ..$ predictors:function (x, ...)   #>   .. ..$ tags      : chr [1:2] \"Linear Regression\" \"Accepts Case Weights\" #>   .. ..$ varImp    :function (object, ...)   #>   .. ..$ sort      :function (x)   #>   ..$ modelType   : chr \"Regression\" #>   ..$ results     :'data.frame': 0 obs. of  4 variables: #>   .. ..$ RMSE     : num(0)  #>   .. ..$ Rsquared : num(0)  #>   .. ..$ MAE      : num(0)  #>   .. ..$ intercept: logi(0)  #>   ..$ pred        : NULL #>   ..$ bestTune    :'data.frame': 1 obs. of  1 variable: #>   .. ..$ intercept: logi TRUE #>   ..$ call        : language train.formula(form = Y ~ ., data = list(x1 = c(0.276550747291463, 2.28664539270111,  -0.727292059474465, -0.60892| __truncated__ ... #>   ..$ dots        : list() #>   ..$ metric      : chr \"RMSE\" #>   ..$ control     :List of 28 #>   .. ..$ method           : chr \"none\" #>   .. ..$ number           : num 25 #>   .. ..$ repeats          : logi NA #>   .. ..$ search           : chr \"grid\" #>   .. ..$ p                : num 0.75 #>   .. ..$ initialWindow    : NULL #>   .. ..$ horizon          : num 1 #>   .. ..$ fixedWindow      : logi TRUE #>   .. ..$ skip             : num 0 #>   .. ..$ verboseIter      : logi FALSE #>   .. ..$ returnData       : logi TRUE #>   .. ..$ returnResamp     : chr \"final\" #>   .. ..$ savePredictions  : chr \"none\" #>   .. ..$ classProbs       : logi FALSE #>   .. ..$ summaryFunction  :function (data, lev = NULL, model = NULL)   #>   .. ..$ selectionFunction: chr \"best\" #>   .. ..$ preProcOptions   :List of 6 #>   .. .. ..$ thresh   : num 0.95 #>   .. .. ..$ ICAcomp  : num 3 #>   .. .. ..$ k        : num 5 #>   .. .. ..$ freqCut  : num 19 #>   .. .. ..$ uniqueCut: num 10 #>   .. .. ..$ cutoff   : num 0.9 #>   .. ..$ sampling         : NULL #>   .. ..$ index            :List of 1 #>   .. .. ..$ Resample1: int [1:100] 1 2 3 4 5 6 7 8 9 10 ... #>   .. ..$ indexOut         :List of 1 #>   .. .. ..$ Resample1: int(0)  #>   .. ..$ indexFinal       : NULL #>   .. ..$ timingSamps      : num 0 #>   .. ..$ predictionBounds : logi [1:2] FALSE FALSE #>   .. ..$ seeds            : logi NA #>   .. ..$ adaptive         :List of 4 #>   .. .. ..$ min     : num 5 #>   .. .. ..$ alpha   : num 0.05 #>   .. .. ..$ method  : chr \"gls\" #>   .. .. ..$ complete: logi TRUE #>   .. ..$ trim             : logi FALSE #>   .. ..$ allowParallel    : logi TRUE #>   .. ..$ yLimits          : num [1:2] -1.89 2.63 #>   ..$ finalModel  :List of 17 #>   .. ..$ coefficients : Named num [1:4] 0.0315 0.05775 0.00883 -0.03161 #>   .. .. ..- attr(*, \"names\")= chr [1:4] \"(Intercept)\" \"x1\" \"x2\" \"x3\" #>   .. ..$ residuals    : Named num [1:100] 1.118 -0.859 -0.15 0.132 -0.127 ... #>   .. .. ..- attr(*, \"names\")= chr [1:100] \"X56\" \"X12\" \"X65\" \"X34\" ... #>   .. ..$ effects      : Named num [1:100] -0.3294 -0.6472 -0.0551 -0.3156 -0.1693 ... #>   .. .. ..- attr(*, \"names\")= chr [1:100] \"(Intercept)\" \"x1\" \"x2\" \"x3\" ... #>   .. ..$ rank         : int 4 #>   .. ..$ fitted.values: Named num [1:100] 0.06922 0.10013 -0.00358 0.02098 0.12662 ... #>   .. .. ..- attr(*, \"names\")= chr [1:100] \"X56\" \"X12\" \"X65\" \"X34\" ... #>   .. ..$ assign       : int [1:4] 0 1 2 3 #>   .. ..$ qr           :List of 5 #>   .. .. ..$ qr   : num [1:100, 1:4] -10 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 ... #>   .. .. .. ..- attr(*, \"dimnames\")=List of 2 #>   .. .. .. .. ..$ : chr [1:100] \"X56\" \"X12\" \"X65\" \"X34\" ... #>   .. .. .. .. ..$ : chr [1:4] \"(Intercept)\" \"x1\" \"x2\" \"x3\" #>   .. .. .. ..- attr(*, \"assign\")= int [1:4] 0 1 2 3 #>   .. .. ..$ qraux: num [1:4] 1.1 1.22 1.09 1.04 #>   .. .. ..$ pivot: int [1:4] 1 2 3 4 #>   .. .. ..$ tol  : num 1e-07 #>   .. .. ..$ rank : int 4 #>   .. .. ..- attr(*, \"class\")= chr \"qr\" #>   .. ..$ df.residual  : int 96 #>   .. ..$ xlevels      : Named list() #>   .. ..$ call         : language lm(formula = .outcome ~ ., data = dat) #>   .. ..$ terms        :Classes 'terms', 'formula'  language .outcome ~ x1 + x2 + x3 #>   .. .. .. ..- attr(*, \"variables\")= language list(.outcome, x1, x2, x3) #>   .. .. .. ..- attr(*, \"factors\")= int [1:4, 1:3] 0 1 0 0 0 0 1 0 0 0 ... #>   .. .. .. .. ..- attr(*, \"dimnames\")=List of 2 #>   .. .. .. .. .. ..$ : chr [1:4] \".outcome\" \"x1\" \"x2\" \"x3\" #>   .. .. .. .. .. ..$ : chr [1:3] \"x1\" \"x2\" \"x3\" #>   .. .. .. ..- attr(*, \"term.labels\")= chr [1:3] \"x1\" \"x2\" \"x3\" #>   .. .. .. ..- attr(*, \"order\")= int [1:3] 1 1 1 #>   .. .. .. ..- attr(*, \"intercept\")= int 1 #>   .. .. .. ..- attr(*, \"response\")= int 1 #>   .. .. .. ..- attr(*, \".Environment\")=<environment: 0x000001967e9e3748>  #>   .. .. .. ..- attr(*, \"predvars\")= language list(.outcome, x1, x2, x3) #>   .. .. .. ..- attr(*, \"dataClasses\")= Named chr [1:4] \"numeric\" \"numeric\" \"numeric\" \"numeric\" #>   .. .. .. .. ..- attr(*, \"names\")= chr [1:4] \".outcome\" \"x1\" \"x2\" \"x3\" #>   .. ..$ model        :'data.frame': 100 obs. of  4 variables: #>   .. .. ..$ .outcome: num [1:100] 1.187534 -0.758921 -0.153358 0.152764 -0.000241 ... #>   .. .. ..$ x1      : num [1:100] 0.277 2.287 -0.727 -0.609 1.215 ... #>   .. .. ..$ x2      : num [1:100] -1.238 0.108 0.59 1.123 -0.997 ... #>   .. .. ..$ x3      : num [1:100] -1.034 2.037 -0.054 -0.466 -1.068 ... #>   .. .. ..- attr(*, \"terms\")=Classes 'terms', 'formula'  language .outcome ~ x1 + x2 + x3 #>   .. .. .. .. ..- attr(*, \"variables\")= language list(.outcome, x1, x2, x3) #>   .. .. .. .. ..- attr(*, \"factors\")= int [1:4, 1:3] 0 1 0 0 0 0 1 0 0 0 ... #>   .. .. .. .. .. ..- attr(*, \"dimnames\")=List of 2 #>   .. .. .. .. .. .. ..$ : chr [1:4] \".outcome\" \"x1\" \"x2\" \"x3\" #>   .. .. .. .. .. .. ..$ : chr [1:3] \"x1\" \"x2\" \"x3\" #>   .. .. .. .. ..- attr(*, \"term.labels\")= chr [1:3] \"x1\" \"x2\" \"x3\" #>   .. .. .. .. ..- attr(*, \"order\")= int [1:3] 1 1 1 #>   .. .. .. .. ..- attr(*, \"intercept\")= int 1 #>   .. .. .. .. ..- attr(*, \"response\")= int 1 #>   .. .. .. .. ..- attr(*, \".Environment\")=<environment: 0x000001967e9e3748>  #>   .. .. .. .. ..- attr(*, \"predvars\")= language list(.outcome, x1, x2, x3) #>   .. .. .. .. ..- attr(*, \"dataClasses\")= Named chr [1:4] \"numeric\" \"numeric\" \"numeric\" \"numeric\" #>   .. .. .. .. .. ..- attr(*, \"names\")= chr [1:4] \".outcome\" \"x1\" \"x2\" \"x3\" #>   .. ..$ xNames       : chr [1:3] \"x1\" \"x2\" \"x3\" #>   .. ..$ problemType  : chr \"Regression\" #>   .. ..$ tuneValue    :'data.frame': 1 obs. of  1 variable: #>   .. .. ..$ intercept: logi TRUE #>   .. ..$ obsLevels    : logi NA #>   .. ..$ param        : list() #>   .. ..- attr(*, \"class\")= chr \"lm\" #>   ..$ preProcess  : NULL #>   ..$ trainingData:'data.frame': 100 obs. of  4 variables: #>   .. ..$ .outcome: num [1:100] 1.187534 -0.758921 -0.153358 0.152764 -0.000241 ... #>   .. ..$ x1      : num [1:100] 0.277 2.287 -0.727 -0.609 1.215 ... #>   .. ..$ x2      : num [1:100] -1.238 0.108 0.59 1.123 -0.997 ... #>   .. ..$ x3      : num [1:100] -1.034 2.037 -0.054 -0.466 -1.068 ... #>   ..$ ptype       :'data.frame': 0 obs. of  3 variables: #>   .. ..$ x1: num(0)  #>   .. ..$ x2: num(0)  #>   .. ..$ x3: num(0)  #>   ..$ resample    : NULL #>   ..$ resampledCM : NULL #>   ..$ perfNames   : chr [1:3] \"RMSE\" \"Rsquared\" \"MAE\" #>   ..$ maximize    : logi FALSE #>   ..$ yLimits     : num [1:2] -1.89 2.63 #>   ..$ times       :List of 3 #>   .. ..$ everything: 'proc_time' Named num [1:5] 0.02 0 0 NA NA #>   .. .. ..- attr(*, \"names\")= chr [1:5] \"user.self\" \"sys.self\" \"elapsed\" \"user.child\" ... #>   .. ..$ final     : 'proc_time' Named num [1:5] 0 0 0 NA NA #>   .. .. ..- attr(*, \"names\")= chr [1:5] \"user.self\" \"sys.self\" \"elapsed\" \"user.child\" ... #>   .. ..$ prediction: logi [1:3] NA NA NA #>   ..$ levels      : logi NA #>   ..$ terms       :Classes 'terms', 'formula'  language Y ~ x1 + x2 + x3 #>   .. .. ..- attr(*, \"variables\")= language list(Y, x1, x2, x3) #>   .. .. ..- attr(*, \"factors\")= int [1:4, 1:3] 0 1 0 0 0 0 1 0 0 0 ... #>   .. .. .. ..- attr(*, \"dimnames\")=List of 2 #>   .. .. .. .. ..$ : chr [1:4] \"Y\" \"x1\" \"x2\" \"x3\" #>   .. .. .. .. ..$ : chr [1:3] \"x1\" \"x2\" \"x3\" #>   .. .. ..- attr(*, \"term.labels\")= chr [1:3] \"x1\" \"x2\" \"x3\" #>   .. .. ..- attr(*, \"order\")= int [1:3] 1 1 1 #>   .. .. ..- attr(*, \"intercept\")= int 1 #>   .. .. ..- attr(*, \"response\")= int 1 #>   .. .. ..- attr(*, \".Environment\")=<environment: R_GlobalEnv>  #>   .. .. ..- attr(*, \"predvars\")= language list(Y, x1, x2, x3) #>   .. .. ..- attr(*, \"dataClasses\")= Named chr [1:4] \"numeric\" \"numeric\" \"numeric\" \"numeric\" #>   .. .. .. ..- attr(*, \"names\")= chr [1:4] \"Y\" \"x1\" \"x2\" \"x3\" #>   ..$ coefnames   : chr [1:3] \"x1\" \"x2\" \"x3\" #>   ..$ xlevels     : Named list() #>   ..- attr(*, \"class\")= chr [1:2] \"train\" \"train.formula\" #>  $ losses        : num [1:100, 1:6] 0 0 0 0 0 0 0 0 0 0 ... #>  $ batch_indices :List of 5 #>   ..$ 1: int [1:20] 56 12 65 34 24 4 9 97 7 1 ... #>   ..$ 2: int [1:20] 98 3 8 64 96 17 63 44 49 28 ... #>   ..$ 3: int [1:20] 62 18 30 21 29 87 99 74 75 90 ... #>   ..$ 4: int [1:20] 69 50 20 52 85 86 19 77 45 36 ... #>   ..$ 5: int [1:20] 42 47 51 40 22 39 83 82 72 68 ..."},{"path":"https://yanisvdc.github.io/cramR/articles/cram_ml_learning.html","id":"custom-models-optional","dir":"Articles","previous_headings":"","what":"üîß Custom Models (Optional)","title":"Using ml_learning() for Batch-wise Machine Learning","text":"can plug models: run:","code":"custom_fit <- function(data) {   model <- glm(Y ~ ., data = data)   return(model) }  custom_predict <- function(model, data) {   return(predict(model, newdata = data)) }  custom_loss <- function(preds, data) {   return((data$Y - preds)^2) } ml_learning(data_df, batch = nb_batch, custom_fit = custom_fit,             custom_predict = custom_predict, custom_loss = custom_loss)"},{"path":"https://yanisvdc.github.io/cramR/articles/cram_ml_learning.html","id":"parallelization","dir":"Articles","previous_headings":"","what":"‚ö° Parallelization","title":"Using ml_learning() for Batch-wise Machine Learning","text":"accelerate training, set:","code":"ml_learning(data_df,             formula = Y ~ .,             batch = nb_batch,             caret_params = caret_params_lm,             loss_name = \"mse\",             parallelize_batch = TRUE,             n_cores = 4)"},{"path":"https://yanisvdc.github.io/cramR/articles/cram_ml_learning.html","id":"see-also","dir":"Articles","previous_headings":"","what":"üìö See Also","title":"Using ml_learning() for Batch-wise Machine Learning","text":"cram_ml() ‚Äî wrapper full pipeline (estimation + CI) cram_policy() ‚Äî causal policy learning caret::train() ‚Äî underlying training API","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_policy.html","id":"introduction-what-is-the-cram-method","dir":"Articles","previous_headings":"","what":"Introduction: What is the Cram Method?","title":"Using cram_policy() for Policy Learning and Evaluation","text":"Cram method powerful approach simultaneously learning evaluating decision rules, individualized treatment rules (ITRs), data. Common applications include healthcare (treat), pricing advertising (target much charge), policy (support). Unlike traditional approaches like sample splitting cross-validation, waste part data evaluation , Cram reuses available data efficiently. key distinction cross-validation Cram evaluates final learned model, rather averaging performance across multiple models trained different data splits. Cram: Simultaneously trains model evaluates final learned decision rule using available data improve statistical efficiency precision‚Äîunlike cross-validation sample splitting, reserve part data evaluation . Learns cumulative batches, using new round data refine model check whether ‚Äôs actually improving‚Äîensuring learning translates meaningful gains. Estimates expected outcome across entire population policy learned data sample applied everyone population, just data sample (statistical quantity called ‚Äúpolicy value‚Äù), allows user assess learned policy generalize beyond data sample. Think Cram like cram school: learn bit, test bit, repeat ‚Äî getting better constantly self-evaluating.","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_policy.html","id":"the-cram-workflow","dir":"Articles","previous_headings":"","what":"The Cram Workflow","title":"Using cram_policy() for Policy Learning and Evaluation","text":"core idea Cram method visualized: procedure ensures update backed performance testing, enabling learning evaluation one pass data. Note: schematic represents Cram estimates difference policy value (see definition policy value ) relative baseline policy - example baseline policy healthcare treat nobody (-zeros) randomly treat individuals (assign 1 treatment 0 treatment randomly); policy value difference ‚ÄúDelta‚Äù gives much better (worse) policy learned Cram data relative baseline policy - Cram can also used estimate policy value learned policy directly, without need specify baseline policy (presented part introduction available outputs main functions Cram).","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_policy.html","id":"the-cram_policy-function","dir":"Articles","previous_headings":"","what":"The cram_policy() Function","title":"Using cram_policy() for Policy Learning and Evaluation","text":"cram_policy() function cramR implements Cram framework binary treatment policy learning.","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_policy.html","id":"key-features-of-cram_policy","dir":"Articles","previous_headings":"The cram_policy() Function","what":"üîë Key Features of cram_policy()","title":"Using cram_policy() for Policy Learning and Evaluation","text":"Model-Agnostic Flexibility: Supports variety learning strategies, including causal_forest, s_learner, m_learner, well fully customizable learners via user-defined fit predict functions. Efficient Design: Built top data.table fast, memory-efficient computation, optional support parallel batch training scale across larger datasets.","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_policy.html","id":"example-running-cram-policy-on-simulated-data","dir":"Articles","previous_headings":"","what":"Example: Running Cram Policy on simulated data","title":"Using cram_policy() for Policy Learning and Evaluation","text":"","code":"library(data.table) # Function to generate sample data with heterogeneous treatment effects: # - Positive effect group # - Neutral effect group # - Adverse effect group generate_data <- function(n) {   X <- data.table(     binary = rbinom(n, 1, 0.5),                 # Binary variable     discrete = sample(1:5, n, replace = TRUE),  # Discrete variable     continuous = rnorm(n)                       # Continuous variable   )    # Binary treatment assignment (50% treated)   D <- rbinom(n, 1, 0.5)    # Define heterogeneous treatment effects based on X   treatment_effect <- ifelse(     X[, binary] == 1 & X[, discrete] <= 2,        # Group 1: Positive effect     1,     ifelse(X[, binary] == 0 & X[, discrete] >= 4, # Group 3: Adverse effect            -1,            0.1)                                   # Group 2: Neutral effect   )    # Outcome depends on treatment effect + noise   Y <- D * (treatment_effect + rnorm(n, mean = 0, sd = 1)) +     (1 - D) * rnorm(n)    return(list(X = X, D = D, Y = Y)) }  # Generate a sample dataset set.seed(123) n <- 1000 data <- generate_data(n) X <- data$X D <- data$D Y <- data$Y # Options for batch: # Either an integer specifying the number of batches or a vector/list of batch assignments for all individuals batch <- 20  # Model type for estimating treatment effects # Options for model_type: 'causal_forest', 's_learner', 'm_learner' # Note: you can also set model_type to NULL and specify custom_fit and custom_predict to use your custom model model_type <- \"causal_forest\"    # Options for learner_type: # if model_type == 'causal_forest', choose NULL # if model_type == 's_learner' or 'm_learner', choose between 'ridge', 'fnn' and 'caret' learner_type <- NULL    # Baseline policy to compare against (list of 0/1 for each individual) # Options for baseline_policy: # A list representing the baseline policy assignment for each individual. # If NULL, a default baseline policy of zeros is created. # Examples of baseline policy:  # - All-control baseline: as.list(rep(0, nrow(X))) or NULL # - Randomized baseline: as.list(sample(c(0, 1), nrow(X), replace = TRUE)) baseline_policy <- as.list(rep(0, nrow(X)))    # Whether to parallelize batch processing (i.e. the cram method learns T policies, with T the number of batches. # They are learned in parallel when parallelize_batch is TRUE # vs. learned sequentially using the efficient data.table structure when parallelize_batch is FALSE, recommended for light weight training). # Defaults to FALSE. parallelize_batch <- FALSE      # Model-specific parameters (more details in the article \"Quick Start\") # Examples: NULL defaults to the following: # - causal_forest: list(num.trees = 100) # - ridge: list(alpha = 1) # - caret: list(formula = Y ~ ., caret_params = list(method = \"lm\", trControl = trainControl(method = \"none\"))) # - fnn (Feedforward Neural Network): see below # input_shape <- if (model_type == \"s_learner\") ncol(X) + 1 else ncol(X) # default_model_params <- list( #       input_layer = list(units = 64, activation = 'relu', input_shape = input_shape), #       layers = list( #         list(units = 32, activation = 'relu') #       ), #       output_layer = list(units = 1, activation = 'linear'), #       compile_args = list(optimizer = 'adam', loss = 'mse'), #       fit_params = list(epochs = 5, batch_size = 32, verbose = 0) #     ) model_params <- NULL     # Significance level for confidence intervals (default = 95%) alpha <- 0.05    # Run the Cram policy method result <- cram_policy(   X, D, Y,   batch = batch,   model_type = model_type,   learner_type = learner_type,   baseline_policy = baseline_policy,   parallelize_batch = parallelize_batch,   model_params = model_params,   alpha = alpha )  # Display the results print(result) #> $raw_results #>                        Metric   Value #> 1              Delta Estimate 0.23208 #> 2        Delta Standard Error 0.05862 #> 3              Delta CI Lower 0.11718 #> 4              Delta CI Upper 0.34697 #> 5       Policy Value Estimate 0.21751 #> 6 Policy Value Standard Error 0.05237 #> 7       Policy Value CI Lower 0.11486 #> 8       Policy Value CI Upper 0.32016 #> 9          Proportion Treated 0.60500 #>  #> $interactive_table #>  #> $final_policy_model #> GRF forest object of type causal_forest  #> Number of trees: 100  #> Number of training samples: 1000  #> Variable importance:  #>     1     2     3  #> 0.437 0.350 0.213"},{"path":"https://yanisvdc.github.io/cramR/articles/cram_policy.html","id":"interpreting-results","dir":"Articles","previous_headings":"","what":"Interpreting Results","title":"Using cram_policy() for Policy Learning and Evaluation","text":"output cram_policy() includes: raw_results: data frame summarizing key evaluation metrics: Delta Estimate: estimated improvement outcomes using final learned policy compared baseline (e.g., treatment treat-). Delta Standard Error confidence interval bounds: Reflect uncertainty around delta estimate. Policy Value Estimate: estimated average outcome final learned policy applied across population. Policy Value Standard Error confidence interval bounds: Reflect uncertainty policy value estimate. Proportion Treated: fraction population treated learned policy. interactive_table: dynamic, scrollable version raw_results easier exploration filtering. final_policy_model: trained policy model object , fitted according specified model_type, learner_type, user-provided custom_fit custom_predict (details article ‚ÄúQuick Start‚Äù). object can used analysis applying learned policy new data. can inspect apply learned model new data.","code":"result$raw_results #>                        Metric   Value #> 1              Delta Estimate 0.23208 #> 2        Delta Standard Error 0.05862 #> 3              Delta CI Lower 0.11718 #> 4              Delta CI Upper 0.34697 #> 5       Policy Value Estimate 0.21751 #> 6 Policy Value Standard Error 0.05237 #> 7       Policy Value CI Lower 0.11486 #> 8       Policy Value CI Upper 0.32016 #> 9          Proportion Treated 0.60500 result$interactive_table class(result$final_policy_model) #> [1] \"causal_forest\" \"grf\" summary(result$final_policy_model) #>                          Length Class  Mode    #> _ci_group_size              1   -none- numeric #> _num_variables              1   -none- numeric #> _num_trees                  1   -none- numeric #> _root_nodes               100   -none- list    #> _child_nodes              100   -none- list    #> _leaf_samples             100   -none- list    #> _split_vars               100   -none- list    #> _split_values             100   -none- list    #> _drawn_samples            100   -none- list    #> _send_missing_left        100   -none- list    #> _pv_values                100   -none- list    #> _pv_num_types               1   -none- numeric #> predictions              1000   -none- numeric #> variance.estimates          0   -none- numeric #> debiased.error           1000   -none- numeric #> excess.error             1000   -none- numeric #> seed                        1   -none- numeric #> num.threads                 1   -none- numeric #> ci.group.size               1   -none- numeric #> X.orig                   3000   -none- numeric #> Y.orig                   1000   -none- numeric #> W.orig                   1000   -none- numeric #> Y.hat                    1000   -none- numeric #> W.hat                    1000   -none- numeric #> clusters                    0   -none- numeric #> equalize.cluster.weights    1   -none- logical #> tunable.params              7   -none- list    #> has.missing.values          1   -none- logical"},{"path":"https://yanisvdc.github.io/cramR/articles/cram_policy.html","id":"visual-summary-and-notes","dir":"Articles","previous_headings":"","what":"Visual Summary and Notes","title":"Using cram_policy() for Policy Learning and Evaluation","text":"visualization summarizes multiple evaluations across iterations contribute full Cram estimate. Notes: Batching: can pass number (e.g., batch = 5) custom vector control data split. Parallelization: Enable parallelize_batch = TRUE. Custom Learners: Use custom_fit custom_predict plug estimator. (details article ‚ÄúQuick Start‚Äù)","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_policy.html","id":"why-cram","dir":"Articles","previous_headings":"","what":"Why Cram?","title":"Using cram_policy() for Policy Learning and Evaluation","text":"Compared classic evaluation methods:","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_policy.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Using cram_policy() for Policy Learning and Evaluation","text":"Jia, Z., Imai, K., & Li, M. L. (2024). Cram Method Efficient Simultaneous Learning Evaluation. arXiv:2403.07031. K√ºnzel, S. R., Sekhon, J. S., Bickel, P. J., & Yu, B. (2019). Metalearners estimating heterogeneous treatment effects using machine learning. Proceedings National Academy Sciences United States America, 116(10), 4156‚Äì4165. https://doi.org/10.1073/pnas.1804597116 Wager, S., & Athey, S. (2018). Estimation inference heterogeneous treatment effects using random forests. Journal American Statistical Association, 113(523), 1228-1242. Athey, S., & Imbens, G. (2016). Recursive partitioning heterogeneous causal effects. Proceedings National Academy Sciences, 113(27), 7353-7360.","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_policy_part_1.html","id":"introduction-what-is-the-cram-method","dir":"Articles","previous_headings":"","what":"Introduction: What is the Cram Method?","title":"Introduction & Cram Policy part 1","text":"Cram method powerful approach simultaneously learning evaluating decision rules, individualized treatment rules (ITRs), data. Common applications include healthcare (treat), pricing advertising (target much charge), policy (support). Unlike traditional approaches like sample splitting cross-validation, waste part data evaluation , Cram reuses available data efficiently. key distinction cross-validation Cram evaluates final learned model, rather averaging performance across multiple models trained different data splits. Cram: Simultaneously trains model evaluates final learned decision rule using available data improve statistical efficiency precision‚Äîunlike cross-validation sample splitting, reserve part data evaluation . Learns cumulative batches, using new round data refine model check whether ‚Äôs actually improving‚Äîensuring learning translates meaningful gains. Estimates expected outcome across entire population policy learned data sample applied everyone population, just data sample (statistical quantity called ‚Äúpolicy value‚Äù), allows user assess learned policy generalize beyond data sample. üõ†Ô∏è Think Cram like cram school: learn bit, test bit, repeat ‚Äî getting better constantly self-evaluating.","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_policy_part_1.html","id":"the-cram-workflow","dir":"Articles","previous_headings":"","what":"The Cram Workflow","title":"Introduction & Cram Policy part 1","text":"core idea Cram method visualized: procedure ensures update backed performance testing, enabling learning evaluation one pass data. Note: schematic represents Cram estimates difference policy value (see definition policy value ) relative baseline policy - example baseline policy healthcare treat nobody (-zeros) randomly treat individuals (assign 1 treatment 0 treatment randomly); policy value difference ‚ÄúDelta‚Äù gives much better (worse) policy learned Cram data relative baseline policy - Cram can also used estimate policy value learned policy directly, without need specify baseline policy (presented part introduction available outputs main functions Cram; see result table ).","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_policy_part_1.html","id":"the-cram_policy-function","dir":"Articles","previous_headings":"","what":"The cram_policy() Function","title":"Introduction & Cram Policy part 1","text":"cram_policy() function cramR implements Cram framework binary treatment policy learning.","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_policy_part_1.html","id":"key-features-of-cram_policy","dir":"Articles","previous_headings":"The cram_policy() Function","what":"üîë Key Features of cram_policy()","title":"Introduction & Cram Policy part 1","text":"Model-Agnostic Flexibility: Supports variety learning strategies, including causal_forest, s_learner, m_learner, well fully customizable learners via user-defined fit predict functions. Efficient Design: Built top data.table fast, memory-efficient computation, optional support parallel batch training scale across larger datasets.","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_policy_part_1.html","id":"example-running-cram-policy-on-simulated-data","dir":"Articles","previous_headings":"","what":"Example: Running Cram Policy on simulated data","title":"Introduction & Cram Policy part 1","text":"","code":"library(data.table) # Function to generate sample data with heterogeneous treatment effects: # - Positive effect group # - Neutral effect group # - Adverse effect group generate_data <- function(n) {   X <- data.table(     binary = rbinom(n, 1, 0.5),                 # Binary variable     discrete = sample(1:5, n, replace = TRUE),  # Discrete variable     continuous = rnorm(n)                       # Continuous variable   )    # Binary treatment assignment (50% treated)   D <- rbinom(n, 1, 0.5)    # Define heterogeneous treatment effects based on X   treatment_effect <- ifelse(     X[, binary] == 1 & X[, discrete] <= 2,        # Group 1: Positive effect     1,     ifelse(X[, binary] == 0 & X[, discrete] >= 4, # Group 3: Adverse effect            -1,            0.1)                                   # Group 2: Neutral effect   )    # Outcome depends on treatment effect + noise   Y <- D * (treatment_effect + rnorm(n, mean = 0, sd = 1)) +     (1 - D) * rnorm(n)    return(list(X = X, D = D, Y = Y)) }  # Generate a sample dataset set.seed(123) n <- 1000 data <- generate_data(n) X <- data$X D <- data$D Y <- data$Y # Options for batch: # Either an integer specifying the number of batches or a vector/list of batch assignments for all individuals batch <- 20  # Model type for estimating treatment effects # Options for model_type: 'causal_forest', 's_learner', 'm_learner' # Note: you can also set model_type to NULL and specify custom_fit and custom_predict to use your custom model model_type <- \"causal_forest\"    # Options for learner_type: # if model_type == 'causal_forest', choose NULL # if model_type == 's_learner' or 'm_learner', choose between 'ridge', 'fnn' and 'caret' learner_type <- NULL    # Baseline policy to compare against (list of 0/1 for each individual) # Options for baseline_policy: # A list representing the baseline policy assignment for each individual. # If NULL, a default baseline policy of zeros is created. # Examples of baseline policy:  # - All-control baseline: as.list(rep(0, nrow(X))) or NULL # - Randomized baseline: as.list(sample(c(0, 1), nrow(X), replace = TRUE)) baseline_policy <- as.list(rep(0, nrow(X)))    # Whether to parallelize batch processing (i.e. the cram method learns T policies, with T the number of batches. # They are learned in parallel when parallelize_batch is TRUE # vs. learned sequentially using the efficient data.table structure when parallelize_batch is FALSE, recommended for light weight training). # Defaults to FALSE. parallelize_batch <- FALSE      # Model-specific parameters (more details in the article \"Cram Policy part 2\") # Examples: NULL defaults to the following: # - causal_forest: list(num.trees = 100) # - ridge: list(alpha = 1) # - caret: list(formula = Y ~ ., caret_params = list(method = \"lm\", trControl = trainControl(method = \"none\"))) # - fnn (Feedforward Neural Network): see below # input_shape <- if (model_type == \"s_learner\") ncol(X) + 1 else ncol(X) # default_model_params <- list( #       input_layer = list(units = 64, activation = 'relu', input_shape = input_shape), #       layers = list( #         list(units = 32, activation = 'relu') #       ), #       output_layer = list(units = 1, activation = 'linear'), #       compile_args = list(optimizer = 'adam', loss = 'mse'), #       fit_params = list(epochs = 5, batch_size = 32, verbose = 0) #     ) model_params <- NULL     # Significance level for confidence intervals (default = 95%) alpha <- 0.05    # Run the Cram policy method result <- cram_policy(   X, D, Y,   batch = batch,   model_type = model_type,   learner_type = learner_type,   baseline_policy = baseline_policy,   parallelize_batch = parallelize_batch,   model_params = model_params,   alpha = alpha )  # Display the results print(result) #> $raw_results #>                        Metric   Value #> 1              Delta Estimate 0.23208 #> 2        Delta Standard Error 0.05862 #> 3              Delta CI Lower 0.11718 #> 4              Delta CI Upper 0.34697 #> 5       Policy Value Estimate 0.21751 #> 6 Policy Value Standard Error 0.05237 #> 7       Policy Value CI Lower 0.11486 #> 8       Policy Value CI Upper 0.32016 #> 9          Proportion Treated 0.60500 #>  #> $interactive_table #>  #> $final_policy_model #> GRF forest object of type causal_forest  #> Number of trees: 100  #> Number of training samples: 1000  #> Variable importance:  #>     1     2     3  #> 0.437 0.350 0.213"},{"path":"https://yanisvdc.github.io/cramR/articles/cram_policy_part_1.html","id":"interpreting-results","dir":"Articles","previous_headings":"","what":"Interpreting Results","title":"Introduction & Cram Policy part 1","text":"output cram_policy() includes: raw_results: data frame summarizing key evaluation metrics: Delta Estimate: estimated policy value difference .e.¬†improvement outcomes using final learned policy compared baseline (e.g., treatment treat-). Delta Standard Error confidence interval bounds: Reflect uncertainty around delta estimate. Policy Value Estimate: estimated policy value .e.¬†average outcome final learned policy applied across population. Policy Value Standard Error confidence interval bounds: Reflect uncertainty policy value estimate. Proportion Treated: fraction population treated learned policy. interactive_table: dynamic, scrollable version raw_results easier exploration filtering. final_policy_model: trained policy model object , fitted according specified model_type, learner_type, user-provided custom_fit custom_predict (details article ‚ÄúCram Policy part 2‚Äù). object can used analysis applying learned policy new data. can inspect apply learned model new data.","code":"result$raw_results #>                        Metric   Value #> 1              Delta Estimate 0.23208 #> 2        Delta Standard Error 0.05862 #> 3              Delta CI Lower 0.11718 #> 4              Delta CI Upper 0.34697 #> 5       Policy Value Estimate 0.21751 #> 6 Policy Value Standard Error 0.05237 #> 7       Policy Value CI Lower 0.11486 #> 8       Policy Value CI Upper 0.32016 #> 9          Proportion Treated 0.60500 result$interactive_table class(result$final_policy_model) #> [1] \"causal_forest\" \"grf\" summary(result$final_policy_model) #>                          Length Class  Mode    #> _ci_group_size              1   -none- numeric #> _num_variables              1   -none- numeric #> _num_trees                  1   -none- numeric #> _root_nodes               100   -none- list    #> _child_nodes              100   -none- list    #> _leaf_samples             100   -none- list    #> _split_vars               100   -none- list    #> _split_values             100   -none- list    #> _drawn_samples            100   -none- list    #> _send_missing_left        100   -none- list    #> _pv_values                100   -none- list    #> _pv_num_types               1   -none- numeric #> predictions              1000   -none- numeric #> variance.estimates          0   -none- numeric #> debiased.error           1000   -none- numeric #> excess.error             1000   -none- numeric #> seed                        1   -none- numeric #> num.threads                 1   -none- numeric #> ci.group.size               1   -none- numeric #> X.orig                   3000   -none- numeric #> Y.orig                   1000   -none- numeric #> W.orig                   1000   -none- numeric #> Y.hat                    1000   -none- numeric #> W.hat                    1000   -none- numeric #> clusters                    0   -none- numeric #> equalize.cluster.weights    1   -none- logical #> tunable.params              7   -none- list    #> has.missing.values          1   -none- logical"},{"path":"https://yanisvdc.github.io/cramR/articles/cram_policy_part_1.html","id":"visual-summary-and-notes","dir":"Articles","previous_headings":"","what":"Visual Summary and Notes","title":"Introduction & Cram Policy part 1","text":"visualization summarizes multiple evaluations across iterations contribute full Cram estimate. Notes: Batching: can pass number (e.g., batch = 5) custom vector control data split. Parallelization: Enable parallelize_batch = TRUE. Custom Learners: Use custom_fit custom_predict plug estimator. (details article ‚ÄúCram Policy part 2‚Äù)","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_policy_part_1.html","id":"comparing-evaluation-strategies-sample-splitting-cross-validation-and-cram","dir":"Articles","previous_headings":"","what":"üìê Comparing Evaluation Strategies: Sample-Splitting, Cross-Validation, and Cram","title":"Introduction & Cram Policy part 1","text":"section, compare classical strategies model evaluation‚Äînamely sample-splitting cross-validation‚ÄîCram method. three approaches may ultimately train model using full dataset, differ fundamentally estimate generalization performance model.","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_policy_part_1.html","id":"sample-splitting","dir":"Articles","previous_headings":"üìê Comparing Evaluation Strategies: Sample-Splitting, Cross-Validation, and Cram","what":"üîç Sample-Splitting","title":"Introduction & Cram Policy part 1","text":"Sample-splitting divides data training set held-test set (e.g., 80/20). model trained training portion, performance assessed held-set. procedure produces evaluation model trained data, may understate performance final model trained full dataset. Thus, evaluation corresponds : partially trained model (fit , say, 80% data), Evaluated unseen data (held-20%). raises two issues: model evaluated final model deploy (‚Äôs undertrained). evaluation uses part available data, reducing statistical efficiency.","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_policy_part_1.html","id":"cross-validation","dir":"Articles","previous_headings":"üìê Comparing Evaluation Strategies: Sample-Splitting, Cross-Validation, and Cram","what":"üîÑ Cross-Validation","title":"Introduction & Cram Policy part 1","text":"consider k-fold cross-validation, partitions data k equal-sized folds. fold, model trained remaining k-1 folds evaluated held-fold. process ensures observation used training evaluation, different models. final performance estimate average fold-specific evaluation metrics serves proxy expected performance model trained full dataset. model trained subset data (e.g., 4 folds 5), Evaluation performed entire dataset, using different models portion. Thus, cross-validation uses data evaluation, evaluates models trained partial data. Crucially, final model trained full dataset never evaluated directly; performance approximated averaging surrogate models trained subsets.","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_policy_part_1.html","id":"cram","dir":"Articles","previous_headings":"üìê Comparing Evaluation Strategies: Sample-Splitting, Cross-Validation, and Cram","what":"üìà Cram","title":"Introduction & Cram Policy part 1","text":"Cram departs approaches directly targeting performance final model trained entire dataset, casting evaluation statistical estimation problem: estimates population-level performance (e.g., expected outcome loss) model achieve deployed. Specifically: Cram trains sequence models cumulative batches evaluates remaining data, described Algorithm 1, uses statistical estimators estimate expected performance final model trained entire dataset‚Äî.e., outcome observe model deployed population level beyond observed sample, provides confidence intervals around estimate, quantify uncertainty: example, 95% confidence interval constructed , repeated samples data-generating process, interval contain true expected performance 95% cases.","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_policy_part_1.html","id":"key-distinction-summary-what-is-being-evaluated","dir":"Articles","previous_headings":"üìê Comparing Evaluation Strategies: Sample-Splitting, Cross-Validation, and Cram","what":"üß† Key Distinction Summary: What Is Being Evaluated?","title":"Introduction & Cram Policy part 1","text":"methods aim estimate generalization performance model trained full dataset* (denoted final model table readability). However, differ models trained evaluation, data used evaluation, final performance estimate constructed. final model*: model trained full dataset Sample-splitting trains single model subset data evaluates held-portion. simple statistically inefficient. Cross-validation trains multiple models, subset data, evaluates corresponding held-fold. fold-specific evaluation metrics averaged approximate final model‚Äôs performance. Although commonly used proxy generalization performance final model, average directly target estimate performance model trained full dataset. Cram trains models cumulative data batches evaluates remaining data. uses evaluations statistically estimate generalization performance final model trained data, providing point estimate valid confidence intervals expected performance deployed.","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_policy_part_1.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Introduction & Cram Policy part 1","text":"Jia, Z., Imai, K., & Li, M. L. (2024). Cram Method Efficient Simultaneous Learning Evaluation, URL: https://www.hbs.edu/ris/Publication%20Files/2403.07031v1_a83462e0-145b-4675-99d5-9754aa65d786.pdf. K√ºnzel, S. R., Sekhon, J. S., Bickel, P. J., & Yu, B. (2019). Metalearners estimating heterogeneous treatment effects using machine learning. Proceedings National Academy Sciences United States America, 116(10), 4156‚Äì4165. https://doi.org/10.1073/pnas.1804597116 Wager, S., & Athey, S. (2018). Estimation inference heterogeneous treatment effects using random forests. Journal American Statistical Association, 113(523), 1228-1242. Athey, S., & Imbens, G. (2016). Recursive partitioning heterogeneous causal effects. Proceedings National Academy Sciences, 113(27), 7353-7360.","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_policy_part_2.html","id":"cram-policy","dir":"Articles","previous_headings":"","what":"Cram Policy","title":"Cram Policy part 2","text":"article ‚ÄúIntroduction & Cram Policy Part 1‚Äù, introduced Cram method, enables simultaneous learning evaluation binary policy. outlined primary parameters cram_policy() function demonstrated application using example dataset. section, provide detailed discussion configure parameters various use cases, depending notably nature dataset specific policy learning goals. begin simulating dataset consisting covariates X, binary treatment assignment D, continuous outcome Y, use demonstrate cram_policy() function.","code":"library(data.table) # Function to generate sample data with heterogeneous treatment effects: # - Positive effect group # - Neutral effect group # - Adverse effect group generate_data <- function(n) {   X <- data.table(     binary = rbinom(n, 1, 0.5),                 # Binary variable     discrete = sample(1:5, n, replace = TRUE),  # Discrete variable     continuous = rnorm(n)                       # Continuous variable   )    # Binary treatment assignment (50% treated)   D <- rbinom(n, 1, 0.5)    # Define heterogeneous treatment effects based on X   treatment_effect <- ifelse(     X[, binary] == 1 & X[, discrete] <= 2,        # Group 1: Positive effect     1,     ifelse(X[, binary] == 0 & X[, discrete] >= 4, # Group 3: Adverse effect            -1,            0.1)                                   # Group 2: Neutral effect   )    # Outcome depends on treatment effect + noise   Y <- D * (treatment_effect + rnorm(n, mean = 0, sd = 1)) +     (1 - D) * rnorm(n)    return(list(X = X, D = D, Y = Y)) }  # Generate a sample dataset set.seed(123) n <- 1000 data <- generate_data(n) X <- data$X D <- data$D Y <- data$Y"},{"path":"https://yanisvdc.github.io/cramR/articles/cram_policy_part_2.html","id":"built-in-model","dir":"Articles","previous_headings":"Cram Policy","what":"Built-in Model","title":"Cram Policy part 2","text":"example, demonstrate use built-modeling options provided cramR package. walk key parameters control cram_policy() behaves, including choice model, learner type, baseline policy, batching strategy. parameters allow flexibility configuring learning process depending use case nature dataset.","code":"# Options for batch: # Either an integer specifying the number of batches or a vector/list of batch assignments for all individuals batch <- 20  # Model type for estimating treatment effects # Options for model_type: 'causal_forest', 's_learner', 'm_learner' # Note: you can also set model_type to NULL and specify custom_fit and custom_predict to use your custom model model_type <- \"causal_forest\"    # Options for learner_type: # if model_type == 'causal_forest', choose NULL # if model_type == 's_learner' or 'm_learner', choose between 'ridge', 'fnn' and 'caret' learner_type <- NULL    # Baseline policy to compare against (list of 0/1 for each individual) # Options for baseline_policy: # A list representing the baseline policy assignment for each individual. # If NULL, a default baseline policy of zeros is created. # Examples of baseline policy:  # - All-control baseline: as.list(rep(0, nrow(X))) or NULL # - Randomized baseline: as.list(sample(c(0, 1), nrow(X), replace = TRUE)) baseline_policy <- as.list(rep(0, nrow(X)))    # Whether to parallelize batch processing (i.e. the cram method learns T policies, with T the number of batches. # They are learned in parallel when parallelize_batch is TRUE # vs. learned sequentially using the efficient data.table structure when parallelize_batch is FALSE, recommended for light weight training). # Defaults to FALSE. parallelize_batch <- FALSE      # Model-specific parameters (more details in the article \"Quick Start\") # Examples: NULL defaults to the following: # - causal_forest: list(num.trees = 100) # - ridge: list(alpha = 1) # - caret: list(formula = Y ~ ., caret_params = list(method = \"lm\", trControl = trainControl(method = \"none\"))) # - fnn (Feedforward Neural Network): see below # input_shape <- if (model_type == \"s_learner\") ncol(X) + 1 else ncol(X) # default_model_params <- list( #       input_layer = list(units = 64, activation = 'relu', input_shape = input_shape), #       layers = list( #         list(units = 32, activation = 'relu') #       ), #       output_layer = list(units = 1, activation = 'linear'), #       compile_args = list(optimizer = 'adam', loss = 'mse'), #       fit_params = list(epochs = 5, batch_size = 32, verbose = 0) #     ) model_params <- NULL"},{"path":"https://yanisvdc.github.io/cramR/articles/cram_policy_part_2.html","id":"how-to-set-model_params","dir":"Articles","previous_headings":"Cram Policy > Built-in Model","what":"How to set model_params?","title":"Cram Policy part 2","text":"model_params argument allows customize hyperparameters model used policy learning. left NULL, cram_policy() fall back sensible defaults depending model learner type. following, give default examples model_params model_type learner_type illustrate can specify model_params. Generally speaking, model_params list containing parameters used underlying model values: model_type = \"causal_forest\": model_params <- NULL, method defaults grf::causal_forest() model_params <- list(num.trees = 100). model_type = \"s_learner\" \"m_learner\", depends learner_type: learner_type = \"ridge\", model_params <- NULL, method defaults glmnet::cv.glmnet() model_params <- list(alpha = 1), corresponding Ridge regression. learner_type = \"fnn\" (Feedforward Neural Network): default Keras model built following architecture: learner_type = \"caret\", defaults linear regression re sampling (see https://topepo.github.io/caret/model-training--tuning.html details caret train parameters): Please note list contain element formula Y refers vector provided input Y, element named caret_params containing parameters choice pass caret::train (see full list parameters : https://topepo.github.io/caret/model-training--tuning.html).","code":"# Determine the input shape based on model_type # For s_learner, the treatment D is added to the covariates to constitute the training data # So the input shape is ncol(X) + 1 input_shape <- if (model_type == \"s_learner\") ncol(X) + 1 else ncol(X)  default_model_params <- list(     input_layer = list(units = 64, activation = 'relu', input_shape = input_shape),      layers = list(       list(units = 32, activation = 'relu')     ),     output_layer = list(units = 1, activation = 'linear'),     compile_args = list(optimizer = 'adam', loss = 'mse'),     fit_params = list(epochs = 5, batch_size = 32, verbose = 0)   ) default_model_params <- list(formula = Y ~ ., caret_params = list(method = \"lm\", trControl = trainControl(method = \"none\")))"},{"path":"https://yanisvdc.github.io/cramR/articles/cram_policy_part_2.html","id":"case-of-categorical-target-y","dir":"Articles","previous_headings":"Cram Policy > Built-in Model","what":"Case of categorical target Y","title":"Cram Policy part 2","text":"using caret, note Y categorical using model_type = \"s_learner\", need choose classification method outputting probabilities .e.¬†using key word classProbs = TRUE trainControl, see following example Random Forest Classifier: Also note data inputs needs numeric types, hence Y categorical, contain numeric values representing class observation. need use type factor cram_policy(). Note M-learner: model_type = \"m_learner\", keep mind Y transformed internally. M-learner requires propensity model transformed outcomes: propensity argument cram_policy, NULL, defaults outcome_transform element model_params accessed follows: NULL, defaults Thus, Y transformed might categorical even though Y categorical .e.¬†might want use regression model. See following reference details M-learner: Jia, Z., Imai, K., & Li, M. L. (2024). Cram Method Efficient Simultaneous Learning Evaluation, URL: https://www.hbs.edu/ris/Publication%20Files/2403.07031v1_a83462e0-145b-4675-99d5-9754aa65d786.pdf. can override defaults passing custom list model_params including parameter name defined underlying package model chose, namely grf::causal_forest(), glmnet::cv.glmnet(), keras caret::train()","code":"model_params <- list(formula = Y ~ ., caret_params = list(method = \"rf\", trControl = trainControl(method = \"none\", classProbs = TRUE))) propensity <- function(X) {rep(0.5, nrow(X))} outcome_transform <- model_params$m_learner_outcome_transform outcome_transform <- function(Y, D, prop_score) {Y * D / prop_score - Y * (1 - D) / (1 - prop_score)}`, where `prop_score` is `propensity(X) # Significance level for confidence intervals (default = 95%) alpha <- 0.05    # Run the CRAM policy method result <- cram_policy(   X, D, Y,   batch = batch,   model_type = model_type,   learner_type = learner_type,   baseline_policy = baseline_policy,   parallelize_batch = parallelize_batch,   model_params = model_params,   alpha = alpha )  # Display the results print(result) #> $raw_results #>                        Metric   Value #> 1              Delta Estimate 0.23208 #> 2        Delta Standard Error 0.05862 #> 3              Delta CI Lower 0.11718 #> 4              Delta CI Upper 0.34697 #> 5       Policy Value Estimate 0.21751 #> 6 Policy Value Standard Error 0.05237 #> 7       Policy Value CI Lower 0.11486 #> 8       Policy Value CI Upper 0.32016 #> 9          Proportion Treated 0.60500 #>  #> $interactive_table #>  #> $final_policy_model #> GRF forest object of type causal_forest  #> Number of trees: 100  #> Number of training samples: 1000  #> Variable importance:  #>     1     2     3  #> 0.437 0.350 0.213"},{"path":"https://yanisvdc.github.io/cramR/articles/cram_policy_part_2.html","id":"custom-model","dir":"Articles","previous_headings":"Cram Policy","what":"Custom Model","title":"Cram Policy part 2","text":"use model policy learning, trigger set model_type = NULL supply two user-defined functions:","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_policy_part_2.html","id":"custom_fitx-y-d----","dir":"Articles","previous_headings":"Cram Policy > Custom Model","what":"1. custom_fit(X, Y, D, ...)","title":"Cram Policy part 2","text":"function takes training data: covariates X, outcomes Y, binary treatment indicators D, returns fitted model object. may also define use additional parameters (e.g., number folds, regularization settings, etc.) within function body. X: matrix data frame features Y: numeric outcome vector D: binary vector indicating treatment assignment (0 1) Example: Custom X-learner Ridge regression 5-fold cross-validation","code":"library(glmnet) #> Loading required package: Matrix #> Loaded glmnet 4.1-8  custom_fit <- function(X, Y, D, n_folds = 5) {   treated_indices <- which(D == 1)   control_indices <- which(D == 0)   X_treated <- X[treated_indices, ]   Y_treated <- Y[treated_indices]   X_control <- X[control_indices, ]   Y_control <- Y[control_indices]   model_treated <- cv.glmnet(as.matrix(X_treated), Y_treated, alpha = 0, nfolds = n_folds)   model_control <- cv.glmnet(as.matrix(X_control), Y_control, alpha = 0, nfolds = n_folds)   tau_control <- Y_treated - predict(model_control, as.matrix(X_treated), s = \"lambda.min\")   tau_treated <- predict(model_treated, as.matrix(X_control), s = \"lambda.min\") - Y_control   X_combined <- rbind(X_treated, X_control)   tau_combined <- c(tau_control, tau_treated)   weights <- c(rep(1, length(tau_control)), rep(1, length(tau_treated)))   final_model <- cv.glmnet(as.matrix(X_combined), tau_combined, alpha = 0, weights = weights, nfolds = n_folds)   return(final_model) }"},{"path":"https://yanisvdc.github.io/cramR/articles/cram_policy_part_2.html","id":"custom_predictmodel-x_new-d_new","dir":"Articles","previous_headings":"Cram Policy > Custom Model","what":"2. custom_predict(model, X_new, D_new)","title":"Cram Policy part 2","text":"function uses fitted model generate binary treatment decision individual X_new. return vector 0s 1s, indicating whether assign treatment (1) (0). may also incorporate custom threshold post-processing logic within function. Example: Apply decision rule ‚Äî treat estimated CATE greater 0","code":"custom_predict <- function(model, X_new, D_new) {   cate <- predict(model, as.matrix(X_new), s = \"lambda.min\")    # Apply decision rule: treat if CATE > 0   as.integer(cate > 0) }"},{"path":"https://yanisvdc.github.io/cramR/articles/cram_policy_part_2.html","id":"use-cram_policy-with-custom_fit-and-custom_predict","dir":"Articles","previous_headings":"Cram Policy > Custom Model","what":"3. Use cram_policy() with custom_fit() and custom_predict()","title":"Cram Policy part 2","text":"custom_fit() custom_predict() defined, can integrate Cram framework passing cram_policy() shown (forget set model_type = NULL):","code":"experiment_results <- cram_policy(   X, D, Y,   batch = 20,   model_type = NULL,   custom_fit = custom_fit,   custom_predict = custom_predict,   alpha = 0.05 ) print(experiment_results) #> $raw_results #>                        Metric   Value #> 1              Delta Estimate 0.22542 #> 2        Delta Standard Error 0.06004 #> 3              Delta CI Lower 0.10774 #> 4              Delta CI Upper 0.34310 #> 5       Policy Value Estimate 0.21085 #> 6 Policy Value Standard Error 0.04280 #> 7       Policy Value CI Lower 0.12696 #> 8       Policy Value CI Upper 0.29475 #> 9          Proportion Treated 0.54500 #>  #> $interactive_table #>  #> $final_policy_model #>  #> Call:  cv.glmnet(x = as.matrix(X_combined), y = tau_combined, weights = weights,      nfolds = n_folds, alpha = 0)  #>  #> Measure: Mean-Squared Error  #>  #>     Lambda Index Measure      SE Nonzero #> min 0.0395   100  0.9219 0.02942       3 #> 1se 0.5868    71  0.9505 0.03367       3"},{"path":"https://yanisvdc.github.io/cramR/articles/cram_policy_part_2.html","id":"references","dir":"Articles","previous_headings":"Cram Policy","what":"References","title":"Cram Policy part 2","text":"Jia, Z., Imai, K., & Li, M. L. (2024). Cram Method Efficient Simultaneous Learning Evaluation, URL: https://www.hbs.edu/ris/Publication%20Files/2403.07031v1_a83462e0-145b-4675-99d5-9754aa65d786.pdf. K√ºnzel, S. R., Sekhon, J. S., Bickel, P. J., & Yu, B. (2019). Metalearners estimating heterogeneous treatment effects using machine learning. Proceedings National Academy Sciences United States America, 116(10), 4156‚Äì4165. https://doi.org/10.1073/pnas.1804597116 Wager, S., & Athey, S. (2018). Estimation inference heterogeneous treatment effects using random forests. Journal American Statistical Association, 113(523), 1228-1242. Athey, S., & Imbens, G. (2016). Recursive partitioning heterogeneous causal effects. Proceedings National Academy Sciences, 113(27), 7353-7360.","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_policy_simulation.html","id":"what-is-cram_simulation","dir":"Articles","previous_headings":"","what":"üéØ What is cram_simulation()?","title":"Cram Policy Simulation","text":"cram_simulation() function performs simultaneous policy learning evaluation known data-generating process (DGP). useful : Benchmarking performance Cram method controlled simulated datasets Measuring empirical bias, variance, confidence interval coverage estimates Supporting synthetic covariate generation known DGP provided user (dgp_X), empirical covariate generation based input dataset (X) using row-wise bootstrapping, approximates empirical distribution observed covariates.","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_policy_simulation.html","id":"inputs-overview","dir":"Articles","previous_headings":"","what":"üì¶ Inputs Overview","title":"Cram Policy Simulation","text":"must supply either: X: dataset bootstrap (empirical DGP)dgp_X: function simulates covariates must also define: dgp_D(X): treatment assignment function given X dgp_Y(D, X): outcome generation function given D X","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/cram_policy_simulation.html","id":"example-cram-policy-simulation","dir":"Articles","previous_headings":"","what":"üìò Example: Cram Policy Simulation","title":"Cram Policy Simulation","text":"","code":"set.seed(123)  # dgp_X <- function(n) { #   data.table::data.table( #     binary     = rbinom(n, 1, 0.5), #     discrete   = sample(1:5, n, replace = TRUE), #     continuous = rnorm(n) #   ) # }  n <- 100  X_data <- data.table::data.table(     binary     = rbinom(n, 1, 0.5),     discrete   = sample(1:5, n, replace = TRUE),     continuous = rnorm(n)   )   dgp_D <- function(X) rbinom(nrow(X), 1, 0.5)  dgp_Y <- function(D, X) {   theta <- ifelse(     X[, binary] == 1 & X[, discrete] <= 2,  # Group 1: High benefit     1,     ifelse(X[, binary] == 0 & X[, discrete] >= 4,  # Group 3: Negative benefit            -1,            0.1)  # Group 2: Neutral effect   )   Y <- D * (theta + rnorm(length(D), mean = 0, sd = 1)) +     (1 - D) * rnorm(length(D))  # Outcome for untreated   return(Y) }  # Parameters nb_simulations <- 100 nb_simulations_truth <- 200 batch <- 5  # Perform CRAM simulation result <- cram_simulation(   X = X_data,   dgp_D = dgp_D,   dgp_Y = dgp_Y,   batch = batch,   nb_simulations = nb_simulations,   nb_simulations_truth = nb_simulations_truth,   sample_size = 500 )"},{"path":"https://yanisvdc.github.io/cramR/articles/cram_policy_simulation.html","id":"output-summary","dir":"Articles","previous_headings":"","what":"üìä Output Summary","title":"Cram Policy Simulation","text":"Returns list containing: raw_results: summary key averaged metrics interactive_table: interactive HTML widget quick exploration","code":"result$raw_results #>                                  Metric   Value #> 1            Average Proportion Treated 0.52724 #> 2                Average Delta Estimate 0.22597 #> 3          Average Delta Standard Error 0.10424 #> 4                  Delta Empirical Bias 0.01224 #> 5              Delta Empirical Coverage 0.96000 #> 6         Variance Delta Empirical Bias 0.00220 #> 7         Average Policy Value Estimate 0.22580 #> 8   Average Policy Value Standard Error 0.10080 #> 9           Policy Value Empirical Bias 0.01210 #> 10      Policy Value Empirical Coverage 0.92000 #> 11 Variance Policy Value Empirical Bias 0.00071 result$interactive_table"},{"path":"https://yanisvdc.github.io/cramR/articles/quickstart.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Quick Start with CRAM","text":"Cram package provides unified framework : üß† Cram Policy (cram_policy): Learn evaluate individualized binary treatment rules using Cram. Supports flexible models, including causal forests custom learners. Common examples include whether treat patient, send discount offer, provide financial aid based estimated benefit. üìà Cram ML (cram_ml): Learn evaluate standard machine learning models using Cram. estimates expected loss population level, giving reliable measure well final model likely generalize new data. Supports flexible training via caret custom learners, allows evaluation user-defined loss metrics. Ideal classification, regression, predictive tasks. üé∞ Cram Bandit (cram_bandit): Perform -policy evaluation contextual bandit algorithms using Cram. Supports real data simulation environments built-policies. vignette walks three core modules.","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/quickstart.html","id":"cram-user-file","dir":"Articles","previous_headings":"","what":"Cram User file","title":"Quick Start with CRAM","text":"reproducible use cases, see example script provided Cram GitHub repository: View user_cram.R GitHub","code":""},{"path":[]},{"path":"https://yanisvdc.github.io/cramR/articles/quickstart.html","id":"generate-simulated-data","dir":"Articles","previous_headings":"1. cram_policy() ‚Äî Binary Policy Learning & Evaluation","what":"Generate Simulated Data","title":"Quick Start with CRAM","text":"","code":"generate_data <- function(n) {   X <- data.table(     binary = rbinom(n, 1, 0.5),     discrete = sample(1:5, n, replace = TRUE),     continuous = rnorm(n)   )   D <- rbinom(n, 1, 0.5)   treatment_effect <- ifelse(X$binary == 1 & X$discrete <= 2, 1,                        ifelse(X$binary == 0 & X$discrete >= 4, -1, 0.1))   Y <- D * (treatment_effect + rnorm(n)) + (1 - D) * rnorm(n)   list(X = X, D = D, Y = Y) }  set.seed(123) data <- generate_data(1000) X <- data$X; D <- data$D; Y <- data$Y"},{"path":"https://yanisvdc.github.io/cramR/articles/quickstart.html","id":"run-cram_policy-with-causal-forest","dir":"Articles","previous_headings":"1. cram_policy() ‚Äî Binary Policy Learning & Evaluation","what":"Run cram_policy() with causal forest","title":"Quick Start with CRAM","text":"","code":"res <- cram_policy(   X, D, Y,   batch = 20,   model_type = \"causal_forest\",   learner_type = NULL,   baseline_policy = as.list(rep(0, nrow(X))),   alpha = 0.05 ) print(res) #> $raw_results #>                        Metric   Value #> 1              Delta Estimate 0.23208 #> 2        Delta Standard Error 0.05862 #> 3              Delta CI Lower 0.11718 #> 4              Delta CI Upper 0.34697 #> 5       Policy Value Estimate 0.21751 #> 6 Policy Value Standard Error 0.05237 #> 7       Policy Value CI Lower 0.11486 #> 8       Policy Value CI Upper 0.32016 #> 9          Proportion Treated 0.60500 #>  #> $interactive_table #>  #> $final_policy_model #> GRF forest object of type causal_forest  #> Number of trees: 100  #> Number of training samples: 1000  #> Variable importance:  #>     1     2     3  #> 0.437 0.350 0.213"},{"path":"https://yanisvdc.github.io/cramR/articles/quickstart.html","id":"case-of-categorical-target-y","dir":"Articles","previous_headings":"1. cram_policy() ‚Äî Binary Policy Learning & Evaluation","what":"Case of categorical target Y","title":"Quick Start with CRAM","text":"Use caret choose classification method outputting probabilities .e.¬†using key word classProbs = TRUE trainControl, see following example Random Forest Classifier: Also note data inputs needs numeric types, hence Y categorical, contain numeric values representing class observation. need use type factor cram_policy().","code":"model_params <- list(formula = Y ~ ., caret_params = list(method = \"rf\", trControl = trainControl(method = \"none\", classProbs = TRUE)))"},{"path":"https://yanisvdc.github.io/cramR/articles/quickstart.html","id":"custom-models-with-cram_policy","dir":"Articles","previous_headings":"1. cram_policy() ‚Äî Binary Policy Learning & Evaluation","what":"Custom Models with cram_policy()","title":"Quick Start with CRAM","text":"Set model_params NULL specify custom_fit custom_predict.","code":"custom_fit <- function(X, Y, D, n_folds = 5) {   treated <- which(D == 1); control <- which(D == 0)   m1 <- cv.glmnet(as.matrix(X[treated, ]), Y[treated], alpha = 0, nfolds = n_folds)   m0 <- cv.glmnet(as.matrix(X[control, ]), Y[control], alpha = 0, nfolds = n_folds)   tau1 <- predict(m1, as.matrix(X[control, ]), s = \"lambda.min\") - Y[control]   tau0 <- Y[treated] - predict(m0, as.matrix(X[treated, ]), s = \"lambda.min\")   tau <- c(tau0, tau1); X_all <- rbind(X[treated, ], X[control, ])   final_model <- cv.glmnet(as.matrix(X_all), tau, alpha = 0)   final_model }  custom_predict <- function(model, X, D) {   as.numeric(predict(model, as.matrix(X), s = \"lambda.min\") > 0) }  res <- cram_policy(   X, D, Y,   batch = 20,   model_type = NULL,   custom_fit = custom_fit,   custom_predict = custom_predict ) print(res) #> $raw_results #>                        Metric   Value #> 1              Delta Estimate 0.22542 #> 2        Delta Standard Error 0.06004 #> 3              Delta CI Lower 0.10774 #> 4              Delta CI Upper 0.34310 #> 5       Policy Value Estimate 0.21085 #> 6 Policy Value Standard Error 0.04280 #> 7       Policy Value CI Lower 0.12696 #> 8       Policy Value CI Upper 0.29475 #> 9          Proportion Treated 0.54500 #>  #> $interactive_table #>  #> $final_policy_model #>  #> Call:  cv.glmnet(x = as.matrix(X_all), y = tau, alpha = 0)  #>  #> Measure: Mean-Squared Error  #>  #>     Lambda Index Measure      SE Nonzero #> min 0.0395   100  0.9194 0.02589       3 #> 1se 0.4872    73  0.9423 0.03002       3"},{"path":[]},{"path":"https://yanisvdc.github.io/cramR/articles/quickstart.html","id":"regression-with-cram_ml","dir":"Articles","previous_headings":"2. cram_ml() ‚Äî ML Learning & Evaluation","what":"Regression with cram_ml()","title":"Quick Start with CRAM","text":"Specify formula caret_paramsconforming popular caret::train() set individual loss loss_name.","code":"set.seed(42) data_df <- data.frame(   x1 = rnorm(100), x2 = rnorm(100), x3 = rnorm(100), Y = rnorm(100) )  caret_params <- list(   method = \"lm\",   trControl = trainControl(method = \"none\") )  res <- cram_ml(   data = data_df,   formula = Y ~ .,   batch = 5,   loss_name = \"se\",   caret_params = caret_params ) print(res) #> $raw_results #>                         Metric    Value #> 1       Expected Loss Estimate  0.86429 #> 2 Expected Loss Standard Error  0.73665 #> 3       Expected Loss CI Lower -0.57952 #> 4       Expected Loss CI Upper  2.30809 #>  #> $interactive_table #>  #> $final_ml_model #> Linear Regression  #>  #> 100 samples #>   3 predictor #>  #> No pre-processing #> Resampling: None"},{"path":"https://yanisvdc.github.io/cramR/articles/quickstart.html","id":"classification-with-cram_ml","dir":"Articles","previous_headings":"2. cram_ml() ‚Äî ML Learning & Evaluation","what":"Classification with cram_ml()","title":"Quick Start with CRAM","text":"data inputs needs numeric types, hence Y categorical, contain numeric values representing class observation. need use type factor cram_ml().","code":""},{"path":"https://yanisvdc.github.io/cramR/articles/quickstart.html","id":"case-1-predicting-class-labels","dir":"Articles","previous_headings":"2. cram_ml() ‚Äî ML Learning & Evaluation > Classification with cram_ml()","what":"Case 1: Predicting Class labels","title":"Quick Start with CRAM","text":"case, model outputs hard predictions (labels, e.g.¬†0, 1, 2 etc.), metric used classification accuracy‚Äîproportion correctly predicted labels. Use loss_name = \"accuracy\" Set classProbs = FALSE trainControl Set classify = TRUE cram_ml()","code":"set.seed(42)  # Generate binary classification dataset X_data <- data.frame(x1 = rnorm(100), x2 = rnorm(100), x3 = rnorm(100)) Y_data <- rbinom(nrow(X_data), 1, 0.5) data_df <- data.frame(X_data, Y = Y_data)  # Define caret parameters: predict labels (default behavior) caret_params_rf <- list(   method = \"rf\",   trControl = trainControl(method = \"none\") )  # Run CRAM ML with accuracy as loss result <- cram_ml(   data = data_df,   formula = Y ~ .,   batch = 5,   loss_name = \"accuracy\",   caret_params = caret_params_rf,   classify = TRUE )  print(result) #> $raw_results #>                         Metric    Value #> 1       Expected Loss Estimate  0.48750 #> 2 Expected Loss Standard Error  0.43071 #> 3       Expected Loss CI Lower -0.35668 #> 4       Expected Loss CI Upper  1.33168 #>  #> $interactive_table #>  #> $final_ml_model #> Random Forest  #>  #> 100 samples #>   3 predictor #>   2 classes: 'class0', 'class1'  #>  #> No pre-processing #> Resampling: None"},{"path":"https://yanisvdc.github.io/cramR/articles/quickstart.html","id":"case-2-predicting-class-probabilities","dir":"Articles","previous_headings":"2. cram_ml() ‚Äî ML Learning & Evaluation > Classification with cram_ml()","what":"Case 2: Predicting Class Probabilities","title":"Quick Start with CRAM","text":"setup, model outputs class probabilities, loss evaluated using logarithmic loss (logloss)‚Äîstandard metric probabilistic classification. Use loss_name = \"logloss\" Set classProbs = TRUE trainControl Set classify = TRUE cram_ml() addition using built-learners via caret, cram_ml() also supports fully custom model workflows. can specify : Model fitting function (custom_fit) Prediction function (custom_predict) Loss function (custom_loss) See vignette ‚ÄúCram ML‚Äù details.","code":"set.seed(42)  # Generate binary classification dataset X_data <- data.frame(x1 = rnorm(100), x2 = rnorm(100), x3 = rnorm(100)) Y_data <- rbinom(nrow(X_data), 1, 0.5) data_df <- data.frame(X_data, Y = Y_data)  # Define caret parameters for probability output caret_params_rf_probs <- list(   method = \"rf\",   trControl = trainControl(method = \"none\", classProbs = TRUE) )  # Run CRAM ML with logloss as the evaluation loss result <- cram_ml(   data = data_df,   formula = Y ~ .,   batch = 5,   loss_name = \"logloss\",   caret_params = caret_params_rf_probs,   classify = TRUE )  print(result) #> $raw_results #>                         Metric    Value #> 1       Expected Loss Estimate  0.93225 #> 2 Expected Loss Standard Error  0.48118 #> 3       Expected Loss CI Lower -0.01085 #> 4       Expected Loss CI Upper  1.87534 #>  #> $interactive_table #>  #> $final_ml_model #> Random Forest  #>  #> 100 samples #>   3 predictor #>   2 classes: 'class0', 'class1'  #>  #> No pre-processing #> Resampling: None"},{"path":"https://yanisvdc.github.io/cramR/articles/quickstart.html","id":"cram_bandit-contextual-bandits-for-on-policy-statistical-evaluation","dir":"Articles","previous_headings":"","what":"3. cram_bandit() ‚Äî Contextual Bandits for On-policy Statistical Evaluation","title":"Quick Start with CRAM","text":"Specify: pi: array shape (T √ó B, T, K) (T √ó B, T), : TT number learning steps (policy updates) BB batch size KK number arms T√óBT \\times B total number contexts natural 3D version, pi[j, t, ] gives probability policy œÄÃÇt\\hat{\\pi}_t assigns arm context XjX_j. 2D version, keep probabilities assigned chosen arm AjA_j context XjX_j historical data - probabilities arms aa context XjX_j. arm: vector length T√óBT \\times B indicating arm selected context. reward: vector observed rewards length T√óBT \\times B. batch: (optional) Integer batch size BB. Default 1. alpha: Significance level confidence intervals.","code":"set.seed(42) T <- 100; K <- 4 pi <- array(runif(T * T * K, 0.1, 1), dim = c(T, T, K)) for (t in 1:T) for (j in 1:T) pi[j, t, ] <- pi[j, t, ] / sum(pi[j, t, ]) arm <- sample(1:K, T, replace = TRUE) reward <- rnorm(T, 1, 0.5)  res <- cram_bandit(pi, arm, reward, batch=1, alpha=0.05) print(res) #> $raw_results #>                        Metric   Value #> 1       Policy Value Estimate 0.67621 #> 2 Policy Value Standard Error 0.04394 #> 3       Policy Value CI Lower 0.59008 #> 4       Policy Value CI Upper 0.76234 #>  #> $interactive_table"},{"path":"https://yanisvdc.github.io/cramR/articles/quickstart.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Quick Start with CRAM","text":"cram_policy(): Learn evaluate binary policy. cram_ml(): Learn evaluate ML models. cram_bandit(): Cramming contextual bandits -policy statistical evaluation.","code":""},{"path":"https://yanisvdc.github.io/cramR/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Yanis Vandecasteele. Maintainer, author. Michael Lingzhi Li. Contributor. Kosuke Imai. Contributor. Zeyang Jia. Contributor. Longlin Wang. Contributor.","code":""},{"path":"https://yanisvdc.github.io/cramR/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Vandecasteele Y, Li M, Imai K, Jia Z, Wang L (2025). cramR: Cram Method Efficient Simultaneous Learning Evaluation. Package developed maintained Yanis Vandecasteele., https://github.com/yanisvdc/cramR. Jia Z, Imai K, Li M (2024). ‚ÄúCram Method Efficient Simultaneous Learning Evaluation.‚Äù Harvard Business School. Accessed April 2025, https://www.hbs.edu/ris/Publication%20Files/2403.07031v1_a83462e0-145b-4675-99d5-9754aa65d786.pdf. Jia Z, Imai K, Li M (2025). ‚ÄúCramming Contextual Bandits -policy Statistical Evaluation.‚Äù 2403.07031, https://arxiv.org/abs/2403.07031.","code":"@Manual{,   title = {cramR: The Cram Method for Efficient Simultaneous Learning and Evaluation},   author = {Yanis Vandecasteele and Michael Lingzhi Li and Kosuke Imai and Zeyang Jia and Longlin Wang},   year = {2025},   note = {Package developed and maintained by Yanis Vandecasteele.},   url = {https://github.com/yanisvdc/cramR}, } @TechReport{,   title = {The Cram Method for Efficient Simultaneous Learning and Evaluation},   author = {Zeyang Jia and Kosuke Imai and Michael Lingzhi Li},   institution = {Harvard Business School},   year = {2024},   url = {https://www.hbs.edu/ris/Publication%20Files/2403.07031v1_a83462e0-145b-4675-99d5-9754aa65d786.pdf},   note = {Accessed April 2025}, } @Misc{,   title = {Cramming Contextual Bandits for On-policy Statistical Evaluation},   author = {Zeyang Jia and Kosuke Imai and Michael Lingzhi Li},   year = {2025},   eprint = {2403.07031},   archiveprefix = {arXiv},   primaryclass = {cs.LG},   url = {https://arxiv.org/abs/2403.07031}, }"},{"path":[]},{"path":"https://yanisvdc.github.io/cramR/index.html","id":"overview","dir":"","previous_headings":"üìö What is Cram?","what":"Overview","title":"CRAM","text":"üéØ Train & Evaluate ML Models üîÅ Cram vs.¬†Sample-Splitting & Cross-Validation üß† Typical use case: Policy Learning üåç Real-World Applications Please visit official website details.","code":""},{"path":"https://yanisvdc.github.io/cramR/index.html","id":"id_-train--evaluate-ml-models","dir":"","previous_headings":"üìö What is Cram?","what":"üéØ Train & Evaluate ML models","title":"CRAM","text":"Cram method efficient approach simultaneous learning evaluation using generic machine learning (ML) algorithm. single pass batched data, proposed method repeatedly trains ML algorithm tests empirical performance.","code":""},{"path":"https://yanisvdc.github.io/cramR/index.html","id":"id_-cram-vs-sample-splitting--cross-validation","dir":"","previous_headings":"üìö What is Cram?","what":"üîÅ Cram vs.¬†Sample-Splitting & Cross-Validation","title":"CRAM","text":"utilizes entire sample learning evaluation, cramming significantly data-efficient sample-splitting, reserves portion data purely evaluation. Also, key distinction cross-validation Cram evaluates final learned model directly, rather using proxy average performance multiple fold-specific models trained different data subsets‚Äîresulting sharper inference better alignment real-world deployment. details Cram procedure can found article Introduction & Cram Policy part 1.","code":""},{"path":"https://yanisvdc.github.io/cramR/index.html","id":"id_-typical-use-case-policy-learning","dir":"","previous_headings":"üìö What is Cram?","what":"üß† Typical use case: Policy Learning","title":"CRAM","text":"Cram method naturally applies policy learning setting, popular subfield ML focused learning decision rule (also called treatment rule policy) assigns treatments actions individuals based features, goal maximizing expected outcome (e.g., health, profit, welfare). Cramming allows users learn individualized decision rule estimate average outcome result learned decision rule deployed entire population beyond data sample.","code":""},{"path":"https://yanisvdc.github.io/cramR/index.html","id":"id_-real-world-applications","dir":"","previous_headings":"üìö What is Cram?","what":"üåç Real-World Applications","title":"CRAM","text":"particularly relevant high-stakes applications decisions must personalized statistically reliable. Common examples include: Healthcare: determining receive treatment based individual characteristics Advertising pricing: setting optimal prices maximize revenue Policy interventions: deciding individuals regions receive targeted support improve outcomes","code":""},{"path":"https://yanisvdc.github.io/cramR/index.html","id":"id_-key-features","dir":"","previous_headings":"","what":"üéØ Key Features","title":"CRAM","text":"üß† Cram Policy (cram_policy): Learn evaluate individualized binary treatment rules using Cram. Supports flexible models, including causal forests custom learners. Common examples include whether treat patient, send discount offer, provide financial aid based estimated benefit. üìà Cram ML (cram_ml): Learn evaluate standard machine learning models using Cram. estimates expected loss population level, giving reliable measure well final model likely generalize new data. Supports flexible training via caret custom learners, allows evaluation user-defined loss metrics. Ideal classification, regression, predictive tasks. üé∞ Cram Bandit (cram_bandit): Perform -policy evaluation contextual bandit algorithms using Cram. Supports real data simulation environments built-policies. users ML background, may informative compare supervised learning introduce contextual bandit setting. supervised learning, data point comes known label. contrast, contextual bandit setting involves context (feature vector), choice among multiple actions, reward observed chosen action. Thus, label (reward) first unknown revealed action chosen - note labels (rewards) associated non-chosen actions remain unknown (partial feedback), makes learning evaluation challenging. Contextual bandits appear applications online system selects actions based context maximize outcomes‚Äîlike showing ads recommendations observing user clicks purchases. Contextual bandit algorithms aim learn policy chooses best action context maximize expected reward, engagement (clicks) conversion. Cram Bandit estimates well final learned policy perform deployed entire population, based data collected policy.","code":""},{"path":"https://yanisvdc.github.io/cramR/index.html","id":"id_-documentation","dir":"","previous_headings":"","what":"üìö Documentation","title":"CRAM","text":"Introduction & Cram Policy part 1 Function Reference ‚Äôs New can also explore additional tutorials examples ‚ÄúArticles‚Äù menu top navigation bar website.","code":""},{"path":"https://yanisvdc.github.io/cramR/index.html","id":"id_Ô∏è-installation","dir":"","previous_headings":"","what":"üõ†Ô∏è Installation","title":"CRAM","text":"install development version Cram GitHub:","code":"# Install devtools if needed install.packages(\"devtools\")  # Install cramR from GitHub devtools::install_github(\"yanisvdc/cramR\")"},{"path":[]},{"path":"https://yanisvdc.github.io/cramR/index.html","id":"id_-citation","dir":"","previous_headings":"üìÑ Citation & ü§ù Contributing","what":"üìö Citation","title":"CRAM","text":"use Cram research, please cite following papers: can also cite R package:","code":"@techreport{jia2024cram,   title        = {The Cram Method for Efficient Simultaneous Learning and Evaluation},   author       = {Jia, Zeyang and Imai, Kosuke and Li, Michael Lingzhi},   institution  = {Harvard Business School},   type         = {Working Paper},   year         = {2024},   url          = {https://www.hbs.edu/ris/Publication%20Files/2403.07031v1_a83462e0-145b-4675-99d5-9754aa65d786.pdf},   note         = {Accessed April 2025} } @misc{jia2025crammingcontextualbanditsonpolicy,       title={Cramming Contextual Bandits for On-policy Statistical Evaluation},        author={Zeyang Jia and Kosuke Imai and Michael Lingzhi Li},       year={2025},       eprint={2403.07031},       archivePrefix={arXiv},       primaryClass={cs.LG},       url={https://arxiv.org/abs/2403.07031},  } @Manual{,   title = {cramR: The Cram Method for Efficient Simultaneous Learning and Evaluation},   author = {Yanis Vandecasteele and Michael Lingzhi Li and Kosuke Imai and Zeyang Jia and Longlin Wang},   year = {2025},   note = {Package developed and maintained by Yanis Vandecasteele.},   url = {https://github.com/yanisvdc/cramR}, }"},{"path":"https://yanisvdc.github.io/cramR/index.html","id":"id_-how-to-contribute","dir":"","previous_headings":"üìÑ Citation & ü§ù Contributing","what":"ü§ù How to Contribute","title":"CRAM","text":"welcome contributions! contribute:","code":"# 1. Fork the repository.  # 2. Create a new branch git checkout -b feature/your-feature  # 3. Commit your changes git commit -am 'Add some feature'  # 4. Push to the branch git push origin feature/your-feature  # 5. Create a pull request.  # 6. Open an Issue or PR at: # https://github.com/yanisvdc/cramR/issues"},{"path":"https://yanisvdc.github.io/cramR/index.html","id":"id_-contact","dir":"","previous_headings":"","what":"üìß Contact","title":"CRAM","text":"questions issues, please open issue.","code":""},{"path":"https://yanisvdc.github.io/cramR/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 Yanis Vandecasteele Permission hereby granted, free charge, person obtaining copy software associated documentation files (‚ÄúSoftware‚Äù), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED ‚Äú‚Äù, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/averaged_cram.html","id":null,"dir":"Reference","previous_headings":"","what":"Averaged CRAM with Permutations ‚Äî averaged_cram","title":"Averaged CRAM with Permutations ‚Äî averaged_cram","text":"function implements Averaged CRAM randomly permuting batches (except last batch kept ) averaging performance results.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/averaged_cram.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Averaged CRAM with Permutations ‚Äî averaged_cram","text":"","code":"averaged_cram(   X,   D,   Y,   batch,   model_type,   learner_type = NULL,   alpha = 0.05,   baseline_policy = NULL,   parallelize_batch = FALSE,   model_params = NULL,   custom_fit = NULL,   custom_predict = NULL,   num_permutations = 10 )"},{"path":"https://yanisvdc.github.io/cramR/reference/averaged_cram.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Averaged CRAM with Permutations ‚Äî averaged_cram","text":"X matrix data frame covariates. D binary vector treatment indicators (0 1). Y vector outcomes. batch Either integer specifying number batches (created random sampling) vector length equal sample size providing batch assignment (index) individual sample. model_type model type policy learning. Options include \"causal_forest\", \"s_learner\", \"m_learner\". Default \"causal_forest\". learner_type learner type chosen model. Options include \"ridge\" Ridge Regression \"fnn\" Feedforward Neural Network. Default \"ridge\". alpha Significance level confidence intervals. Default 0.05 (95% confidence). baseline_policy list providing baseline policy (binary 0 1) sample. NULL, defaults list zeros length number rows X. parallelize_batch Logical. Whether parallelize batch processing (.e. cram method learns T policies, T number batches. learned parallel parallelize_batch TRUE vs. learned sequentially using efficient data.table structure parallelize_batch FALSE, recommended light weight training). Defaults FALSE. model_params list additional parameters pass model, can parameter defined model reference package. Defaults NULL. custom_fit custom, user-defined, function outputs fitted model given training data (allows flexibility). Defaults NULL. custom_predict custom, user-defined, function making predictions given fitted model test data (allow flexibility). Defaults NULL. num_permutations Number random permutations batches.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/averaged_cram.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Averaged CRAM with Permutations ‚Äî averaged_cram","text":"list averaged performance variance estimates.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/averaged_cram.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Averaged CRAM with Permutations ‚Äî averaged_cram","text":"","code":"X <- matrix(rnorm(1000), nrow = 100, ncol = 10) D <- sample(0:1, 100, replace = TRUE) Y <- rnorm(100) avg_cram_results <- averaged_cram(X, D, Y,                                   batch = 20,                                   model_type = \"m_learner\",                                   learner_type = \"ridge\",                                   num_permutations = 3) #> Warning: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold #> Warning: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold #> Warning: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold #> Warning: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold #> Warning: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold #> Warning: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold #> Warning: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold"},{"path":"https://yanisvdc.github.io/cramR/reference/cram_bandit.html","id":null,"dir":"Reference","previous_headings":"","what":"Cram Bandit: On-policy Statistical Evaluation in Contextual Bandits ‚Äî cram_bandit","title":"Cram Bandit: On-policy Statistical Evaluation in Contextual Bandits ‚Äî cram_bandit","text":"Performs Cram method -policy Statistical Evaluation Contextual Bandits","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/cram_bandit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cram Bandit: On-policy Statistical Evaluation in Contextual Bandits ‚Äî cram_bandit","text":"","code":"cram_bandit(pi, arm, reward, batch = 1, alpha = 0.05)"},{"path":"https://yanisvdc.github.io/cramR/reference/cram_bandit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cram Bandit: On-policy Statistical Evaluation in Contextual Bandits ‚Äî cram_bandit","text":"pi array shape (T √ó B, T, K) (T √ó B, T), T number learning steps (policy updates), B batch size, K number arms, T x B total number contexts. 3D, pi[j, t, ] gives probability policy pi_t assigns arm context X_j. 2D, pi[j, t] gives probability policy pi_t assigns arm A_j (arm actually chosen X_j history) context X_j. Please see vignette details. arm vector length T x B indicating arm selected context reward vector observed rewards length T x B batch (Optional) vector integer. vector, gives batch assignment context. integer, interpreted batch size contexts assigned batch order dataset. Default 1. alpha Significance level confidence intervals calculating empirical coverage. Default 0.05 (95% confidence).","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/cram_bandit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cram Bandit: On-policy Statistical Evaluation in Contextual Bandits ‚Äî cram_bandit","text":"list containing: raw_results data frame summarizing key metrics:   Empirical Bias Policy Value,   Average relative error Policy Value,   RMSE using relative errors Policy Value,   Empirical Coverage Confidence Intervals. interactive_table interactive table summarizing key metrics user-friendly interface.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/cram_bandit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cram Bandit: On-policy Statistical Evaluation in Contextual Bandits ‚Äî cram_bandit","text":"","code":"# Example with batch size of 1  # Set random seed for reproducibility set.seed(42)  # Define parameters T <- 100  # Number of timesteps K <- 4    # Number of arms  # Simulate a 3D array pi of shape (T, T, K) # - First dimension: Individuals (context Xj) # - Second dimension: Time steps (pi_t) # - Third dimension: Arms (depth) pi <- array(runif(T * T * K, 0.1, 1), dim = c(T, T, K))  # Normalize probabilities so that each row sums to 1 across arms for (t in 1:T) {   for (j in 1:T) {     pi[j, t, ] <- pi[j, t, ] / sum(pi[j, t, ])     }  }  # Simulate arm selections (randomly choosing an arm) arm <- sample(1:K, T, replace = TRUE)  # Simulate rewards (assume normally distributed rewards) reward <- rnorm(T, mean = 1, sd = 0.5)  result <- cram_bandit(pi, arm, reward, batch=1, alpha=0.05) result$raw_results #>                        Metric   Value #> 1       Policy Value Estimate 0.67621 #> 2 Policy Value Standard Error 0.04394 #> 3       Policy Value CI Lower 0.59008 #> 4       Policy Value CI Upper 0.76234 result$interactive_table  {\"x\":{\"filter\":\"none\",\"vertical\":false,\"caption\":\"<caption>CRAM Bandit Policy Evaluation Results<\\/caption>\",\"data\":[[\"1\",\"2\",\"3\",\"4\"],[\"Policy Value Estimate\",\"Policy Value Standard Error\",\"Policy Value CI Lower\",\"Policy Value CI Upper\"],[0.67621,0.04394,0.59008,0.76234]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>Metric<\\/th>\\n      <th>Value<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"pageLength\":5,\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":2},{\"orderable\":false,\"targets\":0},{\"name\":\" \",\"targets\":0},{\"name\":\"Metric\",\"targets\":1},{\"name\":\"Value\",\"targets\":2}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false,\"lengthMenu\":[5,10,25,50,100]},\"selection\":{\"mode\":\"multiple\",\"selected\":null,\"target\":\"row\",\"selectable\":null}},\"evals\":[],\"jsHooks\":[]}"},{"path":"https://yanisvdc.github.io/cramR/reference/cram_bandit_est.html","id":null,"dir":"Reference","previous_headings":"","what":"Cram Bandit Policy Value Estimate ‚Äî cram_bandit_est","title":"Cram Bandit Policy Value Estimate ‚Äî cram_bandit_est","text":"function implements contextual armed bandit -policy evaluation providing policy value estimate.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/cram_bandit_est.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cram Bandit Policy Value Estimate ‚Äî cram_bandit_est","text":"","code":"cram_bandit_est(pi, reward, arm, batch = 1)"},{"path":"https://yanisvdc.github.io/cramR/reference/cram_bandit_est.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cram Bandit Policy Value Estimate ‚Äî cram_bandit_est","text":"pi array shape (T √ó B, T, K) (T √ó B, T), T number learning steps (policy updates), B batch size, K number arms, T x B total number contexts. 3D, pi[j, t, ] gives probability policy pi_t assigns arm context X_j. 2D, pi[j, t] gives probability policy pi_t assigns arm A_j (arm actually chosen X_j history) context X_j. Please see vignette details. reward vector observed rewards length T x B arm vector length T x B indicating arm selected context batch (Optional) vector integer. vector, gives batch assignment context. integer, interpreted batch size contexts assigned batch order dataset. Default 1.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/cram_bandit_est.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cram Bandit Policy Value Estimate ‚Äî cram_bandit_est","text":"estimated policy value.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/cram_bandit_sim.html","id":null,"dir":"Reference","previous_headings":"","what":"Cram Bandit Simulation ‚Äî cram_bandit_sim","title":"Cram Bandit Simulation ‚Äî cram_bandit_sim","text":"function runs -policy simulation contextual bandit algorithms using Cram method. evaluates statistical properties policy value estimates.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/cram_bandit_sim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cram Bandit Simulation ‚Äî cram_bandit_sim","text":"","code":"cram_bandit_sim(   horizon,   simulations,   bandit,   policy,   alpha = 0.05,   do_parallel = FALSE,   seed = 42 )"},{"path":"https://yanisvdc.github.io/cramR/reference/cram_bandit_sim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cram Bandit Simulation ‚Äî cram_bandit_sim","text":"horizon integer specifying number timesteps (rounds) per simulation. simulations integer specifying number independent Monte Carlo simulations perform. bandit contextual bandit environment object generates contexts (feature vectors) observed rewards arm chosen. policy policy object takes context selects arm (action) timestep. alpha Significance level confidence intervals calculating empirical coverage. Default 0.05 (95% confidence). do_parallel Whether parallelize simulations. Default FALSE. recommend keeping FALSE unless necessary, please see vignette. seed optional integer set random seed reproducibility. NULL, seed set.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/cram_bandit_sim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cram Bandit Simulation ‚Äî cram_bandit_sim","text":"list containing: estimates table containing detailed history estimates errors simulation. raw_results data frame summarizing key metrics:   Empirical Bias Policy Value,   Average relative error Policy Value,   RMSE using relative errors Policy Value,   Empirical Coverage Confidence Intervals. interactive_table interactive table summarizing key metrics user-friendly interface.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/cram_bandit_sim.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cram Bandit Simulation ‚Äî cram_bandit_sim","text":"","code":"if (FALSE) { # \\dontrun{ # Number of time steps horizon       <- 500L  # Number of simulations simulations   <- 100L  # Number of arms k = 4  # Number of context features d= 3  # Reward beta parameters of linear model (the outcome generation models, # one for each arm, are linear with arm-specific parameters betas) list_betas <- cramR:::get_betas(simulations, d, k)  # Define the contextual linear bandit, where sigma is the scale # of the noise in the outcome linear model bandit        <- cramR:::ContextualLinearBandit$new(k = k,                                                     d = d,                                                     list_betas = list_betas,                                                     sigma = 0.3)  # Define the policy object (choose between Contextual Epsilon Greedy, # UCB Disjoint and Thompson Sampling) policy <- cramR:::BatchContextualEpsilonGreedyPolicy$new(epsilon=0.1,                                                          batch_size=5) # policy <- cramR:::BatchLinUCBDisjointPolicyEpsilon$new(alpha=1.0,epsilon=0.1,batch_size=1) # policy <- cramR:::BatchContextualLinTSPolicy$new(v = 0.1, batch_size=1)   sim <- cram_bandit_sim(horizon, simulations,                        bandit, policy,                        alpha=0.05, do_parallel = FALSE) sim$summary_table } # }"},{"path":"https://yanisvdc.github.io/cramR/reference/cram_bandit_var.html","id":null,"dir":"Reference","previous_headings":"","what":"Cram Bandit Variance of the Policy Value Estimate ‚Äî cram_bandit_var","title":"Cram Bandit Variance of the Policy Value Estimate ‚Äî cram_bandit_var","text":"function implements crammed variance estimate policy value estimate contextual armed bandit -policy evaluation setting.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/cram_bandit_var.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cram Bandit Variance of the Policy Value Estimate ‚Äî cram_bandit_var","text":"","code":"cram_bandit_var(pi, reward, arm, batch = 1)"},{"path":"https://yanisvdc.github.io/cramR/reference/cram_bandit_var.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cram Bandit Variance of the Policy Value Estimate ‚Äî cram_bandit_var","text":"pi array shape (T √ó B, T, K) (T √ó B, T), T number learning steps (policy updates), B batch size, K number arms, T x B total number contexts. 3D, pi[j, t, ] gives probability policy pi_t assigns arm context X_j. 2D, pi[j, t] gives probability policy pi_t assigns arm A_j (arm actually chosen X_j history) context X_j. Please see vignette details. reward vector observed rewards length T x B arm vector length T x B indicating arm selected context batch (Optional) vector integer. vector, gives batch assignment context. integer, interpreted batch size contexts assigned batch order dataset. Default 1.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/cram_bandit_var.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cram Bandit Variance of the Policy Value Estimate ‚Äî cram_bandit_var","text":"crammed variance estimate policy value estimate.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/cram_estimator.html","id":null,"dir":"Reference","previous_headings":"","what":"Cram Policy Estimator for Policy Value Difference (Delta) ‚Äî cram_estimator","title":"Cram Policy Estimator for Policy Value Difference (Delta) ‚Äî cram_estimator","text":"function returns cram policy estimator policy value difference (delta).","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/cram_estimator.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cram Policy Estimator for Policy Value Difference (Delta) ‚Äî cram_estimator","text":"","code":"cram_estimator(X, Y, D, pi, batch_indices, propensity = NULL)"},{"path":"https://yanisvdc.github.io/cramR/reference/cram_estimator.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cram Policy Estimator for Policy Value Difference (Delta) ‚Äî cram_estimator","text":"X matrix data frame covariates sample. Y vector outcomes n individuals. D vector binary treatments n individuals. pi matrix n rows (nb_batch + 1) columns, n sample size nb_batch number batches, containing policy assignment individual policy. first column represents baseline policy. batch_indices list element vector indices corresponding individuals batch. propensity propensity score function","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/cram_estimator.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cram Policy Estimator for Policy Value Difference (Delta) ‚Äî cram_estimator","text":"estimated policy value difference (Delta).","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/cram_expected_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Cram ML Expected Loss Estimate ‚Äî cram_expected_loss","title":"Cram ML Expected Loss Estimate ‚Äî cram_expected_loss","text":"function computes Cram ML expected loss estimator based given loss matrix batch indices.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/cram_expected_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cram ML Expected Loss Estimate ‚Äî cram_expected_loss","text":"","code":"cram_expected_loss(loss, batch_indices)"},{"path":"https://yanisvdc.github.io/cramR/reference/cram_expected_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cram ML Expected Loss Estimate ‚Äî cram_expected_loss","text":"loss matrix loss values N rows (data points) K+1 columns (batches). assume first column loss matrix contains zeros. following nb_batch columns contain losses trained model individual. batch_indices list element vector indices corresponding batch.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/cram_expected_loss.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cram ML Expected Loss Estimate ‚Äî cram_expected_loss","text":"Cram ML expected loss estimate","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/cram_learning.html","id":null,"dir":"Reference","previous_headings":"","what":"Cram Policy Learning ‚Äî cram_learning","title":"Cram Policy Learning ‚Äî cram_learning","text":"function performs learning part Cram Policy method.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/cram_learning.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cram Policy Learning ‚Äî cram_learning","text":"","code":"cram_learning(   X,   D,   Y,   batch,   model_type = \"causal_forest\",   learner_type = \"ridge\",   baseline_policy = NULL,   parallelize_batch = FALSE,   model_params = NULL,   custom_fit = NULL,   custom_predict = NULL,   n_cores = detectCores() - 1,   propensity = NULL )"},{"path":"https://yanisvdc.github.io/cramR/reference/cram_learning.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cram Policy Learning ‚Äî cram_learning","text":"X matrix data frame covariates sample. D vector binary treatment indicators (1 treated, 0 untreated). Y vector outcome values sample. batch Either integer specifying number batches (created random sampling) vector length equal sample size providing batch assignment (index) individual sample. model_type model type policy learning. Options include \"causal_forest\", \"s_learner\", \"m_learner\". Default \"causal_forest\". Note: can also set model_type NULL specify custom_fit custom_predict use custom model. learner_type learner type chosen model. Options include \"ridge\" Ridge Regression, \"fnn\" Feedforward Neural Network \"caret\" Caret. Default \"ridge\". model_type 'causal_forest', choose NULL, model_type 's_learner' 'm_learner', choose 'ridge', 'fnn' 'caret'. baseline_policy list providing baseline policy (binary 0 1) sample. NULL, baseline policy defaults list zeros length number rows X. parallelize_batch Logical. Whether parallelize batch processing (.e. cram method learns T policies, T number batches. learned parallel parallelize_batch TRUE vs. learned sequentially using efficient data.table structure parallelize_batch FALSE, recommended light weight training). Defaults FALSE. model_params list additional parameters pass model, can parameter defined model reference package. Defaults NULL. custom_fit custom, user-defined, function outputs fitted model given training data (allows flexibility). Defaults NULL. custom_predict custom, user-defined, function making predictions given fitted model test data (allow flexibility). Defaults NULL. n_cores Number cores use parallelization parallelize_batch set TRUE. Defaults detectCores() - 1. propensity propensity score","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/cram_learning.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cram Policy Learning ‚Äî cram_learning","text":"list containing: final_policy_model final fitted policy model, depending model_type learner_type. policies matrix learned policies, column represents batch's learned policy first column baseline policy. batch_indices indices batch, either generated (batch integer) provided user.","code":""},{"path":[]},{"path":"https://yanisvdc.github.io/cramR/reference/cram_ml.html","id":null,"dir":"Reference","previous_headings":"","what":"Cram ML: Simultaneous Machine Learning and Evaluation ‚Äî cram_ml","title":"Cram ML: Simultaneous Machine Learning and Evaluation ‚Äî cram_ml","text":"Performs Cram method simultaneous machine learning evaluation.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/cram_ml.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cram ML: Simultaneous Machine Learning and Evaluation ‚Äî cram_ml","text":"","code":"cram_ml(   data,   batch,   formula = NULL,   caret_params = NULL,   parallelize_batch = FALSE,   loss_name = NULL,   custom_fit = NULL,   custom_predict = NULL,   custom_loss = NULL,   alpha = 0.05,   classify = FALSE )"},{"path":"https://yanisvdc.github.io/cramR/reference/cram_ml.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cram ML: Simultaneous Machine Learning and Evaluation ‚Äî cram_ml","text":"data matrix data frame covariates. supervised learning, must include target variable specified formula. batch Integer specifying number batches vector pre-defined batch assignments. formula Formula supervised learning (e.g., y ~ .). caret_params List parameters caret::train() containing: method: Model type (e.g., \"rf\", \"glm\", \"xgbTree\" supervised learning) Additional method-specific parameters parallelize_batch Logical indicating whether parallelize batch processing (default = FALSE). loss_name Name loss metric (supported: \"se\", \"logloss\", \"accuracy\"). custom_fit Optional custom model training function. custom_predict Optional custom prediction function. custom_loss Optional custom loss function. alpha Confidence level intervals (default = 0.05). classify Indicate classification problem. Defaults FALSE.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/cram_ml.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cram ML: Simultaneous Machine Learning and Evaluation ‚Äî cram_ml","text":"list containing: raw_results: Data frame performance metrics interactive_table: performance metrics user-friendly interface final_ml_model: Trained model object","code":""},{"path":[]},{"path":"https://yanisvdc.github.io/cramR/reference/cram_ml.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cram ML: Simultaneous Machine Learning and Evaluation ‚Äî cram_ml","text":"","code":"# Load necessary libraries library(caret) #> Loading required package: ggplot2 #> Loading required package: lattice  # Set seed for reproducibility set.seed(42)  # Generate example dataset X_data <- data.frame(x1 = rnorm(100), x2 = rnorm(100), x3 = rnorm(100)) Y_data <- rnorm(100)  # Continuous target variable for regression data_df <- data.frame(X_data, Y = Y_data)  # Ensure target variable is included  # Define caret parameters for simple linear regression (no cross-validation) caret_params_lm <- list(   method = \"lm\",   trControl = trainControl(method = \"none\") )  nb_batch <- 5  # Run ML learning function result <- cram_ml(   data = data_df,   formula = Y ~ .,  # Linear regression model   batch = nb_batch,   loss_name = 'se',   caret_params = caret_params_lm )  result$raw_results #>                         Metric    Value #> 1       Expected Loss Estimate  0.86429 #> 2 Expected Loss Standard Error  0.73665 #> 3       Expected Loss CI Lower -0.57952 #> 4       Expected Loss CI Upper  2.30809 result$interactive_table  {\"x\":{\"filter\":\"none\",\"vertical\":false,\"caption\":\"<caption>CRAM ML Results<\\/caption>\",\"data\":[[\"1\",\"2\",\"3\",\"4\"],[\"Expected Loss Estimate\",\"Expected Loss Standard Error\",\"Expected Loss CI Lower\",\"Expected Loss CI Upper\"],[0.86429,0.73665,-0.57952,2.30809]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>Metric<\\/th>\\n      <th>Value<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"pageLength\":5,\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":2},{\"orderable\":false,\"targets\":0},{\"name\":\" \",\"targets\":0},{\"name\":\"Metric\",\"targets\":1},{\"name\":\"Value\",\"targets\":2}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false,\"lengthMenu\":[5,10,25,50,100]},\"selection\":{\"mode\":\"multiple\",\"selected\":null,\"target\":\"row\",\"selectable\":null}},\"evals\":[],\"jsHooks\":[]}result$final_ml_model #> Linear Regression  #>  #> 100 samples #>   3 predictor #>  #> No pre-processing #> Resampling: None"},{"path":"https://yanisvdc.github.io/cramR/reference/cram_policy.html","id":null,"dir":"Reference","previous_headings":"","what":"Cram Policy: Efficient Simultaneous Policy Learning and Evaluation ‚Äî cram_policy","title":"Cram Policy: Efficient Simultaneous Policy Learning and Evaluation ‚Äî cram_policy","text":"function performs cram method (simultaneous policy learning evaluation) binary policies data including covariates (X), binary treatment indicator (D) outcomes (Y).","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/cram_policy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cram Policy: Efficient Simultaneous Policy Learning and Evaluation ‚Äî cram_policy","text":"","code":"cram_policy(   X,   D,   Y,   batch,   model_type = \"causal_forest\",   learner_type = \"ridge\",   baseline_policy = NULL,   parallelize_batch = FALSE,   model_params = NULL,   custom_fit = NULL,   custom_predict = NULL,   alpha = 0.05,   propensity = NULL )"},{"path":"https://yanisvdc.github.io/cramR/reference/cram_policy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cram Policy: Efficient Simultaneous Policy Learning and Evaluation ‚Äî cram_policy","text":"X matrix data frame covariates sample. D vector binary treatment indicators (1 treated, 0 non-treated). Y vector outcome values sample. batch Either integer specifying number batches (created random sampling) vector length equal sample size providing batch assignment (index) individual sample. model_type model type policy learning. Options include \"causal_forest\", \"s_learner\", \"m_learner\". Default \"causal_forest\". Note: can also set model_type NULL specify custom_fit custom_predict use custom model. learner_type learner type chosen model. Options include \"ridge\" Ridge Regression, \"fnn\" Feedforward Neural Network \"caret\" Caret. Default \"ridge\". model_type 'causal_forest', choose NULL, model_type 's_learner' 'm_learner', choose 'ridge', 'fnn' 'caret'. baseline_policy list providing baseline policy (binary 0 1) sample. NULL, defaults list zeros length number rows X. parallelize_batch Logical. Whether parallelize batch processing (.e. cram method learns T policies, T number batches. learned parallel parallelize_batch TRUE vs. learned sequentially using efficient data.table structure parallelize_batch FALSE, recommended light weight training). Defaults FALSE. model_params list additional parameters pass model, can parameter defined model reference package. Defaults NULL. custom_fit custom, user-defined, function outputs fitted model given training data (allows flexibility). Defaults NULL. custom_predict custom, user-defined, function making predictions given fitted model test data (allow flexibility). Defaults NULL. alpha Significance level confidence intervals. Default 0.05 (95% confidence). propensity propensity score function binary treatment indicator (D) (probability unit receive treatment). Defaults 0.5 (random assignment).","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/cram_policy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cram Policy: Efficient Simultaneous Policy Learning and Evaluation ‚Äî cram_policy","text":"list containing: raw_results: data frame summarizing key metrics truncated decimals: Delta Estimate: estimated treatment effect (delta). Delta Standard Error: standard error delta estimate. Delta CI Lower: lower bound confidence interval delta. Delta CI Upper: upper bound confidence interval delta. Policy Value Estimate: estimated policy value. Policy Value Standard Error: standard error policy value estimate. Policy Value CI Lower: lower bound confidence interval policy value. Policy Value CI Upper: upper bound confidence interval policy value. Proportion Treated: proportion individuals treated final policy. interactive_table: interactive table summarizing key metrics detailed exploration. final_policy_model: final fitted policy model based model_type learner_type custom_fit.","code":""},{"path":[]},{"path":"https://yanisvdc.github.io/cramR/reference/cram_policy.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cram Policy: Efficient Simultaneous Policy Learning and Evaluation ‚Äî cram_policy","text":"","code":"# Example data X_data <- matrix(rnorm(100 * 5), nrow = 100, ncol = 5) D_data <- as.integer(sample(c(0, 1), 100, replace = TRUE)) Y_data <- rnorm(100) nb_batch <- 5  # Perform CRAM policy result <- cram_policy(X = X_data,                           D = D_data,                           Y = Y_data,                           batch = nb_batch)  # Access results result$raw_results #>                        Metric    Value #> 1              Delta Estimate  0.36852 #> 2        Delta Standard Error  0.26573 #> 3              Delta CI Lower -0.15230 #> 4              Delta CI Upper  0.88935 #> 5       Policy Value Estimate  0.53258 #> 6 Policy Value Standard Error  0.27544 #> 7       Policy Value CI Lower -0.00727 #> 8       Policy Value CI Upper  1.07243 #> 9          Proportion Treated  1.00000 result$interactive_table  {\"x\":{\"filter\":\"none\",\"vertical\":false,\"caption\":\"<caption>CRAM Experiment Results<\\/caption>\",\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"],[\"Delta Estimate\",\"Delta Standard Error\",\"Delta CI Lower\",\"Delta CI Upper\",\"Policy Value Estimate\",\"Policy Value Standard Error\",\"Policy Value CI Lower\",\"Policy Value CI Upper\",\"Proportion Treated\"],[0.36852,0.26573,-0.1523,0.88935,0.5325800000000001,0.27544,-0.00727,1.07243,1]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>Metric<\\/th>\\n      <th>Value<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"pageLength\":5,\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":2},{\"orderable\":false,\"targets\":0},{\"name\":\" \",\"targets\":0},{\"name\":\"Metric\",\"targets\":1},{\"name\":\"Value\",\"targets\":2}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false,\"lengthMenu\":[5,10,25,50,100]},\"selection\":{\"mode\":\"multiple\",\"selected\":null,\"target\":\"row\",\"selectable\":null}},\"evals\":[],\"jsHooks\":[]}result$final_policy_model #> GRF forest object of type causal_forest  #> Number of trees: 100  #> Number of training samples: 100  #> Variable importance:  #>     1     2     3     4     5  #> 0.089 0.187 0.142 0.124 0.160"},{"path":"https://yanisvdc.github.io/cramR/reference/cram_policy_value_estimator.html","id":null,"dir":"Reference","previous_headings":"","what":"Cram Policy: Estimator for Policy Value (Psi) ‚Äî cram_policy_value_estimator","title":"Cram Policy: Estimator for Policy Value (Psi) ‚Äî cram_policy_value_estimator","text":"function returns cram estimator policy value (psi).","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/cram_policy_value_estimator.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cram Policy: Estimator for Policy Value (Psi) ‚Äî cram_policy_value_estimator","text":"","code":"cram_policy_value_estimator(X, Y, D, pi, batch_indices, propensity = NULL)"},{"path":"https://yanisvdc.github.io/cramR/reference/cram_policy_value_estimator.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cram Policy: Estimator for Policy Value (Psi) ‚Äî cram_policy_value_estimator","text":"X matrix data frame covariates sample. Y vector outcomes n individuals. D vector binary treatments n individuals. pi matrix n rows (nb_batch + 1) columns, n sample size nb_batch number batches, containing policy assignment individual policy. first column represents baseline policy. batch_indices list element vector indices corresponding individuals batch. propensity Propensity score function","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/cram_policy_value_estimator.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cram Policy: Estimator for Policy Value (Psi) ‚Äî cram_policy_value_estimator","text":"estimated policy value.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/cram_simulation.html","id":null,"dir":"Reference","previous_headings":"","what":"Cram Policy Simulation ‚Äî cram_simulation","title":"Cram Policy Simulation ‚Äî cram_simulation","text":"function performs cram method (simultaneous learning evaluation) simulation data, data generation process (DGP) known. data generation process X can given directly function induced provided dataset via row-wise bootstrapping. Results averaged across Monte Carlo replicates given DGP.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/cram_simulation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cram Policy Simulation ‚Äî cram_simulation","text":"","code":"cram_simulation(   X = NULL,   dgp_X = NULL,   dgp_D,   dgp_Y,   batch,   nb_simulations,   nb_simulations_truth = NULL,   sample_size,   model_type = \"causal_forest\",   learner_type = \"ridge\",   alpha = 0.05,   baseline_policy = NULL,   parallelize_batch = FALSE,   model_params = NULL,   custom_fit = NULL,   custom_predict = NULL,   propensity = NULL )"},{"path":"https://yanisvdc.github.io/cramR/reference/cram_simulation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cram Policy Simulation ‚Äî cram_simulation","text":"X Optional. matrix data frame covariates sample inducing empirically DGP covariates. dgp_X Optional. function generate covariate data simulations. dgp_D vectorized function generate binary treatment assignments sample. dgp_Y vectorized function generate outcome variable sample given treatment covariates. batch Either integer specifying number batches (created random sampling) vector length equal sample size providing batch assignment (index) individual sample. nb_simulations number simulations (Monte Carlo replicates) run. nb_simulations_truth Optional. number additional simmulations (Monte Carlo replicates) beyond nb_simulations use calculating true policy value difference (delta) true policy value (psi) sample_size number samples simulation. model_type model type policy learning. Options include \"causal_forest\", \"s_learner\", \"m_learner\". Default \"causal_forest\". Note: can also set model_type NULL specify custom_fit custom_predict use custom model. learner_type learner type chosen model. Options include \"ridge\" Ridge Regression, \"fnn\" Feedforward Neural Network \"caret\" Caret. Default \"ridge\". model_type 'causal_forest', choose NULL, model_type 's_learner' 'm_learner', choose 'ridge', 'fnn' 'caret'. alpha Significance level confidence intervals. Default 0.05 (95% confidence). baseline_policy list providing baseline policy (binary 0 1) sample. NULL, defaults list zeros length number rows X. parallelize_batch Logical. Whether parallelize batch processing (.e. cram method learns T policies, T number batches. learned parallel parallelize_batch TRUE vs. learned sequentially using efficient data.table structure parallelize_batch FALSE, recommended light weight training). Defaults FALSE. model_params list additional parameters pass model, can parameter defined model reference package. Defaults NULL. custom_fit custom, user-defined, function outputs fitted model given training data (allows flexibility). Defaults NULL. custom_predict custom, user-defined, function making predictions given fitted model test data (allow flexibility). Defaults NULL. propensity propensity score model","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/cram_simulation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cram Policy Simulation ‚Äî cram_simulation","text":"list containing: avg_proportion_treated average proportion treated individuals across simulations. avg_delta_estimate average delta estimate across simulations. avg_delta_standard_error average standard error delta estimates. delta_empirical_bias empirical bias delta estimates. delta_empirical_coverage empirical coverage delta confidence intervals. avg_policy_value_estimate average policy value estimate across simulations. avg_policy_value_standard_error average standard error policy value estimates. policy_value_empirical_bias empirical bias policy value estimates. policy_value_empirical_coverage empirical coverage policy value confidence intervals.","code":""},{"path":[]},{"path":"https://yanisvdc.github.io/cramR/reference/cram_simulation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cram Policy Simulation ‚Äî cram_simulation","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(123)  # dgp_X <- function(n) { #   data.table::data.table( #     binary     = rbinom(n, 1, 0.5), #     discrete   = sample(1:5, n, replace = TRUE), #     continuous = rnorm(n) #   ) # }  n <- 100  X_data <- data.table::data.table(   binary     = rbinom(n, 1, 0.5),   discrete   = sample(1:5, n, replace = TRUE),   continuous = rnorm(n) )   dgp_D <- function(X) rbinom(nrow(X), 1, 0.5)  dgp_Y <- function(D, X) {   theta <- ifelse(     X[, binary] == 1 & X[, discrete] <= 2,  # Group 1: High benefit     1,     ifelse(X[, binary] == 0 & X[, discrete] >= 4,  # Group 3: Negative benefit            -1,            0.1)  # Group 2: Neutral effect   )   Y <- D * (theta + rnorm(length(D), mean = 0, sd = 1)) +     (1 - D) * rnorm(length(D))  # Outcome for untreated   return(Y) }  # Parameters nb_simulations <- 100 nb_simulations_truth <- 200 batch <- 5  # Perform CRAM simulation result <- cram_simulation(   X = X_data,   dgp_D = dgp_D,   dgp_Y = dgp_Y,   batch = batch,   nb_simulations = nb_simulations,   nb_simulations_truth = nb_simulations_truth,   sample_size = 500 )  result$raw_results result$interactive_table } # }"},{"path":"https://yanisvdc.github.io/cramR/reference/cram_variance_estimator.html","id":null,"dir":"Reference","previous_headings":"","what":"Cram Policy: Variance Estimate of the crammed Policy Value Difference (Delta) ‚Äî cram_variance_estimator","title":"Cram Policy: Variance Estimate of the crammed Policy Value Difference (Delta) ‚Äî cram_variance_estimator","text":"function estimates asymptotic variance cram estimator policy value difference (delta).","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/cram_variance_estimator.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cram Policy: Variance Estimate of the crammed Policy Value Difference (Delta) ‚Äî cram_variance_estimator","text":"","code":"cram_variance_estimator(X, Y, D, pi, batch_indices, propensity = NULL)"},{"path":"https://yanisvdc.github.io/cramR/reference/cram_variance_estimator.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cram Policy: Variance Estimate of the crammed Policy Value Difference (Delta) ‚Äî cram_variance_estimator","text":"X matrix data frame covariates sample. Y vector outcomes n individuals. D vector binary treatments n individuals. pi matrix n rows (nb_batch + 1) columns, n sample size nb_batch number batches, containing policy assignment individual policy. first column represents baseline policy. batch_indices list element vector indices corresponding individuals batch. propensity propensity score function","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/cram_variance_estimator.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cram Policy: Variance Estimate of the crammed Policy Value Difference (Delta) ‚Äî cram_variance_estimator","text":"estimated variance policy value difference (Delta)","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/cram_variance_estimator_policy_value.html","id":null,"dir":"Reference","previous_headings":"","what":"Cram Policy: Variance Estimate of the crammed Policy Value estimate (Psi) ‚Äî cram_variance_estimator_policy_value","title":"Cram Policy: Variance Estimate of the crammed Policy Value estimate (Psi) ‚Äî cram_variance_estimator_policy_value","text":"function estimates asymptotic variance cram estimator policy value (psi).","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/cram_variance_estimator_policy_value.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cram Policy: Variance Estimate of the crammed Policy Value estimate (Psi) ‚Äî cram_variance_estimator_policy_value","text":"","code":"cram_variance_estimator_policy_value(   X,   Y,   D,   pi,   batch_indices,   propensity = NULL )"},{"path":"https://yanisvdc.github.io/cramR/reference/cram_variance_estimator_policy_value.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cram Policy: Variance Estimate of the crammed Policy Value estimate (Psi) ‚Äî cram_variance_estimator_policy_value","text":"X matrix data frame covariates sample. Y vector outcomes n individuals. D vector binary treatments n individuals. pi matrix n rows (nb_batch + 1) columns, n sample size nb_batch number batches, containing policy assignment individual policy. first column represents baseline policy. batch_indices list element vector indices corresponding individuals batch. propensity Propensity score function","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/cram_variance_estimator_policy_value.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cram Policy: Variance Estimate of the crammed Policy Value estimate (Psi) ‚Äî cram_variance_estimator_policy_value","text":"variance estimate crammed Policy Value estimate (Psi)","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/cram_var_expected_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Cram ML: Variance Estimate of the crammed expected loss estimate ‚Äî cram_var_expected_loss","title":"Cram ML: Variance Estimate of the crammed expected loss estimate ‚Äî cram_var_expected_loss","text":"function computes variance estimator based given loss matrix batch indices.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/cram_var_expected_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cram ML: Variance Estimate of the crammed expected loss estimate ‚Äî cram_var_expected_loss","text":"","code":"cram_var_expected_loss(loss, batch_indices)"},{"path":"https://yanisvdc.github.io/cramR/reference/cram_var_expected_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cram ML: Variance Estimate of the crammed expected loss estimate ‚Äî cram_var_expected_loss","text":"loss matrix loss values N rows (data points) K+1 columns (batches). assume first column loss matrix contains zeros. following nb_batch columns contain losses trained model individual. batch_indices list element vector indices corresponding batch.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/cram_var_expected_loss.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cram ML: Variance Estimate of the crammed expected loss estimate ‚Äî cram_var_expected_loss","text":"variance estimate crammed expected loss estimate","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/fit_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Cram Policy: Fit Model ‚Äî fit_model","title":"Cram Policy: Fit Model ‚Äî fit_model","text":"function trains given unfitted model provided data parameters, according model type learner type.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/fit_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cram Policy: Fit Model ‚Äî fit_model","text":"","code":"fit_model(model, X, Y, D, model_type, learner_type, model_params, propensity)"},{"path":"https://yanisvdc.github.io/cramR/reference/fit_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cram Policy: Fit Model ‚Äî fit_model","text":"model unfitted model object, returned `set_model`. X matrix data frame covariates samples. Y vector outcome values. D vector binary treatment indicators (1 treated, 0 untreated). model_type model type policy learning. Options include \"causal_forest\", \"s_learner\", \"m_learner\". Default \"causal_forest\". learner_type learner type chosen model. Options include \"ridge\" Ridge Regression \"fnn\" Feedforward Neural Network. Default \"ridge\". model_params list additional parameters pass model, can parameter defined model reference package. Defaults NULL. propensity propensity score","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/fit_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cram Policy: Fit Model ‚Äî fit_model","text":"fitted model object.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/fit_model_ml.html","id":null,"dir":"Reference","previous_headings":"","what":"Cram ML: Fit Model ML ‚Äî fit_model_ml","title":"Cram ML: Fit Model ML ‚Äî fit_model_ml","text":"function trains given unfitted model provided data parameters, according model type learner type.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/fit_model_ml.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cram ML: Fit Model ML ‚Äî fit_model_ml","text":"","code":"fit_model_ml(data, formula, caret_params, classify)"},{"path":"https://yanisvdc.github.io/cramR/reference/fit_model_ml.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cram ML: Fit Model ML ‚Äî fit_model_ml","text":"data dataset formula formula caret_params parameters caret model classify Indicate classification problem. Defaults FALSE","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/fit_model_ml.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cram ML: Fit Model ML ‚Äî fit_model_ml","text":"fitted model object.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/generate_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Mock Dataset ‚Äî generate_data","title":"Generate Mock Dataset ‚Äî generate_data","text":"function generates simulated dataset covariates, treatment assignments, outcomes testing experimentation. dataset includes heterogeneous treatment effects across groups, mimicking realistic causal inference scenarios.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/generate_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Mock Dataset ‚Äî generate_data","text":"","code":"generate_data(n)"},{"path":"https://yanisvdc.github.io/cramR/reference/generate_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Mock Dataset ‚Äî generate_data","text":"n Integer. number observations generate.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/generate_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Mock Dataset ‚Äî generate_data","text":"list containing: X data.table three variables: D Binary treatment assignment (0 1). Y Numeric outcome based treatment effects covariates.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/generate_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate Mock Dataset ‚Äî generate_data","text":"","code":"# Generate a dataset with 1000 observations data <- generate_data(1000) str(data) #> List of 3 #>  $ X:Classes 'data.table' and 'data.frame':\t1000 obs. of  3 variables: #>   ..$ binary    : int [1:1000] 1 0 0 0 1 1 0 0 1 1 ... #>   ..$ discrete  : int [1:1000] 3 4 4 4 1 4 1 1 3 2 ... #>   ..$ continuous: num [1:1000] 2.047 -0.485 0.363 1.911 -0.275 ... #>   ..- attr(*, \".internal.selfref\")=<externalptr>  #>  $ D: int [1:1000] 0 0 1 1 1 0 1 0 0 0 ... #>  $ Y: num [1:1000] -0.218 -0.2 -2.267 0.635 1.702 ... head(data$X) #>    binary discrete continuous #>     <int>    <int>      <num> #> 1:      1        3  2.0470005 #> 2:      0        4 -0.4845959 #> 3:      0        4  0.3625913 #> 4:      0        4  1.9112226 #> 5:      1        1 -0.2745191 #> 6:      1        4 -0.6519016 head(data$D) #> [1] 0 0 1 1 1 0 head(data$Y) #> [1] -0.2178099 -0.1997781 -2.2670366  0.6351589  1.7018075 -0.1513984"},{"path":"https://yanisvdc.github.io/cramR/reference/ml_learning.html","id":null,"dir":"Reference","previous_headings":"","what":"Cram ML: Generalized ML Learning ‚Äî ml_learning","title":"Cram ML: Generalized ML Learning ‚Äî ml_learning","text":"function performs batch-wise learning machine learning models.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/ml_learning.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cram ML: Generalized ML Learning ‚Äî ml_learning","text":"","code":"ml_learning(   data,   formula = NULL,   batch,   parallelize_batch = FALSE,   loss_name = NULL,   caret_params = NULL,   custom_fit = NULL,   custom_predict = NULL,   custom_loss = NULL,   n_cores = detectCores() - 1,   classify = FALSE )"},{"path":"https://yanisvdc.github.io/cramR/reference/ml_learning.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cram ML: Generalized ML Learning ‚Äî ml_learning","text":"data matrix data frame features. Must include target variable. formula Formula specifying relationship target predictors supervised learning. batch Either integer specifying number batches (randomly sampled) vector length equal sample size indicating batch assignment observation. parallelize_batch Logical. Whether parallelize batch processing. Defaults `FALSE`. loss_name name loss function used (e.g., `\"se\"`, `\"logloss\"`). caret_params list parameters pass `caret::train()` function. - Required: `method` (e.g., `\"glm\"`, `\"rf\"`). custom_fit custom function training user-defined models. Defaults `NULL`. custom_predict custom function making predictions user-defined models. Defaults `NULL`. custom_loss Optional custom function computing loss trained model data. return vector containing per-instance losses. n_cores Number CPU cores use parallel processing (`parallelize_batch = TRUE`). Defaults `detectCores() - 1`. classify Indicate classification problem. Defaults FALSE","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/ml_learning.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cram ML: Generalized ML Learning ‚Äî ml_learning","text":"list containing: final_ml_model final trained ML model. losses matrix losses column represents batch's trained model. first column contains zeros (baseline model). batch_indices indices observations batch.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/model_predict.html","id":null,"dir":"Reference","previous_headings":"","what":"Cram Policy: Predict with the Specified Model ‚Äî model_predict","title":"Cram Policy: Predict with the Specified Model ‚Äî model_predict","text":"function performs inference using trained model, providing flexibility different types models Causal Forest, Ridge Regression, Feedforward Neural Networks (FNNs).","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/model_predict.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cram Policy: Predict with the Specified Model ‚Äî model_predict","text":"","code":"model_predict(model, X, D, model_type, learner_type, model_params)"},{"path":"https://yanisvdc.github.io/cramR/reference/model_predict.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cram Policy: Predict with the Specified Model ‚Äî model_predict","text":"model trained model object returned `fit_model` function. X matrix data frame covariates predictions required. D vector binary treatment indicators (1 treated, 0 untreated). Optional, depending model type. model_type model type policy learning. Options include \"causal_forest\", \"s_learner\", \"m_learner\". Default \"causal_forest\". learner_type learner type chosen model. Options include \"ridge\" Ridge Regression \"fnn\" Feedforward Neural Network. Default \"ridge\". model_params list additional parameters pass model, can parameter defined model reference package. Defaults NULL.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/model_predict.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cram Policy: Predict with the Specified Model ‚Äî model_predict","text":"vector binary policy assignments, depending model_type learner_type.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/model_predict_ml.html","id":null,"dir":"Reference","previous_headings":"","what":"Cram ML: Predict with the Specified Model ‚Äî model_predict_ml","title":"Cram ML: Predict with the Specified Model ‚Äî model_predict_ml","text":"function performs inference using trained model","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/model_predict_ml.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cram ML: Predict with the Specified Model ‚Äî model_predict_ml","text":"","code":"model_predict_ml(   model,   data,   formula,   caret_params,   cram_policy_handle = FALSE )"},{"path":"https://yanisvdc.github.io/cramR/reference/model_predict_ml.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cram ML: Predict with the Specified Model ‚Äî model_predict_ml","text":"model trained model object returned `fit_model_ml` function. data dataset formula formula caret_params parameters caret model cram_policy_handle Internal use. Post-process predictions differently cram policy use. Defaults FALSE.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/model_predict_ml.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cram ML: Predict with the Specified Model ‚Äî model_predict_ml","text":"Predictions model data","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/set_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Cram Policy: Set Model ‚Äî set_model","title":"Cram Policy: Set Model ‚Äî set_model","text":"function maps model type learner type corresponding model function.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/set_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cram Policy: Set Model ‚Äî set_model","text":"","code":"set_model(model_type, learner_type, model_params)"},{"path":"https://yanisvdc.github.io/cramR/reference/set_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cram Policy: Set Model ‚Äî set_model","text":"model_type model type policy learning. Options include \"causal_forest\", \"s_learner\", \"m_learner\". Default \"causal_forest\". Note: can also set model_type NULL specify custom_fit custom_predict use custom model. learner_type learner type chosen model. Options include \"ridge\" Ridge Regression, \"fnn\" Feedforward Neural Network \"caret\" Caret. Default \"ridge\". model_type 'causal_forest', choose NULL, model_type 's_learner' 'm_learner', choose 'ridge', 'fnn' 'caret'. model_params list additional parameters pass model, can parameter defined model reference package. Defaults NULL. FNNs, following elements defined model params list: input_layer list defining input layer. Must include: units Number units input layer. activation Activation function input layer. input_shape Input shape layer.  layers list lists, sublist specifies hidden layer : units Number units layer. activation Activation function layer.  output_layer list defining output layer. Must include: units Number units output layer. activation Activation function output layer (e.g., \"linear\" \"sigmoid\").  compile_args list arguments compiling model. Must include: optimizer Optimizer training (e.g., \"adam\" \"sgd\"). loss Loss function (e.g., \"mse\" \"binary_crossentropy\"). metrics Optional list metrics evaluation (e.g., c(\"accuracy\")).  learners (e.g., \"ridge\" \"causal_forest\"), model_params can include relevant hyperparameters.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/set_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cram Policy: Set Model ‚Äî set_model","text":"instantiated model object corresponding model function.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/test_baseline_policy.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate or Set the Baseline Policy ‚Äî test_baseline_policy","title":"Validate or Set the Baseline Policy ‚Äî test_baseline_policy","text":"function validates provided baseline policy sets default baseline policy zeros individuals.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/test_baseline_policy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate or Set the Baseline Policy ‚Äî test_baseline_policy","text":"","code":"test_baseline_policy(baseline_policy, n)"},{"path":"https://yanisvdc.github.io/cramR/reference/test_baseline_policy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate or Set the Baseline Policy ‚Äî test_baseline_policy","text":"baseline_policy list representing baseline policy individual. NULL, default baseline policy zeros created. n integer specifying number individuals population.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/test_baseline_policy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate or Set the Baseline Policy ‚Äî test_baseline_policy","text":"validated default baseline policy list numeric values.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/test_batch.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate or Generate Batch Assignments ‚Äî test_batch","title":"Validate or Generate Batch Assignments ‚Äî test_batch","text":"function validates provided batch assignment generates random batch assignments individuals.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/test_batch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate or Generate Batch Assignments ‚Äî test_batch","text":"","code":"test_batch(batch, n)"},{"path":"https://yanisvdc.github.io/cramR/reference/test_batch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate or Generate Batch Assignments ‚Äî test_batch","text":"batch Either integer specifying number batches vector/list batch assignments individuals. n integer specifying number individuals population.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/test_batch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate or Generate Batch Assignments ‚Äî test_batch","text":"list containing: batches list element contains indices individuals assigned specific batch. nb_batch total number batches.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/validate_params.html","id":null,"dir":"Reference","previous_headings":"","what":"Cram Policy: Validate User-Provided Parameters for a Model ‚Äî validate_params","title":"Cram Policy: Validate User-Provided Parameters for a Model ‚Äî validate_params","text":"function validates user-provided parameters formal arguments specified model function. ensures user-specified parameters recognized model raises error invalid parameters.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/validate_params.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cram Policy: Validate User-Provided Parameters for a Model ‚Äî validate_params","text":"","code":"validate_params(model_function, model_type, learner_type, user_params)"},{"path":"https://yanisvdc.github.io/cramR/reference/validate_params.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cram Policy: Validate User-Provided Parameters for a Model ‚Äî validate_params","text":"model_function model function parameters validated (e.g., grf::causal_forest). model_type model type policy learning. Options include \"causal_forest\", \"s_learner\", \"m_learner\". Default \"causal_forest\". Note: can also set model_type NULL specify custom_fit custom_predict use custom model. learner_type learner type chosen model. Options include \"ridge\" Ridge Regression, \"fnn\" Feedforward Neural Network \"caret\" Caret. Default \"ridge\". model_type 'causal_forest', choose NULL, model_type 's_learner' 'm_learner', choose 'ridge', 'fnn' 'caret'. user_params named list parameters provided user.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/validate_params.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cram Policy: Validate User-Provided Parameters for a Model ‚Äî validate_params","text":"named list validated parameters safe pass model function.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/validate_params_fnn.html","id":null,"dir":"Reference","previous_headings":"","what":"Cram Policy: Validate Parameters for Feedforward Neural Networks (FNNs) ‚Äî validate_params_fnn","title":"Cram Policy: Validate Parameters for Feedforward Neural Networks (FNNs) ‚Äî validate_params_fnn","text":"function validates user-provided parameters Feedforward Neural Network (FNN) model. ensures correct structure input_layer, layers, output_layer, compile_args fit_params.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/validate_params_fnn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cram Policy: Validate Parameters for Feedforward Neural Networks (FNNs) ‚Äî validate_params_fnn","text":"","code":"validate_params_fnn(model_type, learner_type, model_params, X)"},{"path":"https://yanisvdc.github.io/cramR/reference/validate_params_fnn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cram Policy: Validate Parameters for Feedforward Neural Networks (FNNs) ‚Äî validate_params_fnn","text":"model_type model type policy learning. Options include \"causal_forest\", \"s_learner\", \"m_learner\". Default \"causal_forest\". Note: can also set model_type NULL specify custom_fit custom_predict use custom model. learner_type learner type chosen model. Options include \"ridge\" Ridge Regression, \"fnn\" Feedforward Neural Network \"caret\" Caret. Default \"ridge\". model_type 'causal_forest', choose NULL, model_type 's_learner' 'm_learner', choose 'ridge', 'fnn' 'caret'. model_params named list parameters provided user configuring FNN model. X matrix data frame covariates parameters validated.","code":""},{"path":"https://yanisvdc.github.io/cramR/reference/validate_params_fnn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cram Policy: Validate Parameters for Feedforward Neural Networks (FNNs) ‚Äî validate_params_fnn","text":"named list validated parameters merged defaults missing values.","code":""},{"path":"https://yanisvdc.github.io/cramR/news/index.html","id":"cramr-010","dir":"Changelog","previous_headings":"","what":"cramR 0.1.0","title":"cramR 0.1.0","text":"Initial CRAN submission.","code":""}]

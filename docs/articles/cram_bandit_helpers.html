<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Cram Bandit Helpers ‚Ä¢ cramR</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Cram Bandit Helpers">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
<!-- Load Inter font --><link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;700&amp;display=swap" rel="stylesheet">
<style>
  :root {
    --primary-gradient: linear-gradient(135deg, #2c3e50, #3498db);
    --hover-shadow: 0 4px 15px rgba(0,0,0,0.2);
  }

  .navbar {
    background-color: rgba(255, 255, 255, 0.95); /* Light background with slight transparency */
    box-shadow: 0 2px 10px rgba(0,0,0,0.1); /* Optional shadow for depth */
  }

  body {
    padding-top: 80px;
    font-family: 'Inter', -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
  }

  h1, h2, h3, h4, h5, h6 {
    font-family: 'Inter', sans-serif;
  }

  code, pre, kbd {
    font-family: 'JetBrains Mono', monospace;
    background-color: #f5f5f5;
    padding: 0.2em 0.4em;
    border-radius: 4px;
    font-size: 90%;
  }

  pre {
    overflow-x: auto;
  }

  pre code {
    padding: 1em;
    display: block;
  }

  .navbar-brand img {
    height: 40px;
    transition: transform 0.3s ease;
  }

  .navbar-brand:hover img {
    transform: scale(1.05);
  }

  .hero-banner {
    background: var(--primary-gradient);
    padding: 6rem 1rem;
    color: white;
    text-shadow: 0 2px 4px rgba(0,0,0,0.2);
  }

  .feature-card {
    background: white;
    border-radius: 12px;
    padding: 2rem;
    margin: 1rem;
    box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    transition: all 0.3s ease;
  }

  .feature-card:hover {
    transform: translateY(-5px);
    box-shadow: var(--hover-shadow);
  }

  /* Add hover effect to make the navbar more readable */
  .navbar:hover {
    background-color: rgba(255, 255, 255, 1); /* Fully visible on hover */
  }

  /* Add space below the navbar to prevent cutting off content */
  main {
    padding-top: 1rem;
  }
</style>
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">cramR</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/cram_policy_part_1.html">Introduction &amp; Cram Policy part 1</a></li>
    <li><a class="dropdown-item" href="../articles/quickstart.html">Quick Start</a></li>
    <li><a class="dropdown-item" href="../articles/cram_policy_part_2.html">Cram Policy part 2</a></li>
    <li><a class="dropdown-item" href="../articles/cram_ml.html">Cram ML</a></li>
    <li><a class="dropdown-item" href="../articles/cram_bandit.html">Cram Bandit</a></li>
    <li><a class="dropdown-item" href="../articles/cram_bandit_helpers.html">Cram Bandit Helpers</a></li>
    <li><a class="dropdown-item" href="../articles/cram_policy_simulation.html">Cram Policy Simulation</a></li>
    <li><a class="dropdown-item" href="../articles/cram_bandit_simulation.html">Cram Bandit Simulation</a></li>
  </ul>
</li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-resources" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Resources</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-resources">
<li><a class="dropdown-item" href="../reference/index.html">Function Reference</a></li>
    <li><a class="dropdown-item" href="../news/index.html">Release Notes</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/yanisvdc/cramR" aria-label="GitHub repository"><span class="fa fa-brands fa-github"></span></a></li>
<li class="nav-item"><a class="external-link nav-link" href="https://www.hbs.edu/ris/Publication%20Files/2403.07031v1_a83462e0-145b-4675-99d5-9754aa65d786.pdf" aria-label="Research paper"><span class="fa fa-solid fa-file-pdf"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Cram Bandit Helpers</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/yanisvdc/cramR/blob/HEAD/vignettes/cram_bandit_helpers.Rmd" class="external-link"><code>vignettes/cram_bandit_helpers.Rmd</code></a></small>
      <div class="d-none name"><code>cram_bandit_helpers.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="what-is-this-article-about">üåü What is this article about?<a class="anchor" aria-label="anchor" href="#what-is-this-article-about"></a>
</h2>
<p>In order to use <code><a href="../reference/cram_bandit.html">cram_bandit()</a></code>, users must supply a
matrix of <strong>action selection probabilities</strong>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>œÄ</mi><mi>t</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>X</mi><mi>j</mi></msub><mo>,</mo><msub><mi>A</mi><mi>j</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\pi_t(X_j, A_j)</annotation></semantics></math>
for each combination of policy update
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math>
and context
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>
in the historical dataset.</p>
<p>While some environments log these probabilities directly, many
contextual bandit libraries (such as <a href="https://github.com/Nth-iteration-labs/contextual" class="external-link"><code>contextual</code></a>)
only store <strong>policy parameters</strong> (e.g., regression
coefficients) without explicit probability tracking.</p>
<p>This article explains how <strong>Cram Bandit Helpers</strong>
reconstruct
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>œÄ</mi><mi>t</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>X</mi><mi>j</mi></msub><mo>,</mo><msub><mi>A</mi><mi>j</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\pi_t(X_j, A_j)</annotation></semantics></math>
from these parameters for common policies:</p>
<table class="table">
<colgroup>
<col width="30%">
<col width="70%">
</colgroup>
<thead><tr class="header">
<th>Policy Type</th>
<th>Class Name</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Epsilon-Greedy</td>
<td><code>BatchContextualEpsilonGreedyPolicy</code></td>
</tr>
<tr class="even">
<td>LinUCB Disjoint with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œµ</mi><annotation encoding="application/x-tex">\varepsilon</annotation></semantics></math>-greedy
exploration</td>
<td><code>BatchLinUCBDisjointPolicyEpsilon</code></td>
</tr>
<tr class="odd">
<td>Thompson Sampling</td>
<td><code>BatchContextualLinTSPolicy</code></td>
</tr>
</tbody>
</table>
<p>Both <strong>theoretical formulas</strong> and <strong>practical code
snippets</strong> are provided.</p>
<hr>
</div>
<div class="section level2">
<h2 id="policy-parameters-explained">üõ†Ô∏èPolicy parameters explained<a class="anchor" aria-label="anchor" href="#policy-parameters-explained"></a>
</h2>
<p>When using linear bandit algorithms like Epsilon-Greedy, LinUCB, or
Thompson Sampling, each arm
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
maintains <strong>summary statistics</strong> (parameters) to estimate
the expected reward:</p>
<ul>
<li><p><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>A</mi><mi>k</mi></msub><annotation encoding="application/x-tex">A_k</annotation></semantics></math>
is the <strong>Gram matrix</strong>:<br><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mi>k</mi></msub><mo>=</mo><msubsup><mi>X</mi><mi>k</mi><mi>T</mi></msubsup><msub><mi>X</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">
A_k = X_k^T X_k
</annotation></semantics></math> where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>X</mi><mi>k</mi></msub><annotation encoding="application/x-tex">X_k</annotation></semantics></math>
is the matrix of feature vectors (contexts) for all rounds where arm
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
was selected.<br>
‚ûî <strong>Interpretation</strong>:
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>A</mi><mi>k</mi></msub><annotation encoding="application/x-tex">A_k</annotation></semantics></math>
captures the amount of information (and correlation structure) about the
features for arm
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>.
It plays the role of a ‚Äúfeature covariance matrix.‚Äù</p></li>
<li><p><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>b</mi><mi>k</mi></msub><annotation encoding="application/x-tex">b_k</annotation></semantics></math>
is the <strong>response vector</strong>:<br><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>b</mi><mi>k</mi></msub><mo>=</mo><msubsup><mi>X</mi><mi>k</mi><mi>T</mi></msubsup><msub><mi>y</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">
b_k = X_k^T y_k
</annotation></semantics></math> where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mi>k</mi></msub><annotation encoding="application/x-tex">y_k</annotation></semantics></math>
are the observed rewards for arm
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>.<br>
‚ûî <strong>Interpretation</strong>:
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>b</mi><mi>k</mi></msub><annotation encoding="application/x-tex">b_k</annotation></semantics></math>
captures the relationship between the observed rewards and the contexts
for arm
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>.</p></li>
</ul>
<p>These sufficient statistics allow the policy to compute the
<strong>Least Squares estimate</strong> for the reward model:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ∏</mi><mi>k</mi></msub><mo>=</mo><msubsup><mi>A</mi><mi>k</mi><mrow><mi>‚àí</mi><mn>1</mn></mrow></msubsup><msub><mi>b</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">
\theta_k = A_k^{-1} b_k
</annotation></semantics></math></p>
<p>where:</p>
<ul>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Œ∏</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\theta_k</annotation></semantics></math>
is the estimated coefficient vector that predicts the expected reward of
arm
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
as a function of the context.</li>
</ul>
<p>Thus:</p>
<ul>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>A</mi><mi>k</mi></msub><annotation encoding="application/x-tex">A_k</annotation></semantics></math>
tells us <strong>how confident</strong> we are about
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Œ∏</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\theta_k</annotation></semantics></math>
(smaller eigenvalues of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>A</mi><mi>k</mi></msub><annotation encoding="application/x-tex">A_k</annotation></semantics></math>
imply more uncertainty).</li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>b</mi><mi>k</mi></msub><annotation encoding="application/x-tex">b_k</annotation></semantics></math>
provides the <strong>observed signal</strong> (reward-weighted context
features) to fit
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Œ∏</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\theta_k</annotation></semantics></math>.</li>
</ul>
<p>The policy selects an action based on the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Œ∏</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\theta_k</annotation></semantics></math>
of each arm
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
and then observe the reward associated with this choice, which is used
to update the parameters
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>A</mi><mi>k</mi></msub><annotation encoding="application/x-tex">A_k</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>b</mi><mi>k</mi></msub><annotation encoding="application/x-tex">b_k</annotation></semantics></math>
of the policy.</p>
<hr>
</div>
<div class="section level2">
<h2 id="epsilon-greedy-policy">‚ú® Epsilon-Greedy Policy<a class="anchor" aria-label="anchor" href="#epsilon-greedy-policy"></a>
</h2>
<div class="section level4">
<h4 id="theoretical-computation">ü§ñ Theoretical computation<a class="anchor" aria-label="anchor" href="#theoretical-computation"></a>
</h4>
<p>In Epsilon-Greedy, with exploration rate
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œµ</mi><annotation encoding="application/x-tex">\varepsilon</annotation></semantics></math>,
the probability of selecting one of the best arms is:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>A</mi><mi>t</mi></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>X</mi><mi>t</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>‚àí</mo><mi>Œµ</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>√ó</mo><mfrac><mn>1</mn><mrow><mi>#</mi><mtext mathvariant="normal">best arms</mtext></mrow></mfrac><mo>+</mo><mi>Œµ</mi><mo>√ó</mo><mfrac><mn>1</mn><mi>K</mi></mfrac></mrow><annotation encoding="application/x-tex"> P(A_t | X_t) = (1 - \varepsilon) \times \frac{1}{\# \text{best arms}} + \varepsilon \times \frac{1}{K} </annotation></semantics></math></p>
<p>While the probability of selecting an arm that is not among the best
arms is:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>A</mi><mi>t</mi></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>X</mi><mi>t</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>Œµ</mi><mo>√ó</mo><mfrac><mn>1</mn><mi>K</mi></mfrac></mrow><annotation encoding="application/x-tex"> P(A_t | X_t) = \varepsilon \times \frac{1}{K} </annotation></semantics></math></p>
<p>where:</p>
<ul>
<li>Best arms are those with maximal estimated rewards.</li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>K</mi><annotation encoding="application/x-tex">K</annotation></semantics></math>
is the total number of available arms.</li>
</ul>
<p>We define the least squares estimate as:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ∏</mi><mi>k</mi></msub><mo>=</mo><msubsup><mi>A</mi><mi>k</mi><mrow><mi>‚àí</mi><mn>1</mn></mrow></msubsup><msub><mi>b</mi><mi>k</mi></msub><mspace width="1.0em"></mspace><mtext mathvariant="normal">(Least Squares estimate)</mtext></mrow><annotation encoding="application/x-tex"> \theta_k = A_k^{-1} b_k \quad \text{(Least Squares estimate)} </annotation></semantics></math></p>
<p>where:</p>
<ul>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>A</mi><mi>k</mi></msub><annotation encoding="application/x-tex">A_k</annotation></semantics></math>
is the Gram matrix
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>X</mi><mi>k</mi><mi>T</mi></msubsup><msub><mi>X</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">X_k^T X_k</annotation></semantics></math>
</li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>b</mi><mi>k</mi></msub><annotation encoding="application/x-tex">b_k</annotation></semantics></math>
is the vector
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>X</mi><mi>k</mi><mi>T</mi></msubsup><msub><mi>Y</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">X_k^T Y_k</annotation></semantics></math>
</li>
</ul>
<p>Best arms are identified via the estimated expected reward:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext mathvariant="normal">Expected reward</mtext><mo>=</mo><msubsup><mi>X</mi><mi>t</mi><mi>T</mi></msubsup><msub><mi>Œ∏</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex"> \text{Expected reward} = X_t^T \theta_k </annotation></semantics></math></p>
</div>
<div class="section level4">
<h4 id="code-helper">üìä Code helper<a class="anchor" aria-label="anchor" href="#code-helper"></a>
</h4>
<p>In <code>cramR</code>, this is implemented by:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">get_proba_c_eps_greedy</span><span class="op">(</span><span class="va">eps</span>, <span class="va">A_list</span>, <span class="va">b_list</span>, <span class="va">contexts</span>, <span class="va">chosen_arms</span><span class="op">)</span></span></code></pre></div>
<p>This function:</p>
<ul>
<li>Computes
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Œ∏</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\theta_k</annotation></semantics></math>
for each arm</li>
<li>Calculates expected rewards
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>X</mi><mi>t</mi><mi>T</mi></msubsup><msub><mi>Œ∏</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">X_t^T \theta_k</annotation></semantics></math>
</li>
<li>Identifies the best arms</li>
<li>Applies the above formula</li>
</ul>
<hr>
</div>
</div>
<div class="section level2">
<h2 id="linucb-disjoint-policy-with-varepsilon-greedy">üî¢ LinUCB Disjoint Policy with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œµ</mi><annotation encoding="application/x-tex">\varepsilon</annotation></semantics></math>-Greedy<a class="anchor" aria-label="anchor" href="#linucb-disjoint-policy-with-varepsilon-greedy"></a>
</h2>
<div class="section level4">
<h4 id="theoretical-computation-1">ü§ñ Theoretical computation<a class="anchor" aria-label="anchor" href="#theoretical-computation-1"></a>
</h4>
<p>LinUCB selects arms based on <strong>Upper Confidence Bounds
(UCBs)</strong>:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mtext mathvariant="normal">UCB</mtext><mi>k</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>X</mi><mi>t</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msub><mi>Œº</mi><mi>k</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>X</mi><mi>t</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><mi>Œ±</mi><msub><mi>œÉ</mi><mi>k</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>X</mi><mi>t</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex"> \text{UCB}_k(X_t) = \mu_k(X_t) + \alpha \sigma_k(X_t) </annotation></semantics></math></p>
<p>where:</p>
<ul>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œº</mi><mi>k</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>X</mi><mi>t</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msubsup><mi>X</mi><mi>t</mi><mi>T</mi></msubsup><msub><mi>Œ∏</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mu_k(X_t) = X_t^T \theta_k</annotation></semantics></math></li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>œÉ</mi><mi>k</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>X</mi><mi>t</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msqrt><mrow><msubsup><mi>X</mi><mi>t</mi><mi>T</mi></msubsup><msubsup><mi>A</mi><mi>k</mi><mrow><mi>‚àí</mi><mn>1</mn></mrow></msubsup><msub><mi>X</mi><mi>t</mi></msub></mrow></msqrt></mrow><annotation encoding="application/x-tex">\sigma_k(X_t) = \sqrt{X_t^T A_k^{-1} X_t}</annotation></semantics></math>
measures uncertainty</li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
controls the exploration strength</li>
</ul>
<p>The action probabilities follow the same structure as Epsilon-Greedy
but with UCB scores instead of plain expected rewards i.e.¬†the
probability to select one of the best arms is:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>A</mi><mi>t</mi></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>X</mi><mi>t</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>‚àí</mo><mi>Œµ</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>√ó</mo><mfrac><mn>1</mn><mrow><mi>#</mi><mtext mathvariant="normal">best arms</mtext></mrow></mfrac><mo>+</mo><mi>Œµ</mi><mo>√ó</mo><mfrac><mn>1</mn><mi>K</mi></mfrac></mrow><annotation encoding="application/x-tex"> P(A_t | X_t) = (1 - \varepsilon) \times \frac{1}{\# \text{best arms}} + \varepsilon \times \frac{1}{K} </annotation></semantics></math></p>
<p>While the probability to select an arm that is not among the best
arms is:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>A</mi><mi>t</mi></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>X</mi><mi>t</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>Œµ</mi><mo>√ó</mo><mfrac><mn>1</mn><mi>K</mi></mfrac></mrow><annotation encoding="application/x-tex"> P(A_t | X_t) = \varepsilon \times \frac{1}{K} </annotation></semantics></math></p>
<p>where ‚Äúbest arms‚Äù are those with highest UCB scores.</p>
</div>
<div class="section level4">
<h4 id="code-helper-1">üìä Code helper<a class="anchor" aria-label="anchor" href="#code-helper-1"></a>
</h4>
<p>In <code>cramR</code>, this is implemented by:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">get_proba_ucb_disjoint</span><span class="op">(</span><span class="va">alpha</span>, <span class="va">eps</span>, <span class="va">A_list</span>, <span class="va">b_list</span>, <span class="va">contexts</span>, <span class="va">chosen_arms</span><span class="op">)</span></span></code></pre></div>
<p>This function:</p>
<ul>
<li>Computes
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Œ∏</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\theta_k</annotation></semantics></math>
</li>
<li>Computes
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œº</mi><mi>k</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>X</mi><mi>t</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mu_k(X_t)</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>œÉ</mi><mi>k</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>X</mi><mi>t</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\sigma_k(X_t)</annotation></semantics></math>
</li>
<li>Identifies arms maximizing
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mtext mathvariant="normal">UCB</mtext><mi>k</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>X</mi><mi>t</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\text{UCB}_k(X_t)</annotation></semantics></math>
</li>
<li>Applies the Epsilon-Greedy selection formula</li>
</ul>
<hr>
</div>
</div>
<div class="section level2">
<h2 id="thompson-sampling-lints">ü§ì Thompson Sampling (LinTS)<a class="anchor" aria-label="anchor" href="#thompson-sampling-lints"></a>
</h2>
<div class="section level4">
<h4 id="theoretical-computation-2">ü§ñ Theoretical computation<a class="anchor" aria-label="anchor" href="#theoretical-computation-2"></a>
</h4>
<p>In Thompson Sampling, actions are sampled according to posterior
draws and the action associated with the maximum value is chosen. The
probability that the arm
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>A</mi><mi>t</mi></msub><annotation encoding="application/x-tex">A_t</annotation></semantics></math>
is optimal is:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>A</mi><mi>t</mi></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>X</mi><mi>t</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>‚Ñô</mi><mrow><mo stretchy="true" form="prefix">(</mo><msubsup><mi>Œ∏</mi><msub><mi>A</mi><mi>t</mi></msub><mi>T</mi></msubsup><msub><mi>X</mi><mi>t</mi></msub><mo>&gt;</mo><msubsup><mi>Œ∏</mi><mi>k</mi><mi>T</mi></msubsup><msub><mi>X</mi><mi>t</mi></msub><mspace width="1.0em"></mspace><mo>‚àÄ</mo><mi>k</mi><mo>‚â†</mo><msub><mi>A</mi><mi>t</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex"> P(A_t | X_t) = \mathbb{P}\left( \theta_{A_t}^T X_t &gt; \theta_{k}^T X_t \quad \forall k \neq A_t \right) </annotation></semantics></math></p>
<p>where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ∏</mi><mi>k</mi></msub><mo>‚àº</mo><mi>ùí©</mi><mrow><mo stretchy="true" form="prefix">(</mo><msubsup><mi>A</mi><mi>k</mi><mrow><mi>‚àí</mi><mn>1</mn></mrow></msubsup><msub><mi>b</mi><mi>k</mi></msub><mo>,</mo><msup><mi>œÉ</mi><mn>2</mn></msup><msubsup><mi>A</mi><mi>k</mi><mrow><mi>‚àí</mi><mn>1</mn></mrow></msubsup><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\theta_k \sim \mathcal{N}(A_k^{-1} b_k, \sigma^2 A_k^{-1})</annotation></semantics></math>.</p>
<p>This requires <strong>computing a multivariate probability</strong>,
which we approximate via <strong>adaptive numerical
integration</strong>.</p>
</div>
<div class="section level4">
<h4 id="code-helper-2">üìä Code helper<a class="anchor" aria-label="anchor" href="#code-helper-2"></a>
</h4>
<p>In <code>cramR</code>, this is implemented by:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">get_proba_thompson</span><span class="op">(</span><span class="va">sigma</span>, <span class="va">A_list</span>, <span class="va">b_list</span>, <span class="va">contexts</span>, <span class="va">chosen_arms</span><span class="op">)</span></span></code></pre></div>
<p>This function:</p>
<ul>
<li>Computes posterior means and variances</li>
<li>Integrates over the space where chosen arm
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>A</mi><mi>t</mi></msub><annotation encoding="application/x-tex">A_t</annotation></semantics></math>
has the highest sampled reward</li>
<li>Returns clipped probabilities for numerical stability</li>
</ul>
<hr>
</div>
</div>
<div class="section level2">
<h2 id="practical-workflow">üë®‚Äçüíª Practical Workflow<a class="anchor" aria-label="anchor" href="#practical-workflow"></a>
</h2>
<p>When using your bandit policy in practice:</p>
<ol style="list-style-type: decimal">
<li>Record action choices, contexts, and policy parameters (e.g.,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi><annotation encoding="application/x-tex">A</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>b</mi><annotation encoding="application/x-tex">b</annotation></semantics></math>)</li>
<li>Calculate the action selection probabilities. If your policy is
within the ones presented above, please feel free to rely on our helper
functions to build
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>œÄ</mi><annotation encoding="application/x-tex">\pi</annotation></semantics></math>.</li>
<li>Feed <code>pi</code>, <code>arm</code>, and <code>reward</code> into
<code><a href="../reference/cram_bandit.html">cram_bandit()</a></code> for evaluation of your policy.</li>
</ol>
<hr>
</div>
<div class="section level2">
<h2 id="estimand-calculation-in-cram_bandit_sim">üß™ Estimand Calculation in <code>cram_bandit_sim()</code><a class="anchor" aria-label="anchor" href="#estimand-calculation-in-cram_bandit_sim"></a>
</h2>
<p>The following only concerns the simulation framework we implemented
for benchmarking purposes.</p>
<p>Once the policies are reconstructed, we compute their true expected
value ‚Äî referred to as the estimand ‚Äî by applying the learned policy to
independent contexts and evaluating it against the known reward function
used in the simulation.</p>
<p>This is done via:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">compute_estimand</span><span class="op">(</span><span class="va">data_group</span>, <span class="va">list_betas</span>, <span class="va">policy</span>, <span class="va">policy_name</span>, <span class="va">batch_size</span>, <span class="va">bandit</span><span class="op">)</span></span></code></pre></div>
<p>Accurately computing the estimand is critical for properly assessing
the bias and confidence interval coverage of the Cram estimate in our
simulations.</p>
</div>
<div class="section level2">
<h2 id="useful-links">üìÇ Useful Links<a class="anchor" aria-label="anchor" href="#useful-links"></a>
</h2>
<ul>
<li>
<a href="https://github.com/Nth-iteration-labs/contextual" class="external-link"><code>contextual</code></a>
package: original framework</li>
<li>
<code><a href="../reference/cram_bandit.html">cram_bandit()</a></code>: Cram evaluation for contextual
bandits</li>
<li>
<code><a href="../reference/cram_bandit_sim.html">cram_bandit_sim()</a></code>: Full simulation engine with
automatic pi estimation</li>
</ul>
<hr>
</div>
<div class="section level2">
<h2 id="acknowledgments">üåü Acknowledgments<a class="anchor" aria-label="anchor" href="#acknowledgments"></a>
</h2>
<p>These helper functions were designed to faithfully reconstruct action
probabilities for the policies implemented in <a href="https://github.com/Nth-iteration-labs/contextual" class="external-link"><code>contextual</code></a>,
while enabling reproducible Cram-based evaluation.</p>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Yanis Vandecasteele.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer>
</div>





  </body>
</html>

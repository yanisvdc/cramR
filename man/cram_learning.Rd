% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/cram_learning.R
\name{cram_learning}
\alias{cram_learning}
\title{CRAM Learning with Model Selection}
\usage{
cram_learning(
  X,
  D,
  Y,
  batch,
  model_type = "Causal Forest",
  learner_type = "ridge",
  baseline_policy = NULL
)
}
\arguments{
\item{X}{A matrix or data frame of covariates for each sample.}

\item{D}{A vector of binary treatment indicators (1 for treated, 0 for untreated).}

\item{Y}{A vector of outcome values for each sample.}

\item{batch}{Either an integer specifying the number of batches (which will be created by random sampling) or a list/vector providing specific batch indices.}

\item{model_type}{The model type for policy learning. Options include \code{"Causal Forest"}, \code{"S-learner"}, and \code{"M-learner"}. Default is \code{"Causal Forest"}.}

\item{learner_type}{The learner type for the chosen model. Options include \code{"ridge"} for Ridge Regression and \code{"FNN"} for Feedforward Neural Network. Default is \code{"ridge"}.}

\item{baseline_policy}{A list providing the baseline policy (binary 0 or 1) for each sample. If \code{NULL}, the baseline policy defaults to a list of zeros with the same length as the number of samples in \code{X}.}
}
\value{
A list containing:
  \item{final_policy_model}{The final fitted policy model, depending on \code{model_type} and \code{learner_type}.}
  \item{policies}{A matrix of learned policies, where each column represents a batch's learned policy and the first column is the baseline policy.}
  \item{batch_indices}{The indices for each batch, either as generated (if \code{batch} is an integer) or as provided by the user.}
}
\description{
This function performs policy learning using cumulative batches with a choice of model types and learner types. Supported models include Causal Forest, S-learner, and M-learner with options for Ridge Regression and Feedforward Neural Network (FNN) learners.
}
\examples{
# Example usage
X_data <- matrix(rnorm(100 * 5), nrow = 100, ncol = 5)  # 100 samples, 5 features
D_data <- sample(c(0, 1), 100, replace = TRUE)          # Random binary treatment assignment
Y_data <- rnorm(100)                                    # Random outcome variable
nb_batch <- 3                                           # Number of batches

# Perform CRAM learning
result <- cram_learning(X = X_data, D = D_data, Y = Y_data, batch = nb_batch)

# Access the learned policies and final model
policies_matrix <- result$policies
final_model <- result$final_policy_model
batch_indices <- result$batch_indices
}
\seealso{
\code{\link[grf]{causal_forest}}, \code{\link[glmnet]{cv.glmnet}}, \code{\link[keras]{keras_model_sequential}}
}

% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/armed_bandit_est.R
\name{cram_bandit_est}
\alias{cram_bandit_est}
\title{Cramming Policy Evaluation for Multi-Armed Bandit}
\usage{
cram_bandit_est(pi, reward, arm)
}
\arguments{
\item{reward}{A matrix of observed rewards corresponding to each action and time step.}

\item{policy_diff}{A matrix where each entry represents the difference in policies
between iterations, i.e., \eqn{\pi_t(X, a) - \pi_{t-1}(X, a)} for each t.}

\item{T}{The total number of iterations in the bandit process.}
}
\value{
The estimated policy value difference \eqn{\Delta(\pi_T; \pi_0)}.
}
\description{
This function implements the armed bandit policy evaluation formula for
estimating \eqn{\Delta(\pi_T; \pi_0)} as given in the user-provided formula.
}

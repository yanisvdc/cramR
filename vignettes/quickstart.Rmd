
---
title: "Quick Start with CRAM"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Quick Start with CRAM}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
options(pkgdown.max_print = Inf, width = 1000)
library(cramR)
library(data.table)
library(glmnet)
library(caret)
```

## Introduction

The **Cram** package provides a unified framework for:

- üß† **Cram Policy (`cram_policy`)**: Learn and evaluate individualized binary treatment rules using CRAM. Offers flexible model choices, including causal forests and custom learners.

- üìà **Cram ML (`cram_ml`)**: Learn and evaluate ML models using CRAM. Supports flexible model training (via `caret` or user-defined functions) and custom loss functions.

- üé∞ **Cram Bandit (`cram_bandit`)**: Learn and perform on-policy evaluation of contextual bandit algorithms using CRAM. Supports both real data and simulation environments with built-in policies.

This vignette walks through these **three core modules**.

---

## 1. CRAM ML 

### Built-in Model 

This section illustrates how to use `cram_ml()` with built-in modeling options available through the `cramR` package. The function integrates with the `caret` framework, allowing users to specify a learning algorithm, a loss function, and a batching strategy to evaluate model performance. 

Beyond `caret`, `cram_ml()` also supports fully custom model training, prediction, and loss functions, making it suitable for virtually any machine learning task ‚Äî including regression, classification, or clustering.

To illustrate the use of `cram_ml()`, we begin by generating a synthetic dataset for a regression task. The data consists of three independent covariates and a continuous outcome.

```{r}
set.seed(42)
X_data <- data.frame(x1 = rnorm(100), x2 = rnorm(100), x3 = rnorm(100))
Y_data <- rnorm(100)
data_df <- data.frame(X_data, Y = Y_data)
```

The `cram_ml()` function offers extensive flexibility through its `loss_name` and `caret_params` arguments.

The `loss_name` argument specifies the performance metric used to evaluate the model at each batch. Available options include:

- `"se"` ‚Äì Squared Error (for regression)  
- `"ae"` ‚Äì Absolute Error  
- `"logloss"` ‚Äì Logarithmic Loss (for probabilistic classification)  
- `"accuracy"` ‚Äì Classification Accuracy  
- `"euclidean_distance"` ‚Äì Squared Euclidean Distance (for clustering tasks)

The `caret_params` list defines how the model should be trained using the [`caret`](https://topepo.github.io/caret/model-training-and-tuning.html) package. It can include **any argument supported by `caret::train()`**, allowing full control over model specification and tuning. Common components include:

- `method`: the machine learning algorithm (e.g., `"lm"` for linear regression, `"rf"` for random forest, `"xgbTree"` for XGBoost, `"svmLinear"` for support vector machines)
- `trControl`: the resampling strategy (e.g., `trainControl(method = "cv", number = 5)` for 5-fold cross-validation, or `"none"` for training without resampling)
- `tuneGrid`: a grid of hyperparameters for tuning (e.g., `expand.grid(mtry = c(2, 3, 4))`)
- `metric`: the model selection metric used during tuning (e.g., `"RMSE"` or `"Accuracy"`)
- `preProcess`: optional preprocessing steps (e.g., centering, scaling)
- `importance`: logical flag to compute variable importance (useful for tree-based models)

Refer to the full documentation at [caret model training and tuning](https://topepo.github.io/caret/model-training-and-tuning.html) for the complete list of supported arguments and options.

Together, these arguments allow users to apply `cram_ml()` using a wide variety of built-in machine learning models and losses. If users need to go beyond these built-in choices, we also provide in the next section a friendly workflow on how to specify custom models and losses with `cram_ml()`.

```{r}
caret_params_lm <- list(
  method = "lm",
  trControl = trainControl(method = "none")
)

result <- cram_ml(
  data = data_df,
  formula = Y ~ .,
  batch = 5,
  loss_name = "se",
  caret_params = caret_params_lm
)
print(result)
```

### Custom Model

In addition to using built-in learners via `caret`, `cram_ml()` also supports **fully custom model workflows**. You can specify your own:

- Model fitting function (`custom_fit`)
- Prediction function (`custom_predict`)
- Loss function (`custom_loss`)

This offers maximum flexibility, allowing CRAM to evaluate any learning model with any performance criterion, including regression, classification, or even unsupervised losses such as clustering distance.

---

#### 1. `custom_fit(data, ...)`

This function takes a data frame and returns a fitted model. You may define additional arguments such as hyperparameters or training settings.

- `data`: A data frame that includes both predictors and the outcome variable `Y`.

**Example**: A basic linear model fit on three predictors:

```{r}
custom_fit <- function(data) {
  lm(Y ~ x1 + x2 + x3, data = data)
}
```

#### 2. `custom_predict(model, data)`

This function generates predictions from the fitted model on new data. It returns a numeric vector of predicted outcomes.

- `model`: The fitted model returned by `custom_fit()`
- `data`: A data frame of new observations (typically including all original predictors)

**Example**: Extract predictors and apply a standard `predict()` call:

```{r}
custom_predict <- function(model, data) {
  predictors_only <- data[, setdiff(names(data), "Y"), drop = FALSE]
  predict(model, newdata = predictors_only)
}
```

#### 3. `custom_loss(predictions, data)`

This function defines the loss metric used to evaluate model predictions. It should return a numeric vector of **individual losses**, one per observation. These are internally aggregated by `cram_ml()` to compute the overall performance.

- `predictions`: A numeric vector of predicted values from the model
- `data`: The data frame containing the true outcome values (`Y`)

**Example**: Define a custom loss function using **Squared Error (SE)**

```{r}
custom_loss <- function(predictions, data) {
  actuals <- data$Y
  se_loss <- (predictions - actuals)^2
  return(se_loss)
}
```

#### 4. Use `cram_ml()` with Custom Functions

Once you have defined your custom training, prediction, and loss functions, you can pass them directly to `cram_ml()` as shown below, note that `caret_params` and `loss_name` that were used for built-in functionalities are now `NULL`:

```{r}
result <- cram_ml(
  data = data_df,
  formula = Y ~ .,
  batch = 5,
  custom_fit = custom_fit,
  custom_predict = custom_predict,
  custom_loss = custom_loss
)
print(result)

```

---

## 3. CRAM Bandit

This section illustrates how to use the `cram_bandit()` function to **evaluate the final learned policy of a contextual bandit algorithm using the same data collected by the algorithm itself**. 

To demonstrate the method, we assume a contextual bandit sequence has been run and has produced:

- a sequence of learned policies (encoded as arrays of probabilities `œÄ_t(x, a)`),
- the arms actually chosen (`arm`),
- the corresponding rewards observed (`reward`).

The `cram_bandit()` function requires a policy probability array `pi`, which captures how the learned policies assign probability mass across actions over time.

This array can be specified in one of two formats:

1. **3D Array**: An array of shape `(n, T, K)`, where:

   - `T` is the number of time steps (i.e., policy updates),
   - `K` is the number of available arms,
   - `n = T √ó batch`, where `batch` is the batch size i.e. the number of actions taken between each policy update.

Each element `pi[j, t, k]` represents the probability that the policy at time `t` assigns arm `k` to context `x_j`.

2. **2D Array**: An array of shape `(n, T)`:

   - Each entry represents the probability assigned by the policy at time `t` to the arm that was actually chosen under context `x_j`.

This compact form omits the full distribution over arms and assumes you are only tracking the realized action probabilities.

> üõ†Ô∏è If you need to compute this probability array from a trained policy or historical data, the `cramR` package provides helper utilities in the `cramR:::` namespace (see ‚ÄúBandit Helpers‚Äù vignette). Note that the exact method may depend on how your bandit logs and models are structured.

```{r}
# Assume pi is a 3D array: observations x time x arms
# Assume arm and reward are vectors of length = nrow(pi)
set.seed(42)
T <- 100
K <- 4
pi <- array(runif(T * T * K, 0.1, 1), dim = c(T, T, K))
for (t in 1:T) {
  for (j in 1:T) {
    pi[j, t, ] <- pi[j, t, ] / sum(pi[j, t, ])
  }
}
arm <- sample(1:K, T, replace = TRUE)
reward <- rnorm(T, mean = 1, sd = 0.5)
cram_results <- cram_bandit(pi, arm, reward, batch=1)

# View summary of the evaluation
print(cram_results$raw_results)

# View interactive summary table
cram_results$interactive_table
```

The returned object includes both a raw numerical summary and an interactive table showing:

- the estimated policy value,
- its standard error,
- and the 95% confidence interval bounds.

---

## Summary

- **cram_policy**: Learn and evaluate decision rules from batch data.
- **cram_ml**: Evaluate ML models with customizable losses.
- **cram_bandit**: Evaluate contextual bandits using on-policy evaluation.

This flexible, unified framework supports both standard modeling and complex experimentation.

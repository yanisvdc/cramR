
---
title: "Quick Start with CRAM"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Quick Start with CRAM}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
options(pkgdown.max_print = Inf, width = 1000)
library(cramR)
library(data.table)
library(glmnet)
library(caret)
```

## Introduction

The **CRAM** package provides a unified framework for:

- üß† **Cram Policy (`cram_policy`)**: Learn and evaluate individualized binary treatment rules using CRAM. Offers flexible model choices, including causal forests and custom learners.

- üìà **Cram ML (`cram_ml`)**: Learn and evaluate ML models using CRAM. Supports flexible model training (via `caret` or user-defined functions) and custom loss functions.

- üé∞ **Cram Bandit (`cram_bandit`)**: Learn and perform on-policy evaluation of contextual bandit algorithms using CRAM. Supports both real data and simulation environments with built-in policies.

This vignette walks through these **three core modules**.

---

## 1. CRAM Policy

We begin by simulating a dataset consisting of covariates `X`, a binary treatment assignment `D`, and a continuous outcome `Y`, which we will use to demonstrate the `cram_policy()` function.

```{r}
library(data.table)
# Function to generate sample data with heterogeneous treatment effects:
# - Positive effect group
# - Neutral effect group
# - Adverse effect group
generate_data <- function(n) {
  X <- data.table(
    binary = rbinom(n, 1, 0.5),                 # Binary variable
    discrete = sample(1:5, n, replace = TRUE),  # Discrete variable
    continuous = rnorm(n)                       # Continuous variable
  )

  # Binary treatment assignment (50% treated)
  D <- rbinom(n, 1, 0.5)

  # Define heterogeneous treatment effects based on X
  treatment_effect <- ifelse(
    X[, binary] == 1 & X[, discrete] <= 2,        # Group 1: Positive effect
    1,
    ifelse(X[, binary] == 0 & X[, discrete] >= 4, # Group 3: Adverse effect
           -1,
           0.1)                                   # Group 2: Neutral effect
  )

  # Outcome depends on treatment effect + noise
  Y <- D * (treatment_effect + rnorm(n, mean = 0, sd = 1)) +
    (1 - D) * rnorm(n)

  return(list(X = X, D = D, Y = Y))
}

# Generate a sample dataset
set.seed(123)
n <- 1000
data <- generate_data(n)
X <- data$X
D <- data$D
Y <- data$Y

```

### Built-in Model

In this example, we demonstrate how to use the **built-in modeling options** provided by the `cramR` package. We walk through the key parameters that control how `cram_policy()` behaves, including the choice of model, learner type, baseline policy, and batching strategy. 

These parameters allow flexibility in configuring the learning process depending on your use case and computational resources. 

```{r}
# Number of batches to split the data into
batch <- 20  

# Model type for estimating treatment effects
# Options: "causal_forest", "s_learner", "m_learner", NULL (to use custom model)
model_type <- "causal_forest"  

# Learner type used inside s/m-learners
# NULL is required for causal_forest; use "ridge" or "fnn" for s/m learners
learner_type <- NULL  

# Baseline policy to compare against (list of 0/1 for each individual)
# Common options:
# - All-control baseline: as.list(rep(0, nrow(X))) or NULL
# - Randomized baseline: as.list(sample(c(0, 1), nrow(X), replace = TRUE))
baseline_policy <- as.list(rep(0, nrow(X)))  

# Whether to parallelize across batches (TRUE for faster but memory-heavy runs)
parallelize_batch <- FALSE  

# Model params 
model_params <- NULL  
```

The `model_params` argument allows you to customize hyperparameters for the model used in policy learning. If left as `NULL`, `cram_policy()` will fall back to sensible defaults depending on the model and learner type:

- For `model_type = "causal_forest"`:  
  The method defaults to `grf::causal_forest()` with `num.trees = 100`.

- For `model_type = "s_learner"` or `"m_learner"` with `learner_type = "ridge"`:  
  It defaults to `glmnet::cv.glmnet()` with `alpha = 1`, corresponding to Ridge regression.

- For `learner_type = "fnn"` (Feedforward Neural Network):  
  A default Keras model is built with the following architecture:
  ```r
  list(
    input_layer = list(units = 64, activation = 'relu', input_shape = input_shape),
    layers = list(
      list(units = 32, activation = 'relu')
    ),
    output_layer = list(units = 1, activation = 'linear'),
    compile_args = list(optimizer = 'adam', loss = 'mse'),
    fit_params = list(epochs = 5, batch_size = 32, verbose = 0)
  )
  ```
  
You can override any of these defaults by passing a custom list to model_params including any parameter name defined in the underlying package, namely `grf::causal_forest()`, `glmnet::cv.glmnet()` or `keras`.

```{r}
# Significance level for confidence intervals (default = 95%)
alpha <- 0.05  

# Run the CRAM policy method
result <- cram_policy(
  X, D, Y,
  batch = batch,
  model_type = model_type,
  learner_type = learner_type,
  baseline_policy = baseline_policy,
  parallelize_batch = parallelize_batch,
  model_params = model_params,
  alpha = alpha
)

# Display the results
print(result)

```

### Custom Model

To use your own model for policy learning, you can supply two user-defined functions:

#### 1. `custom_fit(X, Y, D, ...)`  
This function takes the training data: covariates `X`, outcomes `Y`, and binary treatment indicators `D`, and returns a fitted model object.  
You may also define and use additional parameters (e.g., number of folds, regularization settings, etc.) within the function body.

- `X`: a matrix or data frame of features 
- `Y`: a numeric outcome vector  
- `D`: a binary vector indicating treatment assignment (0 or 1)

**Example**: Custom X-learner with Ridge regression and 5-fold cross-validation

```{r}
custom_fit <- function(X, Y, D, n_folds = 5) {
  treated_indices <- which(D == 1)
  control_indices <- which(D == 0)
  X_treated <- X[treated_indices, ]
  Y_treated <- Y[treated_indices]
  X_control <- X[control_indices, ]
  Y_control <- Y[control_indices]
  model_treated <- cv.glmnet(as.matrix(X_treated), Y_treated, alpha = 0, nfolds = n_folds)
  model_control <- cv.glmnet(as.matrix(X_control), Y_control, alpha = 0, nfolds = n_folds)
  tau_control <- Y_treated - predict(model_control, as.matrix(X_treated), s = "lambda.min")
  tau_treated <- predict(model_treated, as.matrix(X_control), s = "lambda.min") - Y_control
  X_combined <- rbind(X_treated, X_control)
  tau_combined <- c(tau_control, tau_treated)
  weights <- c(rep(1, length(tau_control)), rep(1, length(tau_treated)))
  final_model <- cv.glmnet(as.matrix(X_combined), tau_combined, alpha = 0, weights = weights, nfolds = n_folds)
  return(final_model)
}
```


#### 2. `custom_predict(model, X_new, D_new)`

This function uses the fitted model to generate a **binary treatment decision** for each individual in `X_new`.

It should return a vector of 0s and 1s, indicating whether to assign treatment (`1`) or not (`0`).  
You may also incorporate a custom threshold or post-processing logic within the function.

**Example**: Apply the decision rule ‚Äî treat if the estimated CATE is greater than 0
```{r}
custom_predict <- function(model, X_new, D_new) {
  cate <- predict(model, as.matrix(X_new), s = "lambda.min")

  # Apply decision rule: treat if CATE > 0
  as.integer(cate > 0)
}
```


#### 3. Use `cram_policy()` with `custom_fit()` and `custom_predict()`

Once both `custom_fit()` and `custom_predict()` are defined, you can integrate them into the CRAM framework by passing them to `cram_policy()` as shown below:

```{r}
experiment_results <- cram_policy(
  X, D, Y,
  batch = 20,
  custom_fit = custom_fit,
  custom_predict = custom_predict,
  alpha = 0.05
)
print(experiment_results)
```
---

## 2. CRAM ML 

### Built-in Model 

This section illustrates how to use `cram_ml()` with built-in modeling options available through the `cramR` package. The function integrates with the `caret` framework, allowing users to specify a learning algorithm, a loss function, and a batching strategy to evaluate model performance. 

Beyond `caret`, `cram_ml()` also supports fully custom model training, prediction, and loss functions, making it suitable for virtually any machine learning task ‚Äî including regression, classification, or clustering.

To illustrate the use of `cram_ml()`, we begin by generating a synthetic dataset for a regression task. The data consists of three independent covariates and a continuous outcome.

```{r}
set.seed(42)
X_data <- data.frame(x1 = rnorm(100), x2 = rnorm(100), x3 = rnorm(100))
Y_data <- rnorm(100)
data_df <- data.frame(X_data, Y = Y_data)
```

The `cram_ml()` function offers extensive flexibility through its `loss_name` and `caret_params` arguments.

The `loss_name` argument specifies the performance metric used to evaluate the model at each batch. Available options include:

- `"se"` ‚Äì Squared Error (for regression)  
- `"ae"` ‚Äì Absolute Error  
- `"logloss"` ‚Äì Logarithmic Loss (for probabilistic classification)  
- `"accuracy"` ‚Äì Classification Accuracy  
- `"euclidean_distance"` ‚Äì Squared Euclidean Distance (for clustering tasks)

The `caret_params` list defines how the model should be trained using the [`caret`](https://topepo.github.io/caret/model-training-and-tuning.html) package. It can include **any argument supported by `caret::train()`**, allowing full control over model specification and tuning. Common components include:

- `method`: the machine learning algorithm (e.g., `"lm"` for linear regression, `"rf"` for random forest, `"xgbTree"` for XGBoost, `"svmLinear"` for support vector machines)
- `trControl`: the resampling strategy (e.g., `trainControl(method = "cv", number = 5)` for 5-fold cross-validation, or `"none"` for training without resampling)
- `tuneGrid`: a grid of hyperparameters for tuning (e.g., `expand.grid(mtry = c(2, 3, 4))`)
- `metric`: the model selection metric used during tuning (e.g., `"RMSE"` or `"Accuracy"`)
- `preProcess`: optional preprocessing steps (e.g., centering, scaling)
- `importance`: logical flag to compute variable importance (useful for tree-based models)

Refer to the full documentation at [caret model training and tuning](https://topepo.github.io/caret/model-training-and-tuning.html) for the complete list of supported arguments and options.

Together, these arguments allow users to apply `cram_ml()` using a wide variety of built-in machine learning models and losses. If users need to go beyond these built-in choices, we also provide in the next section a friendly workflow on how to specify custom models and losses with `cram_ml()`.

```{r}
caret_params_lm <- list(
  method = "lm",
  trControl = trainControl(method = "none")
)

result <- cram_ml(
  data = data_df,
  formula = Y ~ .,
  batch = 5,
  loss_name = "se",
  caret_params = caret_params_lm
)
print(result)
```

### Custom Model

In addition to using built-in learners via `caret`, `cram_ml()` also supports **fully custom model workflows**. You can specify your own:

- Model fitting function (`custom_fit`)
- Prediction function (`custom_predict`)
- Loss function (`custom_loss`)

This offers maximum flexibility, allowing CRAM to evaluate any learning model with any performance criterion, including regression, classification, or even unsupervised losses such as clustering distance.

---

#### 1. `custom_fit(data, ...)`

This function takes a data frame and returns a fitted model. You may define additional arguments such as hyperparameters or training settings.

- `data`: A data frame that includes both predictors and the outcome variable `Y`.

**Example**: A basic linear model fit on three predictors:

```{r}
custom_fit <- function(data) {
  lm(Y ~ x1 + x2 + x3, data = data)
}
```

#### 2. `custom_predict(model, data)`

This function generates predictions from the fitted model on new data. It returns a numeric vector of predicted outcomes.

- `model`: The fitted model returned by `custom_fit()`
- `data`: A data frame of new observations (typically including all original predictors)

**Example**: Extract predictors and apply a standard `predict()` call:

```{r}
custom_predict <- function(model, data) {
  predictors_only <- data[, setdiff(names(data), "Y"), drop = FALSE]
  predict(model, newdata = predictors_only)
}
```

#### 3. `custom_loss(predictions, data)`

This function defines the loss metric used to evaluate model predictions. It should return a numeric vector of **individual losses**, one per observation. These are internally aggregated by `cram_ml()` to compute the overall performance.

- `predictions`: A numeric vector of predicted values from the model
- `data`: The data frame containing the true outcome values (`Y`)

**Example**: Define a custom loss function using **Squared Error (SE)**

```{r}
custom_loss <- function(predictions, data) {
  actuals <- data$Y
  se_loss <- (predictions - actuals)^2
  return(se_loss)
}
```

#### 4. Use `cram_ml()` with Custom Functions

Once you have defined your custom training, prediction, and loss functions, you can pass them directly to `cram_ml()` as shown below, note that `caret_params` and `loss_name` that were used for built-in functionalities are now `NULL`:

```{r}
result <- cram_ml(
  data = data_df,
  formula = Y ~ .,
  batch = 5,
  custom_fit = custom_fit,
  custom_predict = custom_predict,
  custom_loss = custom_loss
)
print(result)

```

---

## 3. CRAM Bandit

This section illustrates how to use the `cram_bandit()` function to **evaluate the final learned policy of a contextual bandit algorithm using the same data collected by the algorithm itself**. 

To demonstrate the method, we assume a contextual bandit sequence has been run and has produced:

- a sequence of learned policies (encoded as arrays of probabilities `œÄ_t(x, a)`),
- the arms actually chosen (`arm`),
- the corresponding rewards observed (`reward`).

The `cram_bandit()` function requires a policy probability array `pi`, which captures how the learned policies assign probability mass across actions over time.

This array can be specified in one of two formats:

1. **3D Array**: An array of shape `(n, T, K)`, where:

   - `T` is the number of time steps (i.e., policy updates),
   - `K` is the number of available arms,
   - `n = T √ó batch`, where `batch` is the batch size i.e. the number of actions taken between each policy update.

Each element `pi[j, t, k]` represents the probability that the policy at time `t` assigns arm `k` to context `x_j`.

2. **2D Array**: An array of shape `(n, T)`:

   - Each entry represents the probability assigned by the policy at time `t` to the arm that was actually chosen under context `x_j`.

This compact form omits the full distribution over arms and assumes you are only tracking the realized action probabilities.

> üõ†Ô∏è If you need to compute this probability array from a trained policy or historical data, the `cramR` package provides helper utilities in the `cramR:::` namespace (see ‚ÄúBandit Helpers‚Äù vignette). Note that the exact method may depend on how your bandit logs and models are structured.

```{r}
# Assume pi is a 3D array: observations x time x arms
# Assume arm and reward are vectors of length = nrow(pi)
set.seed(42)
T <- 100
K <- 4
pi <- array(runif(T * T * K, 0.1, 1), dim = c(T, T, K))
for (t in 1:T) {
  for (j in 1:T) {
    pi[j, t, ] <- pi[j, t, ] / sum(pi[j, t, ])
  }
}
arm <- sample(1:K, T, replace = TRUE)
reward <- rnorm(T, mean = 1, sd = 0.5)
cram_results <- cram_bandit(pi, arm, reward, batch=1)

# View summary of the evaluation
print(cram_results$raw_results)

# View interactive summary table
cram_results$interactive_table
```

The returned object includes both a raw numerical summary and an interactive table showing:

- the estimated policy value,
- its standard error,
- and the 95% confidence interval bounds.

---

## Summary

- **cram_policy**: Learn and evaluate decision rules from batch data.
- **cram_ml**: Evaluate ML models with customizable losses.
- **cram_bandit**: Evaluate contextual bandits using on-policy evaluation.

This flexible, unified framework supports both standard modeling and complex experimentation.

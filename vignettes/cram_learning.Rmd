---
title: "Using cram_learning() for Sequential or Parallel Policy Training"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Using cram_learning() for Sequential or Parallel Policy Training}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
library(cramR)
library(grf)
library(glmnet)
library(keras)
library(data.table)
```

## 🔍 What is `cram_learning()`?

The `cram_learning()` function runs the **core learning routine** of the CRAM framework. It learns **batch-wise policies** using cumulative data splits and supports:

- Different model types (`causal_forest`, `s_learner`, `m_learner`)
- Different learners (`ridge`, `fnn`)
- Flexible batching (sequential or parallel)
- Support for custom models (`custom_fit`, `custom_predict`)

This function is typically called internally by wrappers like `cram_policy()`, `cram_simulation()`, or `cram_ml()` — but it can also be used **standalone** for advanced use.

---

## 🧠 When to use it?

Use `cram_learning()` directly when you want:
- More control over **model training** or **batch handling**
- To **debug or visualize** the policy learning phase
- To **inject custom models** outside of built-in ones

---

## 📘 Example: Running `cram_learning()` with Causal Forest

```{r}
# Simulated data
X <- matrix(rnorm(100 * 5), nrow = 100, ncol = 5)
D <- sample(c(0, 1), 100, replace = TRUE)
Y <- rnorm(100)
```

```{r}
# Parameters
batch <- 20
model_type <- 'causal_forest'      # causal_forest, s_learner, or m_learner
learner_type <- NULL               # NULL for causal_forest
baseline_policy <- as.list(rep(0, nrow(X)))  # or random: as.list(sample(c(0, 1), nrow(X), TRUE))
parallelize_batch <- FALSE         # Set to TRUE for parallelized learning
model_params <- NULL               # e.g., list(num.trees = 100) for causal_forest
```

```{r}
# Run cram_learning
learning_result <- cram_learning(
  X = X,
  D = D,
  Y = Y,
  batch = batch,
  model_type = model_type,
  learner_type = learner_type,
  baseline_policy = baseline_policy,
  parallelize_batch = parallelize_batch,
  model_params = model_params
)
```

---

## 📦 Output

```{r}
str(learning_result)
```

Returns a **list** with:

| Element            | Description                                                              |
|--------------------|---------------------------------------------------------------------------|
| `final_policy_model` | The trained policy model (e.g. causal forest or custom)                |
| `policies`           | A matrix where each column is a batch-learned policy + baseline column |
| `batch_indices`      | Index assignments used for each batch                                  |

---

## 🛠️ Advanced Configuration

You can plug in custom training/prediction functions:

```r
custom_fit <- function(X, Y, D) { ... }
custom_predict <- function(model, X, D) { ... }
```

You can also provide advanced `model_params` like:

```r
list(num.trees = 200)  # for grf::causal_forest
```

Or for neural networks:

```r
fnn_params <- list(
  input_layer = list(units = 64, activation = 'relu', input_shape = c(ncol(X))),
  layers = list(list(units = 32, activation = 'relu')),
  output_layer = list(units = 1, activation = 'linear'),
  compile_args = list(optimizer = 'adam', loss = 'mse'),
  fit_params = list(epochs = 5, batch_size = 32, verbose = 0)
)
```

---

## ⚡ Parallelization

Set `parallelize_batch = TRUE` to enable `foreach`-based parallel training (e.g. across 4 cores):

```r
learning_result <- cram_learning(
  X, D, Y, batch,
  model_type = "s_learner",
  learner_type = "ridge",
  parallelize_batch = TRUE,
  n_cores = 4
)
```

---

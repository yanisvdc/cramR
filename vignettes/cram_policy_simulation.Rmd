---
title: "Cram Policy Simulation"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Cram Policy Simulation}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
library(cramR)
library(data.table)
library(DT)
```

This vignettes are not necessarily intended for usage by users in their applications but they allow users to reproduce simulations to test the cram method on examples reproduce from paper and may give an example of how cram performs.

## ðŸŽ¯ What is `cram_simulation()`?

The `cram_simulation()` function performs **simultaneous policy learning and evaluation** under a **known data-generating process (DGP)**. It is useful for:

- Benchmarking Cram on simulated datasets
- Measuring empirical **bias**, **variance**, and **confidence interval coverage**
- Supporting both synthetic (`dgp_X`) and empirical (`X`) covariates generation

---

## ðŸ“¦ Inputs Overview

You must supply either:
- `X`: a dataset to bootstrap from (empirical DGP)  
**or**
- `dgp_X`: a function that simulates covariates  

You must also define:
- `dgp_D(X)`: treatment assignment function  
- `dgp_Y(D, X)`: outcome generation function  

---

## ðŸ“˜ Example: Simulated Data with Binary, Discrete, and Continuous Covariates

```{r}
set.seed(123)

dgp_X <- function(n) {
  data.table::data.table(
    binary     = rbinom(n, 1, 0.5),
    discrete   = sample(1:5, n, replace = TRUE),
    continuous = rnorm(n)
  )
}

dgp_D <- function(X) rbinom(nrow(X), 1, 0.5)

dgp_Y <- function(D, X) {
  theta <- ifelse(
    X[, binary] == 1 & X[, discrete] <= 2,  # Group 1: High benefit
    1,
    ifelse(X[, binary] == 0 & X[, discrete] >= 4,  # Group 3: Negative benefit
           -1,
           0.1)  # Group 2: Neutral effect
  )
  Y <- D * (theta + rnorm(length(D), mean = 0, sd = 1)) +
    (1 - D) * rnorm(length(D))  # Outcome for untreated
  return(Y)
}

# Parameters
nb_simulations <- 100
nb_simulations_truth <- 20
batch <- 5

# Perform CRAM simulation
result <- cram_simulation(
  dgp_X = dgp_X,
  dgp_D = dgp_D,
  dgp_Y = dgp_Y,
  batch = batch,
  nb_simulations = nb_simulations,
  nb_simulations_truth = nb_simulations_truth,
  sample_size = 100
)

# Access results
result$avg_delta_estimate
result$delta_empirical_bias
```

---

## ðŸ“Š Output Summary

```{r}
result$raw_results
```

```{r}
result$interactive_table
```

Returns a list containing:

- `raw_results`: A summary of key averaged metrics  
- `interactive_table`: An interactive HTML widget for quick exploration  

| Metric                             | Meaning                                      |
|------------------------------------|----------------------------------------------|
| Average Proportion Treated         | Share of samples treated by learned policy   |
| Average Delta Estimate             | Mean treatment effect (Î”) estimate           |
| Delta Empirical Bias               | Bias of Î” estimate against truth             |
| Delta Empirical Coverage           | CI coverage of Î” estimate                    |
| Average Policy Value Estimate      | Mean value of final policy                   |
| Policy Value Empirical Bias        | Bias against true policy value               |
| Policy Value Empirical Coverage    | CI coverage of policy value                  |

---

## ðŸ’¡ Notes

- Uses **batch splitting** for honest policy learning
- Variance estimates use **influence-function-based asymptotics**
- Simulations are grouped by `sim_id` and averaged
- You can plug in `custom_fit` and `custom_predict` if needed

---

## ðŸ“š See Also

- `cram_policy()` â€” for CRAM on real experimental/observational data  
- `cram_bandit_sim()` â€” for contextual bandits  
- `cram_ml()` â€” for general supervised or unsupervised ML  

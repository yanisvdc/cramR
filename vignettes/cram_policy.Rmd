---
title: "Using cram_policy() for Policy Learning and Evaluation"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Using cram_policy() for Policy Learning and Evaluation}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
library(cramR)
library(DT)
```

## Introduction: What is the CRAM Method?

The **CRAM method** is a powerful approach for **simultaneously learning and evaluating decision rules**, such as individualized treatment rules (ITRs), from data.

Unlike traditional approaches like **sample splitting** or **cross-validation**, which waste part of the data on evaluation only, **CRAM reuses all available data** efficiently.

CRAM:

- Sequentially trains and evaluates models on *batches* of data  
- Tracks model evolution with minimal assumptions  
- Estimates treatment effects and policy values using the **entire dataset**, increasing efficiency and statistical power

> Think of CRAM like a cram school: learn a bit, test a bit, repeat — getting better while constantly self-evaluating.

## The CRAM Workflow

Below is the core idea of the CRAM method visualized:

![ ](cram_visual_1.png)


This procedure ensures each update is backed by performance testing, enabling **both learning and evaluation in one pass** over the data.

## CRAM Estimation in Practice

![ ](cram_visual_3.png)


This schematic represents how CRAM averages over **many mini train-test steps**, ultimately estimating the improvement of the final learned rule over the baseline. 

Mathematically, the estimated policy value difference is:

\[
\hat{\Delta}(\pi_T; \pi_0) = \sum_{t=1}^{T-1} \hat{\Delta}(\pi_t, \pi_{t-1})
\]

Where:

- \(\pi_t\) is the policy learned after batch `t`
- Evaluation is done using the *unseen* remaining data

## The `cram_policy()` Function

The `cram_policy()` function in **cramR** implements the CRAM framework for binary treatment policy learning.

Key features:

- **Model-agnostic**: Use your favorite learners (`causal_forest`, `s_learner`, `m_learner`, or custom)  
- **Flexible**: Accepts user-defined model fitting and prediction  
- **Fast**: Parallelizes across batches  

## Example: Running CRAM on Simulated Data

```{r}
set.seed(123)
X_data <- matrix(rnorm(100 * 5), nrow = 100, ncol = 5)
D_data <- as.integer(sample(c(0, 1), 100, replace = TRUE))
Y_data <- rnorm(100)
nb_batch <- 5
```

```{r}
result <- cram_policy(
  X = X_data,
  D = D_data,
  Y = Y_data,
  batch = nb_batch
)
```

## Interpreting Results

```{r}
result$raw_results
```

```{r}
result$interactive_table
```

The table displays:
- **Batch-wise policy updates**  
- Estimated improvements (\(\hat{\Delta}\)) per step  
- Final policy value estimates  

## Accessing the Final Learned Policy

```{r}
class(result$final_policy_model)
summary(result$final_policy_model)

```

You can inspect or apply the learned model to new data.

## Visual Summary

![ ](cram_visual_2.png)


This visualization summarizes how multiple evaluations across iterations contribute to the full CRAM estimate.

## Notes and Tips

- **Batching**: You can pass a number (e.g., `batch = 5`) or a custom vector to control how data is split.  
- **Parallelization**: Enable with `parallelize_batch = TRUE`.  
- **Custom Learners**: Use `custom_fit` and `custom_predict` to plug in any estimator.  

## Why CRAM?

Compared to classic evaluation methods:

| Method            | Learning | Evaluation        | Data Use         |
|-------------------|----------|-------------------|------------------|
| Sample Splitting  | Partial  | Partial           | ❌ Inefficient    |
| Cross-Validation  | Partial  | Average Performance | ❌ Expensive    |
| **CRAM**          | ✅ Full  | ✅ Rule-Specific  | ✅ Efficient      |

In practice, CRAM:
- Reduces variance of policy evaluation  
- Produces tighter confidence intervals  
- Accommodates online learners and large-scale models  

## References

- Jia, Z., Imai, K., & Li, M. L. (2024). *The CRAM Method for Efficient Simultaneous Learning and Evaluation*. arXiv:2403.07031.  
- Wager & Athey (2018). *Causal Forests*.  
- Athey & Imbens (2016). *S/M-learner framework*.  
